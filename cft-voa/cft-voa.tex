% !TeX program = lualatex
\documentclass[fleqn]{NotesClass}

\strictpagecheck

\usepackage{csquotes}
\usepackage{tensor}

\usepackage{tikz}
\usetikzlibrary{external}
\tikzexternalize[prefix=tikz-external/]

\usepackage{tikz-cd}

\usepackage{simpler-wick}

\usepackage[pdfauthor={Willoughby Seago},pdftitle={Notes from Conformal Field Theory and Vertex Operator Algebras},pdfkeywords={conformal field theory,CFT,vertex operator algebra,voa},pdfsubject={Conformal Field Theory and Vertex Operator Algebras}]{hyperref}  % Should be loaded second last (cleveref last)
\colorlet{hyperrefcolor}{blue!60!black}
\hypersetup{colorlinks=true, linkcolor=hyperrefcolor, urlcolor=hyperrefcolor}
\usepackage[
capitalize,
nameinlink,
noabbrev
]{cleveref} % Should be loaded last

% My packages
\usepackage{NotesBoxes}
\usepackage{NotesMaths2}

\setmathfont[range={\int, \oint, \otimes, \oplus, \bigotimes, \bigoplus}]{Latin Modern Math}


% Highlight colour
\definecolor{highlight}{HTML}{710D78}
\definecolor{my blue}{HTML}{2A0D77}
\definecolor{my red}{HTML}{770D38}
\definecolor{my green}{HTML}{14770D}
\definecolor{my yellow}{HTML}{E7BB41}

% Title page info
\title{Conformal Field Theory and Vertex Operator Algebras}
\author{Willoughby Seago}
\date{October 8th, 2024}
\subtitle{Notes from}
\subsubtitle{SMSTC}
\renewcommand{\abstracttext}{These are my notes from the SMSTC course \emph{Conformal Field Theories and Vertex Operator Algebras} taught by Dr Anatoly Konechny. These notes were last updated at \printtime{} on \today{}.}

% Commands
% Maths
\newcommand{\manifold}{\symcal{M}}
\renewcommand{\dd}[1]{\,\symrm{d}#1}
\renewcommand{\dl}[1]{\symrm{d}#1}
\DeclarePairedDelimiterX{\innerproduct}[2]{(}{)}{#1, #2}
\newcommand{\pt}{\symrm{pt}}
\newcommand{\isomorphic}{\cong}
\DeclareMathOperator{\Aff}{Aff}
\newcommand{\inversion}{\symcal{I}}
\newcommand{\id}{\symrm{id}}
\DeclareMathOperator{\projectiveSpecialLinear}{PSL}
\newcommand{\identityMatrix}{\symbb{1}}
\newcommand{\lieDerivative}{\symcal{L}}
\DeclarePairedDelimiterX{\bracket}[2]{[}{]}{#1, #2}
\newcommand{\Witt}{\symrm{Witt}}
\newcommand{\quantumField}[1]{\symcal{#1}}
\newcommand{\DL}{\symcal{D}}
\newcommand{\DD}{\,\symcal{D}}
\DeclarePairedDelimiter{\correlator}{\langle}{\rangle}
\difdef{f, s}{gd}{op-symbol=\delta}
\NewDocumentCommand{\diffd}{m m}{\diff.gd.{#1}{#2}}
\NewDocumentCommand{\difsd}{m m}{\difs.gd.{#1}{#2}}
\newcommand{\lagrangian}{\symcal{L}}
\newcommand{\freeboson}{\symrm{fb}}
\newcommand{\dalembertian}{\partial^2}

\begin{document}
    \frontmatter
    \titlepage
    \innertitlepage{}
    \tableofcontents
    % \listoffigures
    \mainmatter
    \chapter{Conformal Geometry}
    \section{Local Conformal Maps}
    Intuitively, we want conformal maps to preserve angles, but not necessarily distances.
    To do so consider how the angle between two vectors in, say, \(\reals^3\) is computed,
    \begin{equation}
        \cos(\theta_{\vv{u}, \vv{v}}) = \frac{\vv{u} \cdot \vv{v}}{\norm{\vv{u}} \norm{\vv{v}}} .
    \end{equation}
    We see here that if each vector were made longer by some positive constant, \(\rho\), then we have
    \begin{equation}
        \cos(\theta_{\rho \vv{u}, \rho \vv{v}})\frac{\rho \vv{u} \cdot \rho \vv{v}}{\norm{\rho \vv{u}} \norm{\rho \vv{v}}} = \cos(\theta_{\vv{u}, \vv{v}}).
    \end{equation}
    We can think of scaling all of the vectors here by \(\rho\) as the same as scaling the metric by \(1/\rho\).
    It's \(1/\rho\) because if we make the units of a measurement smaller then the number we measure gets bigger (hence, \emph{contravariant} vectors).
    
    The following is really just fancy differential-geometry-speak for this rescaling of the metric, and we also allow the scaling of the metric to depend on position.
    
    \begin{dfn}{Local Conformal Map}{}
        Let \((\manifold_1, g_1)\) and \((\manifold_2, g_2)\) be \(n\)-dimensional Riemannian manifolds.
        Let \(U_1 \subseteq \manifold_1\) and \(U_2 \subseteq \manifold_2\) be open subsets.
        A (local) \defineindex{conformal transformation} is a smooth, injective map, \(\varphi \colon U_1 \to U_2\), satisfying the pullback condition
        \begin{equation}
            \varphi^*g_2 = \Lambda g_1
        \end{equation}
        for some function \(\Lambda \colon U_1 \to \reals_{>0}\).
        
        A conformal map defined on all of \(\manifold_1\) is a global conformal map.
    \end{dfn}
    
    \begin{remark}{}{}
        It is possible to relax the conditions on \(\varphi\), and require only that it is differentiable.
        However, requiring smoothness and injectivity is common when it comes to applications, so we make it a basic requirement.
        It's also common to further restrict to orientation-preserving maps, but we won't do that just yet.
    \end{remark}
    
    We can express the pullback condition, \(\varphi^*g_2 = \Lambda g_1\), in local coordinates.
    Let \(x = (x^1, \dotsc, x^n)\) be coordinates covering \(U_1\), and \(y = (y^1, \dotsc, y^n)\) coordinates covering \(U_2\).
    Then \(\varphi\) is fully specified by the functions \(\varphi^i\) which are defined such that \(y^i = \varphi^i(x)\).
    The metrics, \(g_i\), may be specified by their components, \((g_i)_{jk} \colon U_i \to \reals\).
    In these coordinates the pullback condition becomes
    \begin{equation}
        \sum_{k,l} \diffp{\varphi^k}{x^i} \diffp{\varphi^l}{x^j} (g_2)_{kl}(\varphi(x)) = \Lambda(x) (g_1)_{ij}(x).
    \end{equation}
    Taking determinants of either side of this equation we have
    \begin{equation}
        \det\left( \diffp{\varphi^k}{x^i} \right) \det(g_2) \det\left( \diffp{\varphi^l}{x^j} \right) = \Lambda^n \det (g_1).
    \end{equation}
    Now, \(\Lambda^n \ne 0\) and \(\det(g_i) \ne 0\), so it follows that \(\det(\difsp{\varphi^k}{x^i}) \ne 0\), meaning that the matrix with components \(\difsp{\varphi^k}{x^i}\) is invertible.
    This means that a conformal map is always \defineindex{locally invertible}.
    That is, for any \(p \in U_1\) we have a neighbourhood \(V_1 \subseteq U_1\) with \(p \in V_1\) such that \(\varphi\) restricted to \(V_1\) is a bijection.
    
    Note that it's possible to be locally invertible but not fully invertible.
    There may be a point in \(U_1 \setminus V_1\) which maps to the same point as a point in \(V_1\), so the function will not be injective.
    
    \subsection{Conformal Maps Preserve Angles}
    Consider two vectors \(u, v \in T_p\manifold_1\) and some \(p \in \manifold_1\).
    Taking some open neighbourhood of \(p\), \(U_1 \subseteq \manifold_1\), we can also take coordinates \(x = (x^1, \dotsc, x^n)\) covering \(U_1\).
    This gives a basis \(\{\difsp{}{x^i}|_p\}\) for \(T_p\manifold_1\).
    The angle between these vectors is given, as in \(\reals^3\), by
    \begin{equation}
        \cos(\theta_{u, v}) = \frac{\innerproduct{u}{v}}{\norm{u} \norm{v}} = \frac{u^i (g_1)_{ij} v^j}{\sqrt{u^l(g_1)_{lk}u^k v^p (g_1)_{pq} v^q}}.
    \end{equation}
    Here we've started to employ the Einstein summation convention, and we shall do so from now on.
    Let \(\varphi \colon U_1 \to U_2\) be a conformal transformation and suppose that \(U_2\) is covered by coordinates \(y = (y^1, \dotsc, y^n)\).
    Consider the pushforward
    \begin{equation}
        \dl{\varphi_p} \colon T_p \manifold_1 \to T_{\varphi(p)} \manifold_2.
    \end{equation}
    Under this the vectors \(u\) and \(v\) map to the vectors
    \begin{equation}
        \tilde{u} = \dl{\varphi_p}(u), \qqand \tilde{v} = \dl{\varphi_p}(v),
    \end{equation}
    which have coordinates
    \begin{equation}
        \tilde{u}^i = \diffp{\varphi^i}{x^j} u^j, \qqand \tilde{v}^i = \diffp{\varphi^i}{x^j} v^j.
    \end{equation}
    We can now calculate the angle between these vectors as follows:
    \begin{align}
        \cos(\theta_{\tilde{u}, \tilde{v}}) &= \frac{\innerproduct{\tilde{u}}{\tilde{v}}}{\norm{u} \norm{v}}\\
        &= \frac{\tilde{u}^a (g_2)_{ab} \tilde{v}^b}{\sqrt{\tilde{u}^c(g_2)_{cd} \tilde{u}^d \tilde{v}^e (g_2)_{ef} \tilde{v}^f}}\\
        &= \frac{\diffp{\varphi^a}{x^i} u^i (g_2)_{ab} \diffp{\varphi^b}{x^j} u^j}{\sqrt{\diffp{\varphi^c}{x^l} u^l (g_2)_{cd} \diffp{\varphi^d}{x^k} u^k \diffp{\varphi^e}{x^p} v^p (g_2)_{ef} \diffp{\varphi^f}{x^q}}}\\
        &= \frac{u^i \Lambda(g_1)_{ij} v^j}{\sqrt{u^l \Lambda(g_1)_{lk}u^k v^p \Lambda(g_1)_{pq}v^q}}\\
        &= \frac{u^i (g_1)_{ij} v^j}{\sqrt{u^l (g_1)_{lk}u^k v^p (g_1)_{pq}v^q}}\\
        &= \cos(\theta_{u,v})
    \end{align}
    where we've used the pullback condition
    \begin{equation}
        \diffp{\varphi^a}{x^i} (g_2)_{ab} \diffp{\varphi^b}{x^j} = \Lambda (g_1)_{ij}.
    \end{equation}
    This shows that conformal transformations really do preserve angles as we were looking for.
    
    \section{Conformal Transformations on \(\reals^2\)}
    We now restrict ourselves to the case \(\manifold_1 = \manifold_2 = \reals^2\) with the standard Euclidean metric.
    In Cartesian coordinates, \((x^1, x^2)\), the metric corresponds to the matrix
    \begin{equation}
        \begin{pmatrix}
            1 & 0\\
            0 & 1
        \end{pmatrix}
        .
    \end{equation}
    It turns out that it's useful to identify \(\reals^2\) with \(\complex\) using the complex coordinates
    \begin{equation}
        z = x^1 + ix^2, \qqand \overbar{z} = x^1 - ix^2.
    \end{equation}
    In the coordinates \((z, \overbar{z})\) the metric corresponds to the matrix
    \begin{equation}
        \frac{1}{2}
        \begin{pmatrix}
            0 & 1\\
            1 & 0
        \end{pmatrix}
        .
    \end{equation}
    To see this notice that
    \begin{equation}
        x^1 = \frac{1}{2}(z + \overbar{z}), \qqand x^2 = \frac{1}{2i}(z - \overbar{z}).
    \end{equation}
    Thus, by the chain rule, we have
    \begin{equation}
        \dl{x^1} = \diffp{x^1}{z} \dd{z} + \diffp{x^1}{\overbar{z}} \dd{\overbar{z}}, \qqand \dl{x^2} = \diffp{x^2}{z} \dd{z} + \diffp{x^2}{\overbar{z}}.
    \end{equation}
    Inserting this into the usual Euclidean metric we have
    \begin{align}
        g &= (\dl{x^1})^2 + (\dl{x^2})^2\\
        &= \left( \diffp{x^1}{z}\dd{z} + \diffp{x^1}{\overbar{z}} \dd{\overbar{z}} \right)^2 + \left( \diffp{x^2}{z} \dd{z} + \diffp{x^2}{\overbar{z}} \dd{\overbar{z}} \right)^2\\
        &= \left( \frac{1}{2} \dl{z} + \frac{1}{2}\dl{\overbar{z}} \right)^2 + \left( \frac{1}{2i} \dl{z} - \frac{1}{2i} \dl{\overbar{z}} \right)^2\\
        &= \dl{z} \dd{\overbar{z}}.
    \end{align}
    Thus, we must have that
    \begin{equation}
        g_{zz} \dd{z} \dd{z} = g_{\overbar{z}\overbar{z}} \dd{\overbar{z}} \dd{\overbar{z}} = 0, \qand g_{z\overbar{z}}\dd{z}\dd{\overbar{z}} + g_{\overbar{z}z}\dd{\overbar{z}}\dd{z} = 1.
    \end{equation}
    The requirement that \(g\) is symmetric implies the matrix form must be symmetric, which is how we end up with the \(1\) evenly split between the off-diagonal elements.
    
    \subsection{Analytic Structure of Conformal Transformations}
    In the complex coordinates, \((z, \overbar{z})\), we may consider a conformal transformation, \(\varphi \colon U \to V\), as consisting of two maps,
    \begin{equation}
        z \mapsto \varphi(z, \overbar{z}), \qqand \overbar{z} \mapsto \overbar{\varphi}(z, \overbar{z}) = \overline{\varphi(z, \overbar{z})}.
    \end{equation}
    Since the second is just the conjugate of the first we need only specify one of these maps.
    
    We can now write out the pullback condition and check what this imposes on \(\varphi\):
    \begin{align}
        \varphi^*(\dl{z}, \dl{\overbar{z}}) &= \dl{\varphi} \, \overline{\dl{\varphi}}\\
        &= \left( \diffp{\varphi}{z} \dd{z} + \diffp{\varphi}{\overbar{z}} \dd{\overbar{z}} \right)\left( \diffp{\overbar{\varphi}}{z} \dd{z} + \diffp{\overbar{\varphi}}{\overbar{z}} \dd{\overbar{z}} \right)\\
        &= \diffp{\varphi}{z}\diffp{\overbar{\varphi}}{z} (\dl{z})^2 + \diffp{\varphi}{z} \diffp{\overbar{\varphi}}{\overbar{z}} \dd{z} \dd{\overbar{z}} + \diffp{\varphi}{\overbar{z}} \diffp{\overbar{\varphi}}{z} \dd{\overbar{z}} \dd{z} + \diffp{\varphi}{\overbar{z}} \diffp{\overbar{\varphi}}{\overbar{z}} (\dl{\overbar{z}})^2 \notag\\
        &= \left( \diffp{\varphi}{z} \diffp{\overbar{\varphi}}{\overbar{z}} + \diffp{\varphi}{\overbar{z}} \diffp{\overbar{\varphi}}{z} \right) \dd{z} \dd{\overbar{z}} + \diffp{\varphi}{z} \diffp{\overbar{\varphi}}{z} (\dl{z})^2 + \diffp{\varphi}{\overbar{z}} \diffp{\overbar{\varphi}}{\overbar{z}} (\dl{\overbar{z}})^2.
    \end{align}
    Introducing the notation \(\partial_w f = \difsp{f}{w}\) we can now use
    \begin{equation}
        \overline{\partial_w f} = \overline{\diffp{f}{w}} = \diffp{\overbar{f}}{\overbar{w}} = \partial_{\overbar{w}} \overbar{f}
    \end{equation}
    to rewrite this in terms of \(\difsp{\varphi}{z}\) and \(\difsp{\varphi}{\overbar{z}}\):
    \begin{multline}
        \varphi^*(\dl{z}, \dl{\overbar{z}}) = ( (\partial_z \varphi) (\overline{\partial_{z} \varphi}) + (\partial_{\overbar{z}} \varphi) (\overline{\partial_{\overbar{z}} \varphi}) ) \dd{z} \dd{\overbar{z}}\\
        + (\partial_z \varphi) (\overline{\partial_{\overbar{z} \varphi}}) (\dl{z})^2 + (\partial_{\overbar{z}} \varphi) (\overline{\partial_z \varphi}) (\dl{\overbar{z}})^2.
    \end{multline}
    Now, if the pullback condition is to hold we must have
    \begin{equation}
        \varphi^*(\dl{z}, \dl{\overbar{z}}) = \Lambda(z, \overbar{z}) \dd{z} \dd{\overbar{z}}.
    \end{equation}
    So, we require that the \((\dl{z})^2\) and \((\dl{\overbar{z}})^2\) terms vanish, which imposes
    \begin{equation}
        (\partial_z \varphi) (\overline{\partial_{\overbar{z}} \varphi}) = 0.
    \end{equation}
    Thus, we must have
    \begin{equation}
        \partial_z \varphi = 0, \qqor \partial_{\overbar{z}} \varphi = 0.
    \end{equation}
    The second of these says that \(\varphi\) has no \(\overbar{z}\) dependence, and we know that \(\varphi\) is (at least) real differentiable, and thus \(\varphi\) is complex differentiable (with respect to \(z\)) and so \(\varphi\) is holomorphic.
    The first of these says that \(\varphi\) has no \(z\) dependence, and we know that \(\varphi\) is (at least) real differentiable, and thus \(\varphi\) is complex differentiable with respect to \(\overbar{z}\), and so \(\varphi\) is antiholomorphic (that is, it's holomorphic as a function of \(\overbar{z}\)).
    We therefore have two cases
    \begin{itemize}
        \item \(\varphi = \varphi(z)\) is holomorphic; or
        \item \(\varphi = \varphi(\overbar{z})\) is antiholomorhpic.
    \end{itemize}
    
    We are then left with the condition
    \begin{equation}
        (\partial_z\varphi)(\overline{\partial_z\varphi} + (\partial_{\overbar{z}} \varphi) (\overline{\partial_{\overbar{z}} \varphi})) = \abs{\partial_z \varphi}^2 + \abs{\partial_{\overbar{z}} \varphi} = \Lambda(z, \overbar{z}) > 0,
    \end{equation}
    which must hold for all \(z \in U\).
    
    The differential, \(\dl{\varphi}\), of a map \(\varphi \colon U \to V\) in complex coordinates has the matrix representation
    \begin{equation}
        \dl{\varphi} = 
        \begin{pmatrix}
            \partial_z \varphi & \partial_{\overbar{z}} \varphi\\
            \partial_z \overbar{\varphi} & \partial_{\overbar{z}} \overbar{\varphi}
        \end{pmatrix}
        .
    \end{equation}
    Thus, in the holomorphic case we have
    \begin{equation}
        \dl{\varphi} = 
        \begin{pmatrix}
            \partial_z \varphi & 0\\
            0 & \partial_{\overbar{z}} \overbar{\varphi}
        \end{pmatrix}
        , \qand \det(\dl{\varphi}) = \abs{\partial_z \varphi}^2 > 0,
    \end{equation}
    assuming that the derivative doesn't vanish as required to have a positive scaling of the metric.
    In the antiholomorphic case, making the same non-vanishing derivative assumption, we have
    \begin{equation}
        \dl{\varphi} = 
        \begin{pmatrix}
            0 & \partial_{\overbar{z}}\\
            \partial_z \overbar{\varphi} & 0
        \end{pmatrix}
        , \qand \det(\dl{\varphi}) = - \abs{\partial_{\overbar{z}} \varphi} < 0.
    \end{equation}
    The interpretation of these is that holomorphic conformal maps preserve orientation, whereas antiholomorphic conformal maps reverse orientation.
    This shouldn't be suprising, the most basic antiholomorphic map is \(z \mapsto \overbar{z}\), which is a reflection in the real axis, so reverses orientation.
    
    We state these results now as a theorem.
    
    \begin{thm}{}{}
        Any local conformal orientation preserving (reversing) transfformation \(\varphi \colon U \to \complex\) is specified by a holomorphic (antiholomorphic) function \(z \mapsto \varphi(z)\) (\(z \mapsto \varphi(\overbar{z})\)) which is invertible everywhere on \(\varphi(U)\).
    \end{thm}
        
    \subsection{Conformal Transformations Examples}
    We can now ask what conformal transformations \(\varphi \colon \complex \to \complex\) exist.
    We'll also consider conformal transformations defined only on \(\complex\setminus\{\pt\}\) where \(\pt\) is some point where the transformation need not be defined.
    
    \subsubsection{Rigid Transformations}
    The rigid transformations, or \define{isometries}\index{isometry} of \(\complex\) are the distance preserving transformations.
    As such they preserve the metric, and thus are conformal with \(\Lambda = 1\).
    It is well known that the isometries of the plane fall into three different classes.
    
    \paragraph{Translation}
    A translation, \(T_b \colon \complex \to \complex\), by \(b \in \complex\) is defined by
    \begin{equation}
        T_b(z) = z + b.
    \end{equation}
    This clearly preserves the metric since the distance between \(z\) and \(w\) is \(\abs{z - w}\), and the distance between \(T_b(z)\) and \(T_b(w)\) is \(\abs{T_b(z) - T_b(w)} = \abs{z + b - w - b} = \abs{z - w}\).
    Clearly \(T_b\) is bijective and smooth also, and it's defined everywhere, so it's a global conformal transformation.
    
    Translations form a group, which is simply the additive group \((\complex, +)\).
    
    \paragraph{Rotation}
    An anticlockwise rotation, \(R_{\alpha, 0} \colon \complex \to \complex\), by an angle \(\alpha\) about the origin, \(0\), is defined by
    \begin{equation}
        R_{\alpha, 0}(z) = \e^{i\alpha}z.
    \end{equation}
    This preserves the metric, since \(\abs{R_{\alpha, 0}(z) - R_{\alpha, 0}(w)} = \abs{\e^{i\alpha}z - \e^{i\alpha}w} = \abs{\e^{i\alpha}(z - w)} = \abs{z - w}\).
    Again, this is bijective, smooth, and defined everywhere, so it is also a global conformal transformation.
    
    Rotations about the origin form a group, which is simply \(\specialOrthogonal(2, \reals) \isomorphic \unitary(1)\).
    
    A rotation about some point, \(c \in \complex\), by an angle \(\alpha\) is simply given by
    \begin{equation}
        R_{\alpha, c} = T_c \circ R_{\alpha, 0} \circ T_{-c}.
    \end{equation}
    That is, we first translate the centre of rotation to the origin, then rotate, then translate back.
    This is again a conformal transformation, as all composites of conformal transformations are.
    
    Rotations and translations form a group.
    
    \paragraph{Reflection}
    A reflection, \(C_{0, 0} \colon \complex \to \complex\), in the real axis, that is \(x^2 = 0\), is given by conjugation
    \begin{equation}
        C_{0, 0}(z) = \overbar{z}.
    \end{equation}
    This preserves the metric, since \(\abs{C_{0, 0}(z) - C_{0, 0}(w)} = \abs{\overbar{z} - \overbar{w}} = \abs{\overline{z - w}} = \abs{z - w}\).
    Again, this is bijective, smooth, and defined everywhere, so it is also a global conformal transformation.
    
    Reflections in the real axis form a group isomorphic to \(\integers/2\integers\).
    
    A reflection in an arbitrary line can similarly be given as a composition of previously defined conformal transformations.
    To do so we parametrise the line by a point, \(c \in \complex\), through which it passes, and the angle, \(\alpha\), that the line makes to the positive real axis.
    Then a reflection in this line is given by
    \begin{equation}
        C_{\alpha, c} = T_b \circ R_{-\alpha, 0} \circ C_{0, 0} \circ R_{\alpha, 0} \circ T_{-b}.
    \end{equation}
    This is again a conformal transformation.
    
    \subsubsection{Dilation}
    A \defineindex{dilation} or \defineindex{dilitation} is a global conformal transformation, \(D_\rho \colon \complex \to \complex\), for \(\rho \in \reals_{>0}\), defined by
    \begin{equation}
        D_\rho(z) = \rho z.
    \end{equation}
    Intuitively, for \(\rho > 1\) this corresponds to stretching space out evenly in all directions, and for \(\rho < 1\) it's a contraction.
    Clearly this is bijective and smooth, and it is conformal with \(\Lambda = \rho^2\), since \(\dl{(\rho z)} \dd{(\rho \overbar{z})} = \rho^2 \dd{z}\dd{\overbar{z}}\).
    
    Dilations form a group, which is just the multiplicative group \((\complex^{\times}, \cdot)\).
    
    Just looking at the formulae we see that rotations about the origin and dilations are very similar, and in fact, we can combine them into a single transformation \(D_a \colon \complex \to \complex\) with \(a \in \complex\) and \(a = \rho \e^{i\alpha}\) for \(\rho \in \reals_{>0}\) and \(\alpha \in \reals\) and
    \begin{equation}
        D_a(z) = az = \rho \e^{i\alpha} z,
    \end{equation}
    which is a dilation by \(\rho\) and a rotation by \(\alpha\) (the order of which is not important).
    That is, \(D_a = D_\rho \circ R_{\alpha, 0} = R_{\alpha, 0} \circ D_\rho\), and \(R_{\alpha, 0} = D_{\e^{i\alpha}}\).
    
    The combination of all translations, dilations, and rotations forms a group, \(\Aff(\complex)\), the affine group.
    
    \subsubsection{Circle Inversion}
    One example of an antiholomorphic conformal transformation is the map \(\inversion_{0,R} \colon \complex\setminus\{0\} \to \complex\setminus\{0\}\), where \(R \in \reals_{>0}\), defined by
    \begin{equation}
        z \mapsto \frac{R^2}{\overbar{z}}.
    \end{equation}
    We can show that this is conformal by computing the metric after the transformation:
    \begin{equation}
        \dl{\left( \frac{R^2}{\overbar{z}} \right)} \dd{\left( \frac{R^2}{z} \right)} = \frac{R^4}{\abs{z}^4} \dd{z} \dd{\overbar{z}}.
    \end{equation}
    So, this is conformal with \(\Lambda = R^4/\abs{z}^4\).
    
    This transformation has a nice geometric picture, as seen in \cref{fig:circle inversion}.
    A point inside the unit circle is mapped to a point outside the unit circle, and that point is mapped to the original point inside the unit circle.
    We call this \defineindex{inversion}, it swaps the inside and outside of the unit circle (removing 0 from the interior for the map to be defined).
    This swapping can even be done geometrically.
    Given a point, \(P\), in the unit circle draw a line through the origin, \(O\), and \(P\).
    Then this map swaps \(P\) with the point \(P'\) which is such that \(\abs{OP}\abs{OP'} = R^2\).
    
    \begin{figure}
        \tikzsetnextfilename{circle-inversion}
        \begin{tikzpicture}
            \draw [thick] (0, 0) circle [radius=3cm];
            \draw [thick] (0, 0) -- (30:5);
            \fill [highlight] (30:2) circle [radius=0.075cm];
            \node [below] at (30:2) {\(P\)};
            \fill [highlight] (30:4.5) circle [radius=0.075cm];
            \node [below] at (30:4.5) {\(P'\)};
            \draw [thick] (0, 0) -- (-30:5);
            \fill [highlight] (-30:2.5) circle [radius=0.075cm];
            \node [below] at (-30:2.5) {\(Q\)};
            \fill [highlight] (-30:9/2.5) circle [radius=0.075cm];
            \node [below] at (-30:9/2.5) {\(Q'\)};
            \node [left] at (0, 0) {\(O\)};
        \end{tikzpicture}
        \caption[Circle inversion]{Circle inversion, the interior and exterior of the circle are swapped. Here, for example, \(R = 3\), \(\abs{OP} = 2\), and so \(P'\) was chosen with \(\abs{OP'} = 9/2\) so that \(\abs{OP}\abs{OP'} = 9\). Similarly, \(\abs{OQ} = 2.5\) and so \(Q'\) was chosen with \(\abs{OQ'} = 9/2.5\). Notice that points closer to the origin map to points further away from the circle and points near the circle map to points near the circle.}
        \label{fig:circle inversion}
    \end{figure}
    
    Notice that \(\inversion_{0,R} \circ \inversion_{0,R} = \id_{\complex\setminus\{0\}}\), so this is invertible everywhere it's defined.
    
    It's possible to do an inversion in a circle centred elsewhere by translation, define \(\inversion_{c, R} \colon \complex \setminus \{c\} \to \complex \setminus \{c\}\) by \(\inversion_{c, R} = T_c \circ \inversion{0, R} \circ T_{-c}\).
    
    We can get a holomorphic version of this transformation by composing with \(C\), since \(C \circ \inversion_{0, R}\) acts as \(z \mapsto R^2 / z\) which is holomorphic on \(\complex \setminus \{0\}\).
    
    \subsubsection{Special Conformal Transformations}
    We have covered almost all conformal transformations of the plane now.
    It turns out that there's just one more type, known as \define{special conformal transformations}\index{special conformal transformation}.
    To arrive at this one may consider the composite
    \begin{equation}
        \inversion{0, R} \circ T_a \circ \inversion_{0, R}(z) = \inversion_{0, R} \circ T_a\left( \frac{R^2}{\overbar{z}} \right) = \inversion_{0, R}\left( \frac{R^2}{\overbar{z}} + a \right) = \frac{R^2}{\overline{\frac{R^2}{\overbar{z}} + a}} = \frac{z}{\frac{\overbar{a}}{R^2}z + 1}.
    \end{equation}
    Since \(\overbar{a}/R^2\) can take on any complex value as \(a\) and \(R\) vary we see that a special conformal transformation, \(S_c \colon \complex \setminus \{-1/c\} \to \complex\) with \(c \in \complex \setminus \{0\}\) is given by
    \begin{equation}
        S_c(z) = \frac{z}{cz + 1}.
    \end{equation}
    For \(c = 0\) \(S_0(z) = z/(0z + 1) = z\), so \(S_0 = \id_{\complex}\) is defined everywhere.
    
    Note that when considering the composite \(\inversion_{0, R} \circ T_a \circ \inversion_{0, R}\) we should, \textit{a priori}, remove two points from the domain, \(0\) and \(-R^2/\overbar{a}\).
    However, after going through the calculation we see that actually the resulting expression is defined at 0.
    Thus, we may allow 0 after all.
    We will, in general, always take conformal transformations to be defined on the largest possible domain.
    In this case we can think of this as an analytic continuation of the special conformal transformation to the point 0.
    This is a hint that we need to better handle these undefined points, which we do in . % TODO: add reference to compactification/C_infty
    
    \subsection{Global Conformal Transformations}
    Restricting to orientation preserving (holomorphic) conformal transformations it turns out that the requirement that a global conformal transformation is defined everywhere is actually quite restrictive.
    It leaves us with just rotations, dilations, and translations.
    Together these form the affine group, \(\Aff(\complex)\).
    A general affine transformation \(\varphi \colon \complex \to \complex\), is of the form
    \begin{equation}
        \varphi(z) = az + b
    \end{equation}
    for some \(a \in \complex^{\times}\) and \(b \in \complex\).
    It is a result of complex analysis that these are the only orientation-preserving global conformal transformations.
    
    \begin{lma}{}{}
        Affine transformations are the only orientation-preserving global conformal transformations of \(\complex\).
        \begin{proof}
            We know that an orientation-preserving global conformal transformation must be a holomorphic function of \(\complex\) which is invertible everywhere.
            Such a function may not have branch cuts or singularities, as these are points at which it is undefined.
            In a neighbourhood of an essential singularity the image of the function is the entirety of \(\complex\), thus, if the function is to be defined outside of this neighbourhood as well, and also be injective there can be no such essential singularities.
            Thus, \(\varphi\) must be meromorphic, and so can be written as
            \begin{equation}
                \varphi(z) = \frac{P(z)}{Q(z)}
            \end{equation}
            where \(P, Q \in \complex[z]\) are polynomials, and we may assume that they don't share any common factors.
            Since we aren't allowed any poles we must actually have that \(Q(z) = c\) is just a constant polynomial, and we can rescale \(P\) to take \(Q(z) = 1\).
            So, \(\varphi(z) = P(z)\) is a polynomial.
            This polynomial cannot have more than one distinct zero, since this would violate the injectivity requirement.
            Hence, \(\varphi(z) = P(z) = a(z - z_0)^n\) for some \(a, z_0 \in \complex\) and \(n \in \integers_{>0}\).
            We can show that actually we must have \(n \le 1\), since if \(n \ge 2\) then such a map is not injective, mapping both \(z = z_0 + 1\) and \(z = z_0 - 1\) to \(1\).
            Thus, \(\varphi(z) = P(z) = a(z - z_0)^n\) for \(n = 0, 1\), and thus \(\varphi(z)\) is linear.
            One further application of injectivity tells us that \(\varphi(z) = b\) (\(b \in \complex\)) is not an acceptable solution, and thus \(\varphi(z) = az + b\) for some \(a \in \complex^{\times}\) and \(b \in \complex\), so \(\varphi\) is an affine transformation.
        \end{proof}
    \end{lma}
    
    If we instead allow global transformations to be defined on \(\complex\) minus a finite set of points then we can expand the allowed transformations a little bit.
    As with the proof above branch cuts aren't allowed, they require infinitely many undefined points.
    We also don't allow essential singularities by the same argument on injectivity as in the proof.
    Thus, we're left with \(\varphi(z) = P(z)/Q(z)\) where \(P\) and \(Q\) are polynomials.
    We require that the set of zeros of \(Q\) coincides with the set of removed points.
    Injectivity requires that \(P\) has a unique zero of order 1, so it must be linear.
    Injectivity also requires that \(Q\) has a unique zero, if it had more than one then a small circle around the corresponding poles would map to a large circle, and it would be possible to choose circles around two different poles which mapped to the same large circle.
    Further, the order of this zero of \(Q\) must be 1, else a small circle around the corresponding pole would map to a circle that winds around more than once, again, failing to be injective.
    Thus, \(P\) and \(Q\) must be linear, and we are left only with transformations
    \begin{equation}
        z \mapsto \frac{az + b}{cz + d} \quad \text{where} \quad ad - bc \ne 0.
    \end{equation}
    These are called \define{M\"obius transformations}\index{M\"obius transformation}.
    The condition that \(ad - bc \ne 0\) is required for this map to be invertible.
    Such a transformation is defined on \(\complex \setminus \{-d/c\}\) if \(c \ne 0\), or \(\complex\) if \(c = 0\).
    
    If we have M\"obius transformations
    \begin{equation}
        z \mapsto \frac{az + b}{cz + d}, \qqand z \mapsto \frac{ez + f}{gz + h}
    \end{equation}
    with \(a, b, c, d, e, f, g, h \in \complex\) such that \(ab - cd \ne 0\) and \(eh - fg \ne 0\) then the composite performed in the order above is
    \begin{equation}
        z \mapsto \frac{(ae + bg)z + (af + bh)}{(ce + dg)z + (cf + dh)}.
    \end{equation}
    We see that this is again a M\"obius transformation since we can show that the condition on invertibility is \((bc - ad)(fg - eg) \ne 0\), which is true.
    Note that while these M\"obius transformations are individually defined on \(\complex \setminus \{-d/c\}\) and \(\complex \setminus \{-h/g\}\) the composite may be taken to be defined on \(\complex \setminus \{-(cf + dh)/(ce + dg)\}\), despite passing through undefined points in the composite.
    
    Noticing that \(ad - bc\) looks like a determinant we recognise that we may package the parameters of the M\"obius transformation into a matrix,
    \begin{equation}
        A = 
        \begin{pmatrix}
            a & b\\
            c & d
        \end{pmatrix}
    \end{equation}
    with \(\det A \ne 0\).
    That is, \(A \in \generalLinear(2, \complex)\).
    Further, a simple calculation shows that if we have two such matrices then their product exactly corresponds to the composition of the corresponding matrices.
    That is, we have a homomorphism \(\generalLinear(2, \complex) \to G\) where \(G\) is the group of all M\"obius transformations under composition.
    
    This mapping is surjective, but not injective, since, for example, with \(A \in \generalLinear(2, \complex)\) both \(A\) and \(\lambda A\) (for \(\lambda \in \complex^{\times}\)) map to the same M\"obius transformations since
    \begin{equation}
        \frac{az + b}{cz + d} = \frac{\lambda az + \lambda b}{\lambda cz + \lambda d}.
    \end{equation}
    We can use this rescaling to always choose our parameters such that \(ad - bc = 1\).
    That is, we can restrict our consideration to matrices of unit determinant.
    This gives a homomorphism \(\specialLinear(2, \complex) \to G\).
    Note that under this correspondence the following are a translation, \(z \mapsto z + b\), dilation, \(z \mapsto az\), special conformal transformation, \(z \mapsto z/(cz + 1)\), and orientation-preserving inversion, \(z \mapsto 1/z\):
    \begin{equation}
        \begin{pmatrix}
            1 & b\\
            0 & 1
        \end{pmatrix}
        , \quad 
        \begin{pmatrix}
            a^{1/2} & 0\\
            0 & a^{-1/2}
        \end{pmatrix}
        , \quad
        \begin{pmatrix}
            1 & 0\\
            c & 1
        \end{pmatrix}
        , \qand 
        \begin{pmatrix}
            0 & i\\
            i & 0
        \end{pmatrix}
        .
    \end{equation}
    
    This map is still not injective.
    If \(A \in \specialLinear(2, \complex)\) then \(-A \in \specialLinear(2, \complex)\) both \(A\) and \(-A\) map to the same M\"obius transformation.
    The solution is to consider the group\footnote{\(\identityMatrix\) is the identity matrix.}
    \begin{equation}
        \projectiveSpecialLinear(2, \complex) \coloneqq \specialLinear(2, \complex) / \{\pm \identityMatrix\}
    \end{equation}
    called the \defineindex{projective special linear group}.
    Then we finally have \(\projectiveSpecialLinear(2, \complex) \isomorphic G\).
    For the most part we will look at matrices in \(\specialLinear(2, \complex)\), sine it's easier than working with the cosets of \(\projectiveSpecialLinear(2, \complex)\), and we'll just remember that we have this overall freedom in the sign of the matrix.
    
    We will call translations, rotations/dilations, special conformal transformations, and the inversion \(z \mapsto 1/z\) the \define{elementary conformal transformations}\index{elementary conformal transformation}.
    Any M\"obius transformation is generated by these elementary transformations.
    
    An important fact about M\"obius transformations is that any M\"obius transformation maps a circle on the plane to either another circle, or a line (which we may view as a circle of infinite radius).
    This is really a fact about inversions and special conformal transformations, since translations, rotations, and dilations trivially map circles to circles.
    
    \subsubsection{Dealing With Infinity}
    Here we look at two ways to deal with infinity.
    The first is simpler, but doesn't really give us anything new.
    The second is more complicated, but gives us a new way to view the plane.
    
    \paragraph{Extended Complex Numbers}
    Define the set
    \begin{equation}
        \complex_{\infty} \coloneqq \complex \cup \{\infty\}
    \end{equation}
    where \(\infty\) is a formal symbol.
    We can extend the natural structure of \(\complex\) to \(\complex_{\infty}\) by making the following definitions for \(z \in \complex\):
    \begin{equation}
        z + \infty = \infty + z = \infty, \quad \infty z = \infty, \quad \frac{1}{\infty} = 0, \qand \frac{1}{0} = \infty.
    \end{equation}
    Then if we have a M\"obius transformation, \(\varphi\), defined by
    \begin{equation}
        \varphi(z) = \frac{az + b}{cz + d}
    \end{equation}
    we can take it as a function \(\complex_{\infty} \to \complex_{\infty}\) by defining
    \begin{equation}
        \varphi(-d/c) = \infty, \qqand \varphi(\infty) = \frac{a}{c}.
    \end{equation}
    Further, since this is now defined at \(-d/c\) and \(\infty\) we see that this is a bijection of \(\complex_{\infty}\).
    
    This definition works for our set-theoretical concerns, but it doesn't really help with the geometry.
    Where is this point, \(\infty\), with respect to the other points of \(\complex\)?
    It should be \enquote{infinitely far away}, but in what direction?
    The solution to these problems is to use the next method of dealing with infinity.
    
    \paragraph{Conformal Compactification}
    The Riemann sphere from complex analysis gives a bijection mapping of \(\complex_{\infty}\) to the unit sphere, \(S^2\).
    This mapping is by stereographic projection.
    The construction is as follows:
    \begin{itemize}
        \item Embed the plane in \(\reals^3\) with coordinates \((u, v, w)\) as the \(w = 0\) plane.
        \item Embed the sphere in \(\reals^3\) as the set \(\{(u, v, w) \in \reals^3 \mid u^2 + v^2 + w^2 = 1\}\).
        \item To map a point of the plane, \((u, v, w)\), to a point on the sphere draw a line from the point to the point \((0, 0, 1)\), which we think of as the north pole of the sphere.
        This line intersects the sphere in two points, the north pole and one other.
        Map \((u, v, w)\) to this other point.
        \item To map the other way draw a line from the north pole to a point on the sphere (not equal to the north pole) and where this line intersects the plane is where the point on the sphere maps.
        The north pole maps to \(\infty\).
    \end{itemize}
    We call \(S^2\) cosntructed in this way the conformal compactification of the plane, or the one-point compactification of the sphere.
    Conformal because, as we'll show shortly, this mapping is conformal, and one-point because we add a point corresponding to the north pole.
    Compactification because the sphere is compact when the plane wasn't.
    
    After some geometry we end up with a map
    \begin{align}
        s \colon S^2 \setminus \{N\} &\to \complex\\
        (u, v, w) &\mapsto \frac{u + iv}{1 - w}
    \end{align}
    where we've identified the \(w = 0\) plane with \(\complex\) taking the \(u\) and \(v\) axes as the real and imaginary axes respectively.
    The inverse of this mapping is
    \begin{equation}
        s^{-1}(x + iy) = \left( \frac{2x}{x^2 + y^2 + 1}, \frac{2y}{x^2 + y^2 + 1}, \frac{x^2 + y^2 - 1}{x^2 + y^2 + 1} \right).
    \end{equation}
    
    This mapping is conformal with respect to the standard metrics on \(S^2\) and \(\complex\).
    The standard metric on \(S^2\) is just the pullback of the Euclidean metric on \(\reals^3\) along the embedding map.
    So, to check that \(s\) is conformal it is sufficient to calculate the pullback \((s^{-1})^*\) of the standard metric of \(\reals^3\).
    The calculation is straightforward, but a little heavy on the algebra.
    The result is that
    \begin{align}
        (\dl{u})^2 + (\dl{v})^2 + (\dl{w})^2 &= \left( \frac{2\dd{x}}{r^2 + 1} - \frac{2x \dd{r^2}}{(r^2 + 1)^2} \right)^2 + \left( \frac{2\dd{x}}{r^2 + 1} - \frac{2y \dd{r^2}}{(r^2 + 1)^2} \right)^2 \notag\\
        &\qquad + \left( \dd{\left( \frac{r^2 - 1}{r^2 + 1} \right)} \right)^2\\
        &= \frac{4}{(r^2 + 1)^2}(\dl{x^2} + \dl{y^2})\\
        &= \frac{4}{(\abs{z}^2 + 1)^2} \dd{z}\dd{\overbar{z}}.
    \end{align}
    Here \(r^2 = x^2 + y^2\).
    This shows that \(s^{-1}\) is conformal with
    \begin{equation}
        \Lambda = \frac{4}{(\abs{z}^2 + 1)^2}.
    \end{equation}
    
    This means that if we have a M\"obius transformation defined on \(\complex\setminus\{p\}\) we can uniquely extend it to a M\"obius transformation defined on \(S^2\) by taking \(\hat{\varphi} = s^{-1} \circ \varphi \circ s\) on \(S^2 \setminus \{N, s^{-1}(p)\}\), and then defining
    \begin{equation}
        \hat{\varphi}(N) = s^{-1}(a / c), \qand \hat{\varphi}(s^{-1}(p)) = N.
    \end{equation}
    This allows us to identify \(N\) with \(\infty\) from \(\complex_{\infty}\).
    Further, it can be shown that all conformal transformations of the sphere arise in this way, so we don't lose or gain anything by looking at \(S^2\) in place of \(\complex\) or \(\reals^2\).
    
    One way to view this process is that \((\complex, s)\) is a coordinate chart on \(S^2\) covering all points except \(N\).
    We can then get another coordinate chart \((\complex, \tilde{s})\) by repeating the stereographic projection process but with the south pole instead.
    These two charts cover the sphere and the transition maps between them are smooth on their intersection, and as such \(S^2\) is a manifold.
    On the overlap of these two charts they are related by the inversion \(z \mapsto 1/z\).
    To see this note that if a point is on the top hemisphere of the sphere then stereographic projection from the north pole takes it to the outside of the circle in the plane, and if it is on the bottom hemisphere of the sphere then stereographic projection maps it to a point inside the circle.
    The equator maps to the circle.
    Projecting from the south pole instead reverses this.
    
    Using this manifold structure we can look at the neighbourhood of the north pole by working in the \((\complex, \tilde{s})\) chart.
    This let's us do things like take the tangent space \(T_NS^2\).
    This is an advantage over \(\complex_{\infty}\) where we don't have a sensible notion of a tangent space at infinity.
    
    This relation between the two charts further shows that the standard metric on \(S^2\) is locally conformally flat on \(S^2\), in particular, it's flat on \(S^2 \setminus \{N\}\).
    By this we simply mean that a conformal transformation takes the sphere metric on \(S^2\setminus\{N\}\) to the standard flat metric on \(\complex\).
    In a sense, we can push all of the curvature to a single point, \(N\).
    Locallity is important here, there is no globally conformally flat metric, as there is a theorem of differential geometry (the Gauss--Bonnet theorem) that says that the curvature of a manifold, \(M\), is \(2\pi \chi(M)\) where \(\chi\) is the Euler characteristic, which is 2 for \(S^2\), and so there cannot be globally zero curvature.
    This is fine in our case because the curvature is given by the integral
    \begin{equation}
        \int_M \sqrt{g} R \dd{A}
    \end{equation}
    where \(R\) is the Ricci scalar.
    Taking \(R\) to be an appropriately scaled Dirac delta supported at \(N\) allows this to evaluate to \(4\pi\) as needed while retaining zero curvature on \(S^2\setminus\{N\}\).
    
    We will swap back and forth between \(\complex\), \(\complex_{\infty}\), and \(S^2\) as needed, and probably refer to all three as \enquote{the plane} and by each others names.
    
    \section{Infinitesimal Conformal Transformations}
    Given an open subset, \(U \subseteq \reals^2\) a \defineindex{vector field} on \(U\) is a map
    \begin{equation}
        \varepsilon \colon U \to T\reals^2
    \end{equation}
    where \(T\reals^2\) is the tangent bundle.
    That is, \(\varepsilon\) assigns a tangent vector, \(\varepsilon_p\), to each point \(p \in U\).
    Let \(x = (x^1, x^2)\) be coordinates covering \(U\).
    Then we can take the standard basis for \(T_p\reals^2\), given by \(\{\difsp{}{x^i}|_p\}\), although we'll drop the \(|_p\) from the notation.
    Then in these coordinates the vector field \(\varepsilon\) may be expressed as
    \begin{equation}
        \varepsilon^i(x) \diffp{}{x^i}
    \end{equation}
    where \(\varepsilon^i \colon U \to \reals\) are smooth functions (assuming we want a smooth vector field).
    
    This operator (as with all tangent vectors) acts on functions defined on \(U\).
    This action can be exponentiated to obtain a finite transformation, which is done by solving the differential equation
    \begin{equation}
        \diff{}{t} \varphi^{\varepsilon}(x, t) = \varepsilon(\varphi^\varepsilon(x, t))
    \end{equation}
    where \(\varphi^\varepsilon \colon U \times I_0\to \reals\) is a one-parameter group of finite transformations labelled by a parameter \(t \in I_0 = (a, b) \subseteq \reals\) and we assume \(0 \in I_0\).
    Moving to coordinates this gives us the differential equation
    \begin{equation}
        \diff{}{t} \varphi^j(x, t) = \varepsilon^i(x) \diffp{}{x^i} \varphi^j(x, t).
    \end{equation}
    We impose the initial condition that \(\varphi^j(x, 0) = x^j\), so we start at the desired point.
    This has a solution so long as \(\abs{t} < \delta\) for some positive \(\delta\).
    This solution can be expressed formally as
    \begin{equation}
        \varphi^j(x, t) = \e^{t \varepsilon^i(x) \partial_i}x^j
    \end{equation}
    where the exponential is understood via its Taylor series.
    The finite transformation we end up with is
    \begin{equation}
        x^j \mapsto \varphi^j(x, t).
    \end{equation}
    The infinitesimal transformation is given by truncating the power series after the first order term:
    \begin{equation}
        x^j \mapsto x^j + t\varepsilon^j(x).
    \end{equation}
    
    A vector field, \(X\), is called a \defineindex{conformal Killing vector field} if the transformations \(\varphi^X(x, t)\) are local conformal transformations for sufficiently small intervals of \(t\) containing \(t = 0\).
    Using this definition one can show that this is equivalent to the equation
    \begin{equation}
        \lieDerivative_\varepsilon g = \lambda g
    \end{equation}
    where \(\lieDerivative_\varepsilon\) is the Lie derivative, \(g\) is the standard metric on \(\reals^2\), and \(\lambda \colon U \to \reals\) is a (not necessarily positive) function on \(U\).
    This is the infinitesimal version of the pullback requirement.
    
    In coordinates we can take the transformation \(x^j \mapsto x^j + t\varepsilon^j(x)\) and compute the change in coordinates of the metric.
    Dropping all higher order terms we are left with
    \begin{equation}
        \partial_i \varepsilon_j + \partial_j \varepsilon_i = \lambda(x) \delta_{ij}.
    \end{equation}
    Note that we are freely lowering all indices here since the standard metric is \(\delta_{ij}\).
    This is the coordinate version of the above statement with the Lie derivative having substituted \(\delta_{ij}\) for the components of the standard metric.
    Taking the trace of this equation we are left with
    \begin{equation}
        \partial_i \varepsilon^i = \lambda(x).
    \end{equation}
    Substituting this back into the previous equation we have
    \begin{equation}
        \partial_1 \varepsilon^2 = -\partial_2 \varepsilon^1, \qand \partial_1 \varepsilon^1 = \partial_2 \varepsilon^2.
    \end{equation}
    If we take our coordinates to be \(x\) and \(y\) and let \(\varepsilon = u(x, y) + iv(x, y)\) then we can see that these are exactly the Cauchy--Riemann equations of complex analysis.
    This means that the complex coordinate components \(\varepsilon^z = \varepsilon(z)\) and \(\varepsilon^{\overbar{z}} = \overline{\varepsilon(z)}\) must be holomorphic.
    Note that we don't get antiholomorphic solutions.
    This is because the orientation reversing conformal transformations do not have infinitesimal versions, which is because they are in a different connected component of the Lie group of conformal transformations.
    
    An infinitesimal local conformal transformation is then written as
    \begin{equation}
        z \mapsto z + \varepsilon(z), \qand \overbar{z} \mapsto \overbar{z} + \overline{\varepsilon(z)}
    \end{equation}
    on some open set, \(U\).
    The collection of all conformal Killing vector fields forms a real vector space, \(V_0\).
    We know that \(\varepsilon(z)\) is holomorphic, and so analytic on \(U\).
    This means that in a neighbourhood of any point \(\varepsilon\) has a convergent Taylor series.
    For the following we'll take \(U\) to be the punctured disc at the origin, 
    \begin{equation}
        U = \{z \mid \abs{z} < r \text{ and } z \ne 0\} \qwhere r > 0,
    \end{equation}
    but, this will hold for any sufficiently nice \(U\).
    We take the puncture disc to allow for \(\varepsilon\) to have a pole at 0.
    Then \(\varepsilon\) has a Laurent series in a neighbourhood of \(z = 0\) given by
    \begin{equation}
        \varepsilon(z) = \sum_{n \in \integers} c_n z^{n + 1}.
    \end{equation}
    The fact that we have \(z^{n + 1}\) rather than \(z^n\) is just a convention to make other notation line up later, since the sum is over all of \(\integers\) this doesn't change the sum at all.
    The coefficients \(c_n\) with \(n \ll 0\) must vanish, since we assume that we only have a simple pole.
    The corresponding vector field is then given in the basis \(\{\partial_z, \partial_{\overbar{z}}\}\) for the tangent space at \(z\) by
    \begin{equation}
        \varepsilon^z \partial_z + \varepsilon^{\overbar{z}} \partial_{\overbar{z}} = -\sum_{n \in \integers} (c_n l_n + \overbar{c}_n \overbar{l}_n)
    \end{equation}
    where the \(l_n\) and \(\overbar{l}_n\) are the differential operators
    \begin{equation}
        l_n = -z^{n + 1} \partial_z, \qand \overbar{l}_n = -\overbar{z}^{n + 1} \partial_{\overbar{z}}.
    \end{equation}
    These operators are such that \(\{l_n + \overbar{l}_n, i(l_n - \overbar{l}_n)\}_{n \in \integers}\) forms a (real) basis for \(V_0\).
    
    A quick calculation shows that \(V_0\) is closed under the commutator.
    As such \(V_0\) is an (infinite-dimensional) real Lie algebra.
    The commutation relations of the basis vectors \(l_n + \overbar{l}_n\) and \(i(l_n - \overbar{l}_n)\) can be computed in a straightforward way, but they're somewhat complicated.
    It is nicer to state the commutation relations for \(l_n\) and \(\overbar{l}_n\) separately.
    We can then reconstruct the commutation relations for \(l_n + \overbar{l}_n\) using linearity.
    To reconstruct the commutation relations for \(i(l_n - \overbar{l}_n)\) we need to allow complex scalars, which results in us looking at the complexification \(V_0^{\complex} \isomorphic V_0 \oplus iV_0 \isomorphic V_0 \otimes_{\reals} \complex\).
    The corresponding Lie algebra then has the (complex) basis \(\{l_n, \overbar{l}_n\}_{n \in \integers}\).
    These satisfy the commutation relations
    \begin{equation}
        \bracket{l_n}{l_m} = (n - m)l_{n + m}, \quad \bracket{\overbar{l}_n}{\overbar{l}_m} = (n - m) \overbar{l}_{n + m}, \qand \bracket{l_n}{\overbar{l}_m} = 0.
    \end{equation}
    We see from this that what we actually have is that \(V_0^{\complex}\) consists of two commuting copies of the Lie algebra \(\{l_n\}_{n \in \integers}\), where the second copy is marked with a bar to distinguish it.
    From basic Lie theory we recognise that this means that \(V_0^{\complex}\) may be written as a direct sum
    \begin{equation}
        V_0^{\complex} = \Witt \oplus \Witt.
    \end{equation}
    Here \(\Witt\) is the \defineindex{Witt} algebra, which abstractly is defined as the complex Lie algebra generated by \(\{l_n\}_{n \in \integers}\) with the commutation relation \(\bracket{l_n}{l_m} = (n - m)l_{n + m}\).
    Less abstractly the Witt algebra is the algebra of derivations of the space of Laurent polynomials \(\complex[z, z^{-1}]\).
    
    Restricting to just the Witt algebra briefly we can look at the subalgebra generated by \(\{l_{-1}, l_0, l_1\}\).
    This subalgebra is isomorphic to \(\specialLinearLie(2, \complex)\), which can be shown by taking the basis
    \begin{equation}
        e_{-1} = 
        \begin{pmatrix}
            0 & 0\\
            -1 & 0
        \end{pmatrix}
        = -f, 
        , \quad e_0 = \frac{1}{2}
        \begin{pmatrix}
            -1 & 0\\
            0 & 1
        \end{pmatrix}
        = -\frac{1}{2}h, \qand e_1 = 
        \begin{pmatrix}
            0 & 1\\
            0 & 0
        \end{pmatrix}
        = e
    \end{equation}
    for \(\specialLinearLie(2, \complex)\), and we can then show, either from the matrices or from the standard commutation relations of \(\{h, e, f\}\), that we have \(\bracket{e_n}{e_m} = (n - m)e_{n + m}\).
    
    Considering both Witt algebras now, still restricting to \(n = -1, 0, 1\), we can compute the following exponentials for \(a, b, c \in \complex\):
    \begin{align}
        \e^{-bl_{-1} - \overbar{b}\overbar{l}_{-1}}z = \e^{b \partial_z}z &= z + b\\
        \e^{-al_0 - \overbar{a}\overbar{l}_0}z = \e^{az\partial_z}z = \e^az\\
        \e^{cl_1 + \overbar{c}\overbar{l}_1}z = \e^{-cz^2\partial_z} = \frac{z}{cz + 1}
    \end{align}
    The first two expressions here are standard using the power series, the third follows by summing the power series using the geometric series when \(\abs{zc} < 1\), and then analytically continuing to \(\complex \setminus \{-1/c\}\).
    We see that we generate the translations, rotations/dilations (since \(a \in \complex\) so \(\e^a \in \complex^{\times}\)) and special conformal transformations from this subalgebra of \(V_0^{\complex}\).
    By moving to the universal enveloping algebra, allowing us to consider products such as \(l_0l_1\), we get composites of these conformal transformations upon exponentiation, and thus we generate all M\"obius transformations this way.
    
    \chapter{Quantum Field Theory}
    In this chapter we look at quantum field theory in general.
    We do not impose any conformal symmetry.
    We will develop QFT axiomatically, mostly focusing on some special functions called correlators.
    We do not interest ourselves with the physical interpretation of any of the objects discussed.
    We will introduce functional integration (also known as path integrals), which is just one of two main ways that a QFT can be constructed, the other being second quantisation, which we won't look at.
    The path integral construction is, at best, ill-defined, but we won't let this bother us and work with the path integrals as formal objects possessing the desired properties.
    
    \section{Correlation Functions}
    A quantum field theory is a quantum theory regarding fields, which are generally operator-valued functions of spacetime.
    We shall restrict our study to Euclidean QFTs in two-dimensions, where spacetime is \(\reals^2\) with the standard metric, or equivalently, \(\complex\) with the standard metric.
    
    We follow the standard physics practice of not really specifying what our fields are, or what they act on, and just say that we have some fields, which we'll denote with a calligraphic font for now, so \(\quantumField{O}\), \(\quantumField{A}\), and so on (later we'll see \(\DL\), which is not a field).
    We call these \define{local fields}\index{local field}, because they depend on the position of a single point.
    
    While we don't specify what the fields are as functions of spacetime they do have a natural notion of addition and scaling, and so it's natural to assume that we have a vector space, \(W\), of fields.
    We can take \(W\) to be a real or complex vector space.
    If we take \(W\) to be a real vector space then we can always complexify to get \(W^{\complex}\) and identifying \(W\) as a real subspace of this complex vector space.
    This allows us to always assume that \(W\) is a vector space over \(\complex\).
    
    \begin{dfn}{Correlator}{}
        Let \(W\) be the vector space of local fields, and let \(\quantumField{O}_1, \dotsc, \quantumField{O}_n \in W\) be local fields.
        Define the set
        \begin{equation}
            \Delta_n \coloneqq \{(z_1, \dotsc, z_n) \in (\reals^2)^n \mid z_i = z_j \text{ for some } i \ne j\},
        \end{equation}
        this consists of all \(n\)-tuples of elements of \(\reals^2\) where two (or more) elements are equal.
        Then we define the \define{\(\symbf{n}\)-point correlation function}\index{correlation function} (or correlator) as a function
        \begin{equation}
            \reals^{2n} \setminus \Delta_n \to \complex
        \end{equation}
        defined by
        \begin{equation}
            (z_1, \dotsc, z_n) \mapsto \correlator{\quantumField{O}_1(z_1) \dotsm \quantumField{O}_n(z_n)} \in \complex.
        \end{equation}
        We will identify \(\reals^2\) with \(\complex\) and then we instead have
        \begin{equation}
            \Delta_n = \{(z_1, \dotsc, z_n) \in \complex^n \mid z_i = z_j \text{ for some } i \ne j\}
        \end{equation}
        and the correlation functions are functions
        \begin{equation}
            \complex^n \setminus \Delta_n \to \complex.
        \end{equation}
    \end{dfn}
    
    Note that while we write \(\quantumField{O}_i(z_i)\) we do not require that the \(\quantumField{O}_i\) are complex-analytic, and could just as well write \(\quantumField{O}_i(z_i, \overbar{z}_i)\), but we'll soon see that expressions in QFT already get quite large, so we don't want to add even more symbols.
    
    We do not specify how the correlation function is evaluated, for now it's just notation.
    We'll look at one way to evaluate it later.
    For now we just demand that these functions have some desirable properties.
    
    The first property is that the correlators are independent\footnote{Here we assume that the fields represent bosons (particles with integer spin). If instead they represent fermions (particles with half-integer spin) then exchanging two fermionic fields should pick up a minus sign. The result is that in the following formula we need a \(\sgn \pi\) factor for fermionic fields.} of the order in which we write the \(\quantumField{O}_i(z_i)\).
    That is, for \(\pi \in S_n\) we should have
    \begin{equation}
        \correlator{\quantumField{O}_1(z_1) \dotsm \quantumField{O}_n(z_n)} = \correlator{\quantumField{O}_{\pi(1)}(z_{\pi(1)}) \dotsm \quantumField{O}_{\pi(n)}(z_{\pi(n)})}.
    \end{equation}
    Note that we have to permute both the fields and the evaluation points to get the equality\footnote{The correlator may be thought of as a function of the product of the fields. When we think of the fields as operators as in second quantisation we do not assume that they commute. However, when in a correlator we are either doing path integrals, in which case the fields are taken to commute, or if we are doing second quantisation then for these expressions to make sense we must normal order the terms in the product, and this fixes an ordering independently of the order we write.}.
    
    The second property that we require is linearity in the fields.
    That is, if \(\quantumField{O}_1 = \quantumField{A}_1 + \lambda \quantumField{B}_1\) for \(\lambda \in \complex\) and \(\quantumField{A}_1, \quantumField{B}_1 \in W\) then we have
    \begin{multline}
        \correlator{\quantumField{O}_1(z_1) \quantumField{O}_2(z_2) \dotsm \quantumField{O}_n(z_n)}\\
        = \correlator{\quantumField{A}_1(z_1) \quantumField{O}_2(z_2) \dotsm \quantumField{O}_n(z_n)} + \lambda \correlator{\quantumField{B}_1 \quantumField{O}_2(z_1) \dotsm \quantumField{O}_n(z_n)}.
    \end{multline}
    
    By requiring that the correlators are functions \(\complex^n\setminus \Delta_n \to \complex\) we are requiring that they achieve finite values everywhere on \(\complex^n\setminus \Delta_n\).
    However, we can naturally extend the correlators to all of \(\complex^n\) by considering them as functions \(\complex^n \to \complex_{\infty}\) which are allowed to have singularities only at elements of \(\Delta_n\).
    The assumption that we have poles only at coincident points is called the \defineindex{locallity assumption}.
    Physically the idea is that the fields evaluated at different points can't interact with each other, but by evaluating the fields at the same point they can interact, and often do to produce divergent results.
    In a Euclidean QFT the result of this is that the local fields must be real analytic in a neighbourhood free of points in \(\Delta_n\).
    This means that they have a convergent power series on such neighbourhoods.
    It does not mean that they are \emph{complex} analytic, and so there is no general requirement that the local fields are in any way holomorphic or antiholomorphic.
    
    It is natural to require that as well as the fields \(\quantumField{O}_i\) being in \(W\) there are also fields \(\partial^m\overbar{\partial}^n\quantumField{O}_i\) in \(W\) which can reasonably be interpreted as the derivatives of the fields \(\quantumField{O}_i\).
    We don't define the derivative of a field, we simply require that the following holds:
    \begin{align}
        \correlator{\partial^m \overbar{\partial}^n \quantumField{O}_1(z_1) \dotsm \quantumField{O}_k(z_k)} &= \correlator{\partial_{z_1}^m \partial_{\overbar{z}_1}^n \quantumField{O}_1(z_1) \dotsm \quantumField{O}_k(z_k)}\\
        &= \partial_{z_1}^m \partial_{\overbar{z}_1}^n \correlator{\quantumField{O}_1(z_1) \dotsm \quantumField{O}_k(z_k)}.
    \end{align}
    Here the derivatives on the right are just normal derivatives of a complex function in \(z_1\) and \(\overbar{z}_1\).
    Note that this defines the derivative of any field, since by the symmetry of fields within the correlator we are always free to reorder the fields to get the one we're taking the derivative of at the front.
    
    \begin{ntn}{}{}
        Derivatives are assumed to have higher precedence than multiplication.
        Thus, \(\partial_xfg\) is always interpreted as \((\partial_xf)g\), rather than \(\partial_x(fg)\).
    \end{ntn}
    
    \section{Distributions}
    Now that we've got derivatives it's natural to consider integrals.
    Unfortunately, the singularities cause problems when it comes to defining integrals.
    The solution is to replace functions with distributions.
    
    \begin{dfn}{Distribution}{}
        Let \(X\) be a topological space, and \(U \subseteq X\) open.
        Let \(K(U)\) denote the set of all smooth functions \(f \colon U \to \complex\) with compact support (that is, the subset of \(U\) on which \(f(x) \ne 0\) is compact).
        We call \(K(U)\) the space of test functions, and \(f \in K(U)\) a \defineindex{test function}.
        There is a natural topology on \(K(U)\) called the canonical LF-topology.
        
        A \defineindex{distribution} is a continuous (with respect to the canonical LF-topology) linear functional \(F \in K(U)^*\), that is \(F \colon K(U) \to \complex\).
    \end{dfn}
    
    We are interested in the case \(X = \complex^n\), and we assume that test functions are defined on all of \(\complex^n\), but we'll only ask that they have properties locally.
    Given a test function, \(f \in K(\complex^n)\), and a distribution, \(\phi \in K(U)^*\), if \(f\) is locally integrable, meaning that
    \begin{equation}
        \int_U f(z) \dd^nz
    \end{equation}
    exists for open \(U \subseteq \complex^n\), then there is a canonical way to evaluate the action of the distribution on \(f\), namely
    \begin{equation}
        \innerproduct{\varphi}{f} = \int_U \varphi(z) f(z) \dd^nz.
    \end{equation}
    
    We assume that \(U\) is a region without boundary, or that at least \(f\) vanishes on the boundary of \(U\), which allows us to use integration by parts to show that
    \begin{equation}
        \innerproduct{\varphi}{\partial_\mu f} = \int_U \varphi(z) \partial_\mu f(z) \dd{^nz} = -\int_U (\partial_\mu \varphi(z)) f(z) \dd{^nz}
    \end{equation}
    where the boundary term,
    \begin{equation}
        \int_{\partial U} \varphi(z)f(z) \dd{A},
    \end{equation}
    vanishes for one of the above reasons.
    
    An alternative requirement to compact support for test functions is that test functions must decay to zero at infinity faster than any polynomial.
    This allows, for example, \(z \mapsto \e^{-\abs{z}^2}\), to be a test function, despite being everywhere non-zero.
    
    This is quite a formal way to do distributions, which we'll quickly abandon and start considering them to be functions-but-weird.
    The general rule is that whenever there's a distribution (usually a Dirac delta) it only really makes sense under an integral, even if we don't write the integral.
    So everywhere I write a Dirac delta just assume that it's under an appropriate integral.
    
    \section{Functional Integration}
    One way to produce correlation functions is through \defineindex{functional integration}, the integration of distributions.
    Physicists call these \define{path integrals}\index{path integral}, not to be confused with a contour integral, because when these integrals first arose in physics the domain of the functions was all possible paths between two points in space.
    
    We won't define path integrals properly, mostly because there isn't a consistent definition that works in all scenarios.
    Instead, we'll motivate them by analogy with normal integrals, then we'll treat them as formal objects that we can learn to manipulate in ways that mirror the properties of normal integrals (maybe you're already seeing the similarity to how we treat correlators).
    
    An ordinary integral looks like
    \begin{equation}
        \int_D f(x) \dd{^nx}
    \end{equation}
    where \(\manifold\) is some manifold, \(D \subseteq \manifold\) is a region of that manifold, \(f \colon D \to \complex\) is an integrable function, and \(\dl{^nx}\) is an appropriate measure, where we've already assumed that \(D\) can be covered by some coordinates\footnote{If this is not the case then we need to split \(D\) up into regions and be careful about where they overlap using partitions of unity.} \(x\).
    
    A functional integral looks like
    \begin{equation}
        \int_C F[\phi] \DD\phi
    \end{equation}
    where \(C\) is some set of functions \(\phi \colon \manifold \to \complex\) (with \(\manifold\) a manifold), \(F \colon C \to \complex\) is some functional, and \(\DL\phi\) is an appropriate (usually ill-defined) measure.
    
    \begin{exm}{}{}
        Consider the interval, \(I = [0, 1] \subseteq \reals\), and define
        \begin{equation}
            C(I) = \{\phi \mid I \to \reals \mid \phi \text{is continuous}\}.
        \end{equation}
        We can approximate any such function by a piecewise linear function, \(\phi_N \in P_N(I) \subset C(I)\), where \(P_N(I)\) is the set of all continuous functions which are linear on the intervals \([i/N, (i+1)/N]\) for \(i = 0, 1, \dotsc, N - 1\).
        The space \(C(I)\) is infinite dimensional, whereas the space \(P_N(I)\) is finite dimensional
        To specify an element of \(P_N(I)\) we need only specify \(N + 1\) real numbers, typically the endpoints of each line segment, which are \(\phi(0), \phi(1/N), \phi(2/N), \dotsc, \phi(1)\).
        Given a functional \(F \colon C(I) \to \reals\) we can define the functional integral as the \enquote{limit} of the integral over the \(N + 1\) dimensional space as we take \(N \to \infty\):
        \begin{equation}
            \int_{C(I)} F[\phi] \DD\phi = \lim_{N \to \infty} \int \dotsi \int F[\phi_N] \dd\phi(0) \dotsm \dl \varphi(1).
        \end{equation}
        Proving that this limit exists and is independent of the way we approximate the space \(C(I)\) by finite-dimensional subspaces is hard, and has only been done rigorously in a few cases.
    \end{exm}
    
    So, abandoning all hope of a rigorous definition of functional integrals we proceed to list some properties that we would like functional integrals to possess.
    The first is that, like normal integrals, functional integrals should be linear in the integrand.
    So, if \(F_1\) and \(F_2\) are functionals and \(\lambda \in \complex\) is a scalar then we require the following:
    \begin{equation}
        \int_C (F_1[\phi] + \lambda F_2[\phi]) \DL\phi = \int_C F_1[\phi] \DD\phi + \lambda \int_C F_2[\phi] \DD\phi.
    \end{equation}
    
    Now consider a normal integral over an unbounded region, or where the integrand vanishes on the boundary.
    Then by integration by parts we have
    \begin{equation}
        \int_D \diffp{f}{x} \dd{^nx} = \int_D 1 \cdot \diffp{f}{x} \dd{^nx} = - \int_D \diffp{1}{x} f(x) \dd{^nx} = 0.
    \end{equation}
    We therefore demand the equivalent result for functional integrals, namely
    \begin{equation}
        \int_C \diffd{F}{\phi(x)} \DD\phi = 0.
    \end{equation}
    Of course, we need to define the \defineindex{functional derivative}, \(\difsd{F}{\phi(X)}\).
    This can be done formally as a limit, but again, we just look at the properties it has, including linearity,
    \begin{equation}
        \diffd{(F_1 + \lambda F_2)}{\phi(x)} = \diffd{F_1}{\phi(x)} + \lambda \diffd{F_2}{\phi(x)},
    \end{equation}
    and the product rule,
    \begin{equation}
        \diffd{F_1F_2}{\phi(x)} = \diffd{F_1}{\phi(x)} F_2[\phi] + F_1[\varphi] \diffd{F_2}{\phi(x)}.
    \end{equation}
    Another important property is the functional version of
    \begin{equation}
        \diffp{x^i}{x^j} = \tensor{\delta}{^i_j},
    \end{equation}
    which is
    \begin{equation}
        \diffd{\varphi(x)}{\varphi(y)} = \delta(x - y).
    \end{equation}
    
    The final property that we assume for functional integrals is invariance under a suitable change of variables.
    We'll go into more detail on how this is done later.
    
    \section{Path Integrals}
    In this section we will look at how QFT uses functional integrals (which I'll call path integrals in this context).
    We assume the simplest case, which is that there's only one field, \(\phi\), and it is a scalar field.
    This means that the corresponding particle will have zero spin.
    We won't worry about what this means, and in later sections we'll introduce other types of field which do have spin.
    
    Looking at the properties that correlators and functional integrals possess we see that they match, and so it makes sense to define the correlators to be the result of evaluating specific path integrals.
    Specifically, we can define the \(n\)-point correlator by\footnote{We work in Euclidean spacetime. In Minkowski spacetime the exponent is \(iS[\phi]\). Also, we're working in units where \(\hbar = 1\), else we'd need a \(1/\hbar\) in the exponent to give us a dimensionless quantity, with \(\hbar = 1\) the action is dimensionless.}
    \begin{equation}
        \correlator{\phi(z_1) \dotsm \phi(z_n)} = \frac{1}{Z} \int_C \e^{-S[\phi]} \phi(z_1) \dotsb \phi(z_n) \DD\phi.
    \end{equation}
    Here \(\phi \in W\) is just a particular field, called the \defineindex{fundamental field}.
    We will assume that most of our fields are built out of \(\phi\) and its derivatives.
    In this \(Z\) is the \defineindex{partition functional}, defined as
    \begin{equation}
        Z = \int_C \e^{-S[\phi]} \DD\phi.
    \end{equation}
    It is just a normalisation factor.
    In these we have the \defineindex{action functional}, \(S\), which is usually defined via an integral
    \begin{equation}
        S[\phi] = \int_D \lagrangian(\phi, \partial_\mu \varphi, t) \dd{t}\dd{^nx}
    \end{equation}
    where we're working in \((n + 1)\)-dimensional spacetime.
    The function \(\lagrangian\) is called the \defineindex{Lagrangian} (or more properly, the Lagrangian density as we integrate it over time and space).
    Most QFT theories are specified by defining the Lagrangian.
    The simplest case is a the Lagrangian corresponding to a free scalar massless boson.
    Breaking this down:
    \begin{itemize}
        \item free means that there are no interactions between particles, which in QFT means that the Lagrangian doesn't have any terms higher than second order in \(\phi\);
        \item scalar boson means that the particle has spin zero, and the corresponding field is just scalar valued (as opposed to a spinor or vector valued field, which we'll see later);
        \item massless means that the particle has no mass, which in QFT means that the Lagrangian has no \(\phi^2\) term.
    \end{itemize}
    The Lagrangian is then
    \begin{equation}
        \lagrangian = \frac{1}{8\pi}\partial_\mu \varphi \partial^\mu \varphi.
    \end{equation}
    The single term here is called the kinetic term, and it controls how the particle moves through spacetime.
    The factor of \(1/(8\pi)\) is included here because it will be nice later.
    A more standard choice is just a factor of \(1/2\).
    The action functional is then
    \begin{equation}
        S_{\freeboson}[\phi] = \frac{1}{8\pi} \int_C \partial_\mu \varphi \partial^\mu \varphi \dd{^2x}.
    \end{equation}
    Here we assume that we're working in two dimensional spacetime.
    
    At this point we note that taking a product of composite fields, such as \(\varphi(z)\varphi(z)\), is often going to lead to divergences in our correlators, because here we have two fields evaluated at the same point.
    The usual way we get around this is to consider such a product as short-hand for
    \begin{equation}
        \lim_{\varepsilon \to 0} \varphi(z)\varphi(z + \varepsilon),
    \end{equation}
    or something similar which prevents these coincident evaluation points, and then only take the limit when it is safe to do so.
    Sometimes we still get infinities this way, but physics has a whole system for subtracting these off in a consistent way called \defineindex{renormalisation}.
    In physics it's common to take \(\varphi(x)\varphi(x + i\varepsilon)\), with an extra factor of \(i\), because the poles we're usually wanting to avoid are on the real axis. and so this is often called the \define{\(\symbf{i\varepsilon}\) prescription}\index{ie prescription@\(i\varepsilon\) prescription}.
    
    It should also be noted that we can take many fundamental fields, for example, if we have \(n\) fundamental fields, \(\phi_1, \dotsc, \phi_n\), with \(\phi_i \in C_i\) then we may define the correlator of \(n\) fields as
    \begin{equation*}
        \correlator{\phi_1(z_1) \dotsm \phi_n(z_n)} = \frac{1}{Z}\int_{C_1 \otimes \dotsb \otimes C_n} \e^{-S[\phi_1, \dotsc, \phi_n]} \phi_1(z_1) \dotsm \phi_n(z_n) \DD\phi_1 \dotsm \DD\phi_n
    \end{equation*}
    where
    \begin{equation}
        Z = \correlator{\phi_1(z_1) \dotsm \phi_n(z_n)} = \frac{1}{Z}\int_{C_1 \otimes \dotsb \otimes C_n} \e^{-S[\phi_1, \dotsc, \phi_n]} \DD\phi_1 \dotsm \DD\phi_n.
    \end{equation}
    
    \subsection{Computing Correlators for the Free Boson}
    In this section we'll look at how, despite the fact that the path integrals aren't really defined, we can still use them to evaluate the correlators.
    We'll do this for the free massless scalar boson, which has the action functional\footnote{We start to use the physics convention where the measure is put before the integrand. This assumes that integration binds less tightly than multiplication but more tightly than addition, so \(\int \dl{x} \, fg = \int \dl{x} \, (fg) = \int fg \dd{x}\) and \(\int \dl{x} \, f + g = \left( \int \dl{x} \, f \right) + g = \int f \dd{x} + g = g + \int f \dd{x}\).}
    \begin{equation}
        S_{\freeboson}[\phi] = \frac{1}{8\pi} \int_C \dl{^2x} \, \partial_\mu \varphi \partial^\mu \varphi.
    \end{equation}
    
    \subsubsection{Odd Correlators}
    One important property that this has is that the integrand (which is the Lagrangian) is invariant under the map
    \begin{equation}
        \phi(x) \mapsto -\phi(x).
    \end{equation}
    In fact, we actually have a full-blown \(\unitary(1)\) symmetry
    \begin{equation}
        \phi(x) \mapsto \e^{i\alpha}\phi(x), \quad \alpha \in [0, 2\pi),
    \end{equation}
    but this is more than we need right now.
    This symmetry is important because it means that if the measure, \(\DL{\varphi}\), is also invariant under this mapping then we have
    \begin{equation}
        \correlator{\phi(z_1) \dotsm \phi(z_n)} \mapsto (-1)^n \correlator{\phi(z_1) \dotsm \phi(z_n)}
    \end{equation}
    which tells us that if \(n\) is odd then the \(n\)-point correlator must vanish.
    
    Physically, what this tells us is that there are no \(n\)-point interactions for \(n\) odd.
    An \(n\)-point interaction (in a general QFT) being some particles coming in, interacting, and some (possibly different) particles going out, such that the total number of particles going in plus the total number of particles going out is \(n\).
    The reason that there cannot be \(n\)-point interactions (\(n\) odd) for the free boson is that there are no interactions, and so it is not possible to create or destroy particles, and as such the particles going into an interaction (in which nothing can happen, because we've got free particles) must be the same particles that go out, so if we have \(k\) particles coming in we have \(k\) going out, so we have a \(2k\)-point interaction.
    
    \subsubsection{2-Point Correlators}
    Now we can use another property of functional integrals, the integral of a derivative vanishes, which tells us that
    \begin{equation}
        \label{eqn:free boson 2-correlator step 1}
        \int \diffd{}{\phi(x)} \left( \e^{-S_{\freeboson}[\phi]}\phi(y) \right) \DL\phi = 0.
    \end{equation}
    Now, we can use the product rule, chain rule, and Dirac delta properties to take the derivative and we find that
    \begin{align}
        \diffd{}{\phi(x)} \left( \e^{-S_{\freeboson}[\phi]} \phi(y) \right) &= \left( \diffd{}{\phi(x)} \e^{-S_{\freeboson}[\phi]} \right) \phi(y) + \e^{-S_{\freeboson}[\phi]} \diffd{\phi(y)}{\phi(x)}\\
        &= -\diffd{S[\phi]}{\phi(x)} \e^{-S_{\freeboson}[\phi]} \phi(y) + \e^{-S_{\freeboson}[\phi]} \delta(x - y).
    \end{align}
    Of course, we're assuming that functional derivatives of exponentials work just as they do for normal derivatives, and this is indeed the case.
    Now all we have to do is compute the derivative of \(S_{\freeboson}[\phi]\):
    \begin{equation}
        \diffd{}{\phi(x)} S_{\freeboson}[\phi] = \diffd{}{\phi(x)} \frac{1}{8\pi} \int \dl{^2\tilde{x}} \, \partial_\mu^{\tilde{x}} \phi(\tilde{x}) \partial^\mu_{\tilde{x}} \phi(\tilde{x}).
    \end{equation}
    Here we're introducing \(\tilde{x}\) as a dummy variable distinct from \(x\).
    The first step is to assume that the integral and the functional derivative commute, giving us
    \begin{equation}
        \diffd{}{\phi(x)} S_{\freeboson}[\phi] = \frac{1}{8\pi} \int \dl^2\tilde{x} \, \diffd{}{\phi(x)} [\partial_\mu^{\tilde{x}} \phi(\tilde{x}) \partial^\mu_{\tilde{x}} \phi(\tilde{x})].
    \end{equation}
    Next we apply the chain rule to get
    \begin{equation}
        \diffd{}{\phi(x)} S_{\freeboson}[\phi] = \frac{1}{8\pi} \int \dl^2\tilde{x} \, \left[ \diffd{\partial_\mu^{\tilde{x}} \phi(\tilde{x})}{\phi(x)} \partial^\mu_{\tilde{x}}\phi(\tilde{x}) + \partial_\mu^{\tilde{x}}\phi(\tilde{x}) \diffd{\partial^\mu_{\tilde{x}}\phi(\tilde{x})}{\phi(x)} \right].
    \end{equation}
    Now we assume that the partial derivatives commute with the functional derivative, so we have
    \begin{equation}
        \diffd{}{\phi(x)} S_{\freeboson}[\phi] = \frac{1}{8\pi} \int \dl^2\tilde{x} \, \left[ \left( \partial_\mu^{\tilde{x}} \diffd{\phi(\tilde{x})}{\phi(x)} \right) \partial^\mu_{\tilde{x}}\phi(\tilde{x}) + \partial_\mu^{\tilde{x}}\phi(\tilde{x}) \left(\partial^\mu_{\tilde{x}} \diffd{\phi(\tilde{x})}{\phi(x)} \right) \right].
    \end{equation}
    Now, we the derivatives \(\difsd{\phi(\tilde{x})}{\phi(x)}\) give Dirac deltas, \(\delta(\tilde{x} - x)\), and we can't really take the derivative of these.
    Instead, we use integration by parts to move the derivative onto the other term at the cost of a minus sign, giving
    \begin{align}
        \diffd{}{\phi(x)} S_{\freeboson}[\phi] &= -\frac{1}{8\pi} \int \dl^2\tilde{x} \, \left[ \diffd{\phi(\tilde{x})}{\phi(x)} \partial_\mu^{\tilde{x}}\partial^\mu_{\tilde{x}}\phi(\tilde{x}) + \partial^\mu_{\tilde{x}} \partial_\mu^{\tilde{x}} \phi(\tilde{x})  \diffd{\phi(\tilde{x})}{\phi(x)} \right]\\
        &= -\frac{1}{8\pi} \int \dl^2\tilde{x} \, \left[ \delta(\tilde{x} - x) \partial_\mu^{\tilde{x}}\partial^\mu_{\tilde{x}}\phi(\tilde{x}) + \partial^\mu_{\tilde{x}} \partial_\mu^{\tilde{x}} \phi(\tilde{x}) \delta(\tilde{x} - x) \right] \notag\\
        &= -\frac{1}{8\pi} (\partial_\mu^{x}\partial^\mu_{x}\phi(x) + \partial^\mu_{x} \partial_\mu^{x} \phi(x))\\
        &= -\frac{1}{8\pi} (\partial_\mu^{x}\partial^\mu_{x}\phi(x) + \partial_\mu^{x} \partial^\mu_{x} \phi(x))\\
        &= -\frac{1}{4\pi} \partial_\mu^x\partial^\mu_x\phi(x).
    \end{align}
    
    Using this work to compute the derivative in \cref{eqn:free boson 2-correlator step 1} we get
    \begin{equation}
        0 = \int \DL\phi \left( \frac{1}{4\pi} \phi(y) \partial_\mu^x\partial^\mu_x\phi(x) + \delta(x - y) \right) \e^{-S_{\freeboson}[\phi]}.
    \end{equation}
    This tells us that
    \begin{equation}
        \int \DL\phi \,\phi(y) \partial_\mu^x\partial^\mu_x\phi(x) \e^{-S_{\freeboson}[\phi]} = -4\pi \int \DL\phi \, \delta(x - y) \e^{-S_{\freeboson}[\phi]}.
    \end{equation}
    We can write this a bit more compactly by pulling the \(\delta(x - y)\) out of the integral, which is valid as \(\delta(x - y)\) doesn't depend on \(\phi\).
    Of course, a Dirac delta on its own doesn't make sense, so the following result only holds when we're within the integrand of some integral over \(x\) or \(y\):
    \begin{equation}
        \int \DL\phi \, \phi(y) \partial_\mu^x \partial^\mu_x\phi(x) \e^{-S_{\freeboson}[\phi]} = -4\pi \delta(x - y) \int \DL\phi \, \e^{-S_{\freeboson}[\phi]} = -4\pi\delta(x - y) Z
    \end{equation}
    where \(Z\) is the partition functional.
    If we once again assume that the integral commutes with the derivatives then we can write the left-hand side as
    \begin{multline}
        \int \DL\phi \, \phi(y) \partial_\mu^x \partial^\mu_x \phi(x) \e^{-S_{\freeboson}[\phi]}\\
        = \partial_\mu^x \partial^\mu_x \int \DL\phi \, \phi(y)\phi(x) \e^{-S_{\freeboson[\phi]}} = \partial_\mu^x\partial^\mu_x \correlator{\phi(x)\phi(y)}.
    \end{multline}
    Thus, we're left with the equality (under an integral)
    \begin{equation}\label{eqn:correlator as greens function}
        \partial_\mu^x\partial^\mu_x\correlator{\phi(x)\phi(y)} = -4\pi\delta(x - y).
    \end{equation}
    Writing \(G(x, y) = \correlator{\phi(x)\phi(y)}\) and writing out the derivatives in more detail this becomes
    \begin{equation}
        \left( \diffp[2]{}{x^1} + \diffp[2]{}{x^2} \right) G(x, y) = -4\pi\delta(x - y).
    \end{equation}
    We therefore see that \(G\) is (up to some arbitrary choice of an overall constant factor) the Green's function for Laplace's equation
    \begin{equation}
        \laplacian f = 0
    \end{equation}
    in two dimensional Euclidean spacetime.
    
    \begin{remark}{}{}
        It is a general fact in QFT that the two-point correlators are Green's functions for the differential operator, \(D\), appearing in the kinetic and mass terms when we write these two terms as \(\phi D \phi\).
        One of the first examples of this in most QFT courses is given (in Minkowski space) by adding a mass term, \(-m^2\phi^2/2\), to the Lagrangian.
        The resulting two-point correlator of the massive free scalar boson is the Green's function of the Klein--Gordon operator \(\dalembertian + m^2\), where\footnote{This operator, called the d'Alembert operator or d'Alembertian, is also written as \(\square\), and, confusingly, \(\square^2\) (in analogy with \(\laplacian\)).} \(\dalembertian = \partial^\mu \partial_\mu\) is the Laplacian operator in Minkowski space.
        The example we have here is the two-dimensional Euclidean version of this in the \(m = 0\) case.
    \end{remark}
    
    The reason that this is useful is that we\footnote{well, someone's worked it out} know what the Green's function for Laplace's equation in two-dimensions is, and so we know what the 2-point correlator is, it's
    \begin{equation}
        \correlator{\phi(x)\phi(y)} = -\ln((x^1 - y^1)^2 + (x^2 - y^2)^2) = -2\ln(\abs{x - y})^2,
    \end{equation}
    or, in complex coordinates \(z_1 = x^1 + ix^2\) and \(z_2 = y^1 + iy^2\),
    \begin{equation}
        \label{eqn:free boson 2-point correlator}
        \correlator{\phi(z_1)\phi(z_2)} = -\ln(\abs{z_1 - z_2}^2).
    \end{equation}
    
    We can check, with a bit of work, that this is indeed a solution to \cref{eqn:correlator as greens function} by integrating \cref{eqn:correlator as greens function} using Stoke's theorem.
    This is easiest to do in complex coordinates.
    To do this we'll need to use
    \begin{equation}
        \partial_\mu \partial^\mu = 4\partial_z \partial_{\overbar{z}}
    \end{equation}
    which follows from the fact that in complex coordinates the inverse metric is
    \begin{equation}
        g^{\mu\nu} = 
        \begin{pmatrix}
            0 & 2\\
            2 & 0
        \end{pmatrix}
    \end{equation}
    so
    \begin{align}
        \partial_\mu \partial^\mu &= g^{\mu\nu} \partial_\mu \partial_\nu\\
        &= g^{zz} \partial_z \partial_z + g^{z\overbar{z}} \partial_z \partial_{\overbar{z}} + g^{\overbar{z}z} \partial_{\overbar{z}} \partial_z + g^{\overbar{z}\overbar{z}} \partial_{\overbar{z}} \partial_{\overbar{z}}\\
        &= 2\partial_z \partial_{\overbar{z}} + 2\partial_{\overbar{z}} \partial_z\\
        &= 4\partial_z \partial_{\overbar{z}}.
    \end{align}
    Using this we can write \cref{eqn:correlator as greens function} as
    \begin{equation}
        \label{eqn:correlator as greens function complex coordinates}
        \partial_{z_1} \partial_{\overbar{z}_1} \correlator{\phi(z_1)\phi(z_2)} = -\pi\delta(z_1 - z_2).
    \end{equation}
    Stoke's theorem in complex coordinates is
    \begin{equation}
        \iint_D \partial_{\overbar{z}} F(z, \overbar{z}) \dd{^2z} = -\frac{i}{2} \oint_{\partial D} F(z, \overbar{z}) \dd{z}.
    \end{equation}
    The contour integral is along the boundary of \(D\) and oriented anticlockwise.
    Taking a region \(D\) containing \(z_2\) we can integrate the left hand side of \cref{eqn:correlator as greens function complex coordinates} to get
    \begin{equation}
        \iint_D \partial_{\overbar{z}_1} \partial_{z_1} \correlator{\phi(z_1)\phi(z_2)} \dd{z_1} = -\frac{i}{2}\oint_{\partial D} \partial_{z_1} \correlator{\phi(z_1)\phi(z_2)} \dd{z_1}
    \end{equation}
    and on the right we can use the Dirac delta to simply get
    \begin{equation}
        -\pi \iint_D \delta(z_1 - z_2) \dd{^2z_1} = -\pi.
    \end{equation}
    Thus, we have
    \begin{equation}
        \frac{i}{2}\oint_{\partial D} \partial_{z_1} \correlator{\phi(z_1)\phi(z_2)} \dd{z_1} = \pi.
    \end{equation}
    Now we can substitute in \cref{eqn:free boson 2-point correlator} and we have
    \begin{equation}
        \partial_{z_1} \correlator{\phi(z_1)\phi(z_2)} = - \partial_{z_1} \ln(\abs{z_1 - z_2}^2) = -\frac{2}{z_1 - z_2}
    \end{equation}
    and so we have
    \begin{equation}
        -i \oint_{\partial D} \frac{1}{z_1 - z_2} \dd{z_1} = \pi.
    \end{equation}
    This is true by Cauchy's integral formula,
    \begin{equation}
        f(a) = \frac{1}{2\pi i} \oint_{\partial D} \frac{f(z_1)}{z_1 - z_2} \dd{z_1}
    \end{equation}
    for \(f(z) = 1\).
    
    \subsubsection{4-Point Correlators}
    We can compute 4-point correlation functions now, but we won't because the 2-point correlator took long enough.
    We start again with the integral of a derivative vanishing:
    \begin{equation}
        \int \diffd{}{\phi(z_1)} (\e^{-S_{\freeboson}[\phi]} \phi(z_2) \phi(z_3) \phi(z_4)) \DD\phi = 0.
    \end{equation}
    We then compute the derivative and go through the same steps as for the 2-point correlator and we find that
    \begin{align}
        \partial_\mu^{z_1} \partial^\mu_{z_1} \correlator{\phi(z_1)\phi(z_2)\phi(z_3)\phi(z_4)} &= -\pi \delta(z_1 - z_2) \correlator{\phi(z_3)\phi(z_4)}\\
        &- \pi \delta(z_1 - z_3) \correlator{\phi(z_2)\phi(z_4)}\\
        &- \pi \delta(z_1 - z_4) \correlator{\phi(z_2)\phi(z_3)}.
    \end{align}
    This, and equations like it, are called either
    \begin{itemize}
        \item \define{Schwinger--Dyson equations}\index{Schwinger--Dyson equation}; or
        \item \define{quantum equations of motion}\index{quantum equation of motion}.
    \end{itemize}
    The second comes from identifying that the classical equations of motion, as one would find from the Euler--Lagrange equations, which come from requiring that \(\delta S[\phi] = 0\), are in this case just the usual Laplace equation, \(\partial_z \partial_{\overbar{z}} \phi = 0\).
    The quantum equations of motion then agree with this (replacing the field with the correlator) at all points, except where we have two coincident field evaluations in the correlator, where we instead get Dirac deltas.
    These are called \define{contact terms}\index{contact term}, and the physical intuition is that these infinities arise because we're trying to put two particles in the same place, allowing them to interfere with each other.
    
    We can substitute in the known 2-point correlators and we get
    \begin{align}
        \partial_\mu^{z_1}\partial^\mu_{z_1} \correlator{\phi(z_1)\phi(z_2)\phi(z_3)\phi(z_4)} &= \ln(\abs{z_1 - z_2}^2)\ln(\abs{z_3 - z_4}^2)\\
        &+ \ln(\abs{z_1 - z_3}^2)\ln(\abs{z_2 - z_4}^2)\\
        &+ \ln(\abs{z_1 - z_4}^2)\ln(\abs{z_2 - z_3}^2).
    \end{align}
    
    \subsubsection{Wick's Theorem}
    This process generalises to \(n\)-point correlators for any even \(n\), and we find that we have the following general result.
    
    \begin{thm}{Wick's Theorem For A Free Massless Scalar Boson}{}
        The \(n\)-point correlator of a free massles scalar boson field is either 0, if \(n\) is odd, or
        \begin{equation*}
            \correlator{\phi(z_1) \dotsm \phi(z_{2k})} = \sum_{\mathclap{\text{pairs } (i_\ell, j_{\ell})}} (-1)^k \ln(\abs{z_{i_1} - z_{j_1}}) \ln(\abs{z_{i_2} - z_{j_2}}) \dotsm \ln(\abs{z_{i_k} - z_{j_k}})
        \end{equation*}
        if \(n = 2k\) is even.
        The sum here is taken over ways of partitioning the indices \(\{1, \dotsc, 2k\}\) into pairs of indices with no repeated indices.
        We consider two partitions into pairs to be the same if they differ only by the order of the pairs or the order of the two indices within a pair.
    \end{thm}
    
    To demonstrate what we mean by the pairs thing in the \(n = 2\) case we simply have a single pair, \((1, 2)\), and in the \(n = 4\) case the sum has three terms, corresponding to the pairs \((1, 2)(3, 4)\), \((1, 3)(2, 4)\), and \((1, 4)(2, 3)\).
    We do not consider \((1, 2)(4, 3)\), because this is the same as \((1, 2)(3, 4)\), and we do not consider \((3, 4)(1, 2)\), because this is the same as \((1, 2)(3, 4)\).
    
    \begin{remark}{Wick Contractions and Generalisations}{}
        Noting that the logarithms here are just 2-point correlators and writing
        \begin{equation}
            \wick{\c{\phi}(z_1)\c{\phi}(z_2)} = \correlator{\phi(z_1)\phi(z_2)},
        \end{equation}
        which we call a \defineindex{Wick contraction}, it is common to write these results using this notation, for example if \(n = 4\) we write
        \begin{align}
            \correlator{\phi(z_1) \dotsm \phi(z_{4})} &= \wick{\c{\phi}(z_1)\c{\phi}(z_2)\c{\phi}(z_3)\c{\phi}(z_4)}\\
            &+ \wick{\c1{\phi}(z_1)\c2{\phi}(z_2)\c1{\phi}(z_3)\c2{\phi}(z_4)}\\
            &+ \wick{\c2{\phi}(z_1)\c1{\phi}(z_2)\c1{\phi}(z_3)\c2{\phi}(z_4)}
        \end{align}
        
        It should be noted that in the full generalisation of Wick's theorem for a non-free field there is no reason that the odd correlators should vanish.
        Instead, the odd correlators typically have some product of contracted fields, and some non-contracted fields.
        For a fully general result of \(n = 2k\) or \(n = 2k + 1\) interacting fields we have to sum over all terms with \(2\ell\) contracted fields where \(\ell = 1, \dotsc, k\).
        Because this leaves us with other fields we also have to normal order the non-contracted fields.
        This also assumes that the original fields are time ordered.
        
        In Feynman diagrams the contracted fields correspond to propagators between the points of evaluation.
        Uncontracted fields correspond to vertices.
        So in the free theory since all fields are contracted there are no vertices, which makes sense because the vertices are interactions, and all of the particles just propagate from start to end.
        The reason that we end up with multiple terms is that the particles are indistinguishable, so in the \(n = 4\) case if we assume that 1 and 2 refer to the incoming particles and 3 and 4 the outgoing particles we can't tell which of the three following diagrams in \cref{fig:swapping bosons} actually corresponds to what is actually happening.
        
        (Obligatory \enquote{in QFT Feynman diagrams aren't real, the particles aren't real, and they aren't really following nice paths on the page, instead the Feynman diagrams correspond to integrals in a big series expansion for the scattering matrix and shouldn't be interpreted physically}. Despite this everyone does think of the Feynman diagrams as physical, after all, the fields aren't really any more \enquote{real} than the particles are.)
    \end{remark}
    
    \begin{figure}
        \tikzsetnextfilename{swapping-bosons}
        \begin{tikzpicture}
            \draw [thick] (0, 6) arc (-90:90:1);
            \draw [thick] (3, 6) arc (270:90:1);
            \draw [thick] (0, 3) -- ++ (3, 0);
            \draw [thick] (0, 5) -- ++ (3, 0);
            \draw [thick] (0, 2) -- ++ (3, -2);
            \draw [line width=2mm, white] (0, 0) -- ++ (3, 2);
            \draw [thick] (0, 0) -- ++ (3, 2);
        \end{tikzpicture}
        \caption{The three ways to have two particles enter on the left and two particles leave on the right (to first order, we can have weird loops at higher order, but higher orders are hard and (usually) less relevant than first order). This corresponds to the three different ways to contract four fields.}
        \label{fig:swapping bosons}
    \end{figure}
    
    
%	 Appdendix
	\appendixpage
	\begin{appendices}
    	\chapter{Differential Geometry}
        \section{Tangent Space}
        Let \(\manifold\) be a \(d\)-dimensional manifold.
        The tangent space at \(p \in M\) is a \(d\)-dimensional vector space \(T_p\manifold\).
        One definition of this is the vector space of derivations at \(p\), where a derivation is a linear map \(D \colon C^{\infty}(\manifold) \to \reals\) satisfying
        \begin{equation}
            D(f g) = D(f) g(x) + f(x) D(g).
        \end{equation}
        Clearly derivatives are derivations, this is just the product rule, and in fact given a coordinate chart \((U, x)\) with \(p \in U\) and \(x = (x^1, \dotsc, x^d)\) we have a basis for \(T_p\manifold\) given by
        \begin{equation}
            \left\{ \diffp{}{x^1}\bigg|_p, \dotsc, \diffp{}{x^d}\bigg|_p \right\}.
        \end{equation}
        
        Once we have tangent spaces it makes sense to consider the collection of all tangent vectors at any point \(p \in \manifold\).
        This gives us the tangent bundle
        \begin{equation}
            TM = \bigsqcup_{p \in \manifold} T_pM.
        \end{equation}
        This is a bundle since we have the natural projection \(\pi \colon TM \twoheadrightarrow \manifold\) sending a tangent vector \(v \in T_pM\) to the point \(p \in M\).
        
        \section{Pushforward and Pullback}
        Let \(\varphi \colon \manifold \to \symcal{N}\) be a smooth map between manifolds.
        The \defineindex{pushforward}, also called the \defineindex{differential}, of \(\varphi\) at \(p \in \manifold\) is the linear map
        \begin{equation}
            \dl{\varphi_p} \colon T_p\manifold \to T_{\varphi(p)}\symcal{N}
        \end{equation}
        defined to act on a derivation, \(X \colon C^{\infty}(\manifold) \to \reals\), by sending it to the derivation \(\dl{\varphi_p}(X) \colon C^{\infty}(\symcal{N}) \to \reals\) defined to act on \(f \in C^{\infty}(\symcal{N})\) by
        \begin{equation}
            \dl{\varphi_p}(X)(f) = X(f \circ \varphi).
        \end{equation}
        That is, \(\dl{\varphi_p}\) is nothing but precomposition with \(\varphi\) followed by evaluation.
        
        Fix charts \((U, x)\) and \(V, y\) for neighbourhoods of \(p \in \manifold\) and \(\varphi(p) \in \symcal{N}\). s
        Then \(T_p\manifold\) and \(T_{\varphi(p)}\symcal{N}\) have bases \(\{\difsp{}{x^i}|_p\}\) and \(\{\difsp{}{y^i}|_{\varphi(p)}\}\).
        In these bases \(\dl{\varphi_p}\) may be expressed as a matrix
        \begin{equation}
            \tensor{(\dl{\varphi_p})}{^i_j} = \diffp{\varphi^i}{x^j}
        \end{equation}
        where \(\varphi^j\) is such that \(y^j = \varphi(x^j)\).
        
        The \defineindex{pullback} of \(\varphi\) is the map \(\varphi^* \colon C^{\infty}(\symcal{N}) \to C^{\infty}(\manifold)\) defined by \((\varphi^*f)(x) = f(\varphi(x))\).
        That is, \(\varphi^*\) is precomposition with \(\varphi\).
        We can also define the pullback of a \(k\)-form, \(\omega\), as
        \begin{equation}
            (\varphi^*\omega)_p(X_1, \dotsc, X_k) = \omega_{\varphi(p)}(\dl{\varphi_p}(X_1), \dotsc, \dl{\varphi_p}(X_k)).
        \end{equation}
        This will be particularly important for a 2-form, \(g\), where we have
        \begin{equation}
            (\varphi^*g)_p(X_1, X_2) = g_{\varphi(p)}(\dl{\varphi_p}(X_1), \dl{\varphi_p}(X_2)).
        \end{equation}
        
        
        \section{Riemannian Manifolds}
        A \defineindex{Riemannian manifold}, \((\manifold, g)\), is a manifold, \(\manifold\), equipped with a \defineindex{Riemannian metric}, \(g\), which assigns to each tangent space, \(T_p\manifold\), a positive-definite inner product
        \begin{equation}
            g_p \colon T_p\manifold \times T_p\manifold \to \reals,
        \end{equation}
        such that the component functions, \(g_{ij} \colon U \to \reals\), are smooth on any chart \((U, x)\).
        These components are defined for a basis \(\{e_i\}\) of \(T_p\manifold\) by
        \begin{equation}
            g_{ij} = g_p(e_i, e_j).
        \end{equation}
        These are such that
        \begin{equation}
            g = \sum_{i,j} g_{ij} \dd{x^i} \dd{x^j}
        \end{equation}
        where \(\dl{x^i}\) is the dual basis to \(\{e_i\}\), defined by \(\dl{x^i}(e_j) = \tensor{\delta}{^{i}_j}\).
    \end{appendices}

%	\backmatter
%	\renewcommand{\glossaryname}{Acronyms}
%	\printglossary[acronym]
%	\printindex
\end{document}
