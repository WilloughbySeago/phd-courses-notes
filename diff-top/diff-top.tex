% !TeX program = lualatex
\documentclass[fleqn]{NotesClass}

\strictpagecheck

\usepackage{csquotes}
\usepackage{tensor}

\usepackage{tikz}
\usetikzlibrary{external}
\tikzexternalize[prefix=tikz-external/]

\usepackage{tikz-cd}
\AtBeginEnvironment{tikzcd}{\tikzexternaldisable}
\AtEndEnvironment{tikzcd}{\tikzexternalenable}

\usepackage{pgfplots}
\pgfplotsset{compat=1.18}

\usepackage[pdfauthor={Willoughby Seago},pdftitle={Notes from differential topology},pdfkeywords={differential topology, manifold, tangent space, homology, cohomology},pdfsubject={Differential Topology}]{hyperref}  % Should be loaded second last (cleveref last)
\colorlet{hyperrefcolor}{blue!60!black}
\hypersetup{colorlinks=true, linkcolor=hyperrefcolor, urlcolor=hyperrefcolor}
\usepackage[
capitalize,
nameinlink,
noabbrev
]{cleveref} % Should be loaded last

\let\widehatold=\widehat
\AtBeginDocument{\let\widehat=\widehatold}

% My packages
\usepackage{NotesBoxes}
\usepackage{NotesMaths2}

\setmathfont[range={\int, \oint, \otimes, \oplus, \bigotimes, \bigoplus}]{Latin Modern Math}


% Highlight colour
\definecolor{highlight}{HTML}{710D78}
\definecolor{my blue}{HTML}{2A0D77}
\definecolor{my red}{HTML}{770D38}
\definecolor{my green}{HTML}{14770D}
\definecolor{my yellow}{HTML}{E7BB41}

% Title page info
\title{Differential Topology}
\author{Willoughby Seago}
\date{October 10th, 2024}
\subtitle{Notes from}
\subsubtitle{SMSTC}
\renewcommand{\abstracttext}{These are my notes from the SMSTC course \emph{Differential Topology} taught by Proff Murad Alim. These notes were last updated at \printtime{} on \today{}.}

% Commands
% Maths
\renewcommand{\dl}{\symrm{d}}
\newcommand{\id}{\symrm{id}}
\newcommand{\atlas}{\symcal{A}}
\newcommand{\torus}{\symbb{T}}
\newcommand{\isomorphic}{\cong}
\newcommand{\tangrel}[1][p]{\mathrel{\stackrel{\scriptscriptstyle #1}{\sim}}}
\newcommand{\vectorFields}{\symfrak{X}}
\DeclarePairedDelimiterX{\bracket}[2]{[}{]}{#1, #2}
\DeclareMathOperator{\Der}{Der}
\newcommand{\derivations}{\Der}
\DeclareMathOperator{\End}{End}
\newcommand{\trans}{\top}
\DeclareMathOperator{\Hom}{Hom}
\DeclarePairedDelimiterX{\innerprod}[2]{\langle}{\rangle}{#1, #2}
\ExplSyntaxOn
% Create LaTeX interface command
\NewDocumentCommand{\cycle}{ O{\,} m }{  % optional arg is separator, mandatory
    %arg is comma separated list
    (
    \willoughby_cycle:nn { #1 } { #2 }
    )
}

\clist_new:N \l_willougbhy_cycle_clist  % Create new clist variable
\cs_new_protected:Npn \willoughby_cycle:nn #1 #2 {  % create LaTeX3 function
    \clist_set:Nn \l_willougbhy_cycle_clist { #2 }  % set clist variable with
    %clist #2 passed by user
    \clist_use:Nn \l_willougbhy_cycle_clist { #1 }  % print list separated by #1
}
\ExplSyntaxOff
\makeatletter
\newcommand{\c@egory}{\symsfup}
\newcommand{\Vect}[1][\field]{\c@egory{Vect}_{#1}}
\newcommand{\Ch}[1][R]{\c@egory{Ch}_{#1}}
\newcommand{\Man}{\c@egory{Man}}
\newcommand{\ACGrAlg}[1][\field]{\c@egory{ACGrAlg}_{#1}}
\makeatother
\newcommand{\op}{\symrm{op}}
\DeclareMathOperator{\im}{im}
\newcommand{\compact}{\symrm{c}}
\newcommand{\poincareDuality}{\symrm{PD}}
\newcommand{\openCover}{\symcal{U}}
\newcommand{\derham}{\symrm{dR}}

\begin{document}
    \frontmatter
    \titlepage
    \innertitlepage{}
    \tableofcontents
    % \listoffigures
    \mainmatter
    
    \chapter{Smooth Manifolds}
    \section{Definitions in \texorpdfstring{\(\reals^n\)}{Rn}}
    \begin{dfn}{Smooth Map}{def:smooth map euclidean spaces}
        Let \(U \subseteq \reals^m\) and \(V \subseteq \reals^n\) be open sets\footnote{Here, and throughout, we assume the standard topology on Euclidean space, \(\reals^m\), so a set, \(U\), is open if and only if every point \(x \in U\) there is an open ball centred on \(x\) contained entirely within \(U\).}.
        A map \(f \colon U \to V\) is \define{smooth}\index{smooth!map of Euclidean spaces} is called \defineindex{smooth} if it is infinitely differentiable.
        That is, all partial derivatives of all orders\footnote{we take \(0 \in \naturals\)},
        \begin{equation}
            \partial^\alpha f = \frac{\partial^{\alpha_1 + \dotsb + \alpha_k}}{\partial x_1^{\alpha_1} \dotsm \partial x_k^{\alpha_k}}, \qqwhere \alpha = (\alpha_1, \dotsc, \alpha_k) \in \naturals^{k}
        \end{equation}
        exist and are continuous.
    \end{dfn}
    
    \begin{dfn}{}{def:differential of map between Rn}
        Let \(U \subseteq \reals^m\) and \(V \subseteq \reals^n\) be open sets.
        For a smooth map \(f = (f_1, \dotsc, f_n) \colon U \to V\) and a point \(x \in U\) the \defineindex{derivative}, \defineindex{differential}, or \defineindex{pushforward} of \(f\) at \(x\) is the linear map
        \begin{equation}
            f_*(x) = \dl f_x = \dl f(x) \colon \reals^m \to \reals^n
        \end{equation}
        defined by acting on \(\xi \in \reals^m\) according to
        \begin{equation}
            f_*(x)\xi = \dl f_x(\xi) = \dl(f)(x)\xi = \diff{}{t}\bigg|_{t = 0} f(x + t\xi) = \lim_{t \to 0} \frac{f(x + t\xi) - f(x)}{t}.
        \end{equation}
    \end{dfn}
    
    Fixing coordinates \(x = (x^1, \dotsc, x^m)\) the differential is represented by the Jacobian matrix
    \begin{equation}
        (\dl f(x))_{ij} = \left( \diffp{f_i}{x^j} \right) = 
        \begin{pmatrix}
            \diffp{f_1}{x^1}(x) & \dots & \diffp{f_1}{x^m}(x)\\
            \vdots & \ddots & \vdots\\
            \diffp{f_n}{x^1}(x) & \dots & \diffp{f_n}{x^m}(x)
        \end{pmatrix}
        \in \matrices[n]{m}{\reals}.
    \end{equation}
    
    The differential is defined in terms of a derivative of a function \(\reals \to \reals\) (that function is \(t \mapsto f(x + t\xi)\)), and as such has many of the properties of this derivative, including linearity and the chain rule.
    That is, if \(U \subseteq \reals^m\), \(V \subseteq \reals^n\), and \(W \subseteq \reals^p\) are open and \(f \colon U \to V\) and \(g \colon V \to W\) are smooth then the differential of \(g \circ f \colon U \to W\) at \(x \in U\) is the linear map \(\dl (g \circ f)(x) \colon \reals^m \to \reals^p\) given by
    \begin{equation}
        \dl (g \circ f)(x) = \dl g(f(x)) \circ \dl f(x).
    \end{equation}
    
    The identity map \(\id_U \colon U \to U\), given by \(x \mapsto x\), is smooth, its derivatives all vanish.
    Thus, we have
    \begin{equation}
        \dl (\id_U) (x) = \diff{}{t} \bigg|_{t = 0} \id_U(x + t\xi) = \diff{}{t} \bigg|_{t = 0} (x + t\xi) = \xi,
    \end{equation}
    and so \(\dl (\id_U)(x) = \id_{\reals^n}\).
    
    If \(f \colon U \to V\) is a \defineindex{diffeomorphism} (smooth map with smooth inverse) then for \(x \in V\) we can use the above result to get
    \begin{align}
        \dl (f \circ f^{-1})(x) = \dl \id_U(x) = \id_{\reals^n}(x) = x,
    \end{align}
    and we can use the chain rule to get
    \begin{equation}
        \dl (f \circ f^{-1})(x) = \dl f(f^{-1}(x)) \circ \dl f^{-1}(x).
    \end{equation}
    Thus, we may conclude that
    \begin{equation}
        \dl f(f^{-1}(x)) \circ \dl f^{-1}(x) = \id_{\reals^n}
    \end{equation}
    which tells us that \(\dl f(x)\) is invertible, with inverse \(\dl f(f^{-1}(x))\).
    This requires that \(m = n\).
    
    \section{Smooth Manifold}
    A smooth manifold is a space that locally looks like \(\reals^m\) for some fixed \(m\).
    
    \begin{dfn}{Smooth Manifold}{}
        A \defineindex{smooth manifold}, \((M, \atlas)\), of dimension \(m \in \naturals\), is a topological space, \(M\), equipped with an open cover, \(\{U_\alpha\}_{\alpha \in A}\) for some indexing set \(A\).
        This open cover must be equipped with a collection of homeomorphisms, \(\varphi_\alpha \colon U_\alpha \to \Omega_{\alpha}\), where \(\Omega_\alpha \subseteq \reals^m\) is open.
        These maps must be such that for any \(\alpha, \beta \in A\) the \defineindex{transition map}
        \begin{equation}
            \varphi_{\beta \alpha} \coloneq \varphi_\beta \circ \varphi_\alpha^{-1} \colon \varphi_\alpha(U_\alpha \cap U_\beta) \to \varphi_\beta(U_\alpha \cap U_\beta)
        \end{equation}
        is smooth\footnote{Note that this is a map between open subsets of \(\reals^m\), so \cref{def:smooth map euclidean spaces} applies}.
        We call the pair \((U_\alpha, \varphi_\alpha)\) a \defineindex{coordinate chart}, and the collection \(\atlas = \{(U_\alpha, \varphi_\alpha)\}_{\alpha \in A}\) is called an atlas.
    \end{dfn}
    
    The requirement that the transition maps are diffeomorphisms is why we call these manifolds \emph{smooth}.
    If we just require that they by homeomorphisms then we get the notion of a topological manifold, and if we require they're \(k\)-times differentiable we get a \(C^k\)-manifold.
    It's also possible to replace \(\reals\) with \(\complex\) in all of our previous definitions and consider complex manifolds.
    This is mostly done when we then require that the transition maps are holomorphic, and we get a holomorphic manifold.
    
    It can be shown that \(U \subseteq M\) is open if and only if \(\varphi_\alpha(U \cap U_\alpha)\) is open in \(\reals^m\) for all \(\alpha \in A\).
    Thus, the charts uniquely determine the topology on \(M\) and vice versa.
    
    If we have a homeomorphism \(\psi \colon V \to \Omega\) for \(V \subseteq M\) and \(\Omega \subseteq \reals^m\) open then we call \((\psi, V)\) \defineindex{compatible} with the atlas \(\atlas\) if the transition map \(\varphi_\alpha \circ \varphi^{-1} \colon \psi(V \cap U_\alpha) \to \varphi_\alpha(U \cap U_\alpha)\) is a diffeomorphism for all \(\alpha \in A\).
    
    We call the atlas \(\atlas\) \define{maximal}\index{maximal atlas} if it contains every chart that is compatible with all of its members.
    It can be shown that every atlas is contained in a unique maximal atlas, \(\overbar{\atlas}\).
    Sometimes it's useful to assume that an atlas is maximal, and we can always do this because adding compatible charts to an atlas doesn't change the smooth structure of the manifold.
    We can extend the notion of compatibility to whole atlases, and we say that two atlases are compatible if their union is an atlas, and in this case both induce the same smooth structure on \(M\), and the maximal atlas containing them is the same.
    
    \begin{exm}{}{}
        \begin{itemize}
            \item \(\reals^m\) is a manifold of dimension \(m\) and it has an atlas given by the single chart \((\reals^m, \id_{\reals^m})\).
            \item The sphere, \(S^n = \{(x_1, \dotsc, x_{n + 1}) \in \reals^{n+1} \mid x_1^2 + \dotsb + x_{n+1}^2 = 1\}\), is a manifold of dimension \(n\), and it is covered by two charts \((S^n \setminus \{(1, 0, \dotsc, 0)\}, s_+)\) and \((S^n \setminus \{(-1, 0, \dotsc, 0)\}, s_-)\) where \(s_+\) and \(s_-\) are stereographic projection from the points \((\pm 1, 0, \dotsc, 0)\).
            \item The \(m\)-torus, \(\torus^m \coloneqq \reals^m/\integers^m\) (with the quotient topology, and \(\integers^m\) has the discrete topology, which is also the subset topology as a subset of \(\reals^m\) with the standard topology) is a manifold.
            Two vectors \(x, y \in \reals^m\) project to the same point in \(\torus^m\) if their difference, \(x - y\), is an integer vector (that is, it's in \(\integers^m\)).
            Denote the projection by \(\pi \colon \reals^m \twoheadrightarrow \torus^m\), and this acts on \(x \in \reals^m\) by \(\pi(x) = [x] = x + \integers^m\).
            A set \(U \subseteq \torus^m\) is open if and only if \(\pi^{-1}(U)\) is open in \(\reals^m\) (this is just the definition of the quotient topology).
            An atlas on \(\torus^m\) is given by taking the \(\reals^m\)-indexed open cover
            \begin{equation}
                U_\alpha = \{[x] \mid x \in \reals^m \text{ and } \abs{x - \alpha} < 1/2\},
            \end{equation}
            and the corresponding coordinate maps \(\varphi_\alpha \colon U_\alpha \to \reals^m\) defined by
            \begin{equation}
                \varphi_\alpha([x]) = x
            \end{equation}
            for \(x \in \reals^m\) with \(\abs{x - \alpha} < 1/2\).
            This is well defined since by the construction of the \(U_\alpha\) there is only one \(x \in \reals^m\) satisfying this distance constraint.
            It can be shown that the transition maps are translation by an integer vector.
            One way to think of the quotient torus \(\reals^m/\integers^m\) is as a fixed \(1 \times 1 \times \dotsb \times 1\) cube in \(\reals^m\) with periodic boundary conditions, which we can view as the cube repeating in all directions forever.
            Then the transition maps just move us from one cube to the same point in some other cube.
            Finally, note that the torus may equivalently be defined as \(\torus^m = S^1 \times \dotsb \times S^1\) with \(m\) copies of the circle, \(S^1\), and the product topology.
            \item Fixing a smooth function \(f \colon U \to \reals^n\) from some open subset \(U \subseteq \reals^m\) the curve \(\{(x, f(x)) \in U \times \reals^n \mid x \in U\}\) is a smooth manifold.
            \item \(\generalLinear(n, \reals) \coloneqq \{A \in \matrices{n}{\reals} \mid \det A \ne 0\}\) is a smooth manifold.
            One way to show this is to realise that \(\generalLinear(n, \reals) = \det^{-1}(\reals \setminus \{0\})\).
            That is, \(\generalLinear(n, \reals)\) is the preimage of the set \(\reals \setminus \{0\}\) under the determinant.
            The determinant is a smooth map \(\reals^{n^2} \to \reals\) (note that \(\matrices{n}{\reals} \isomorphic \reals^{n^2}\) as vector spaces), since the determinant is just a polynomial in the entries in the matrix, which are the components of the vectors in \(\reals^{n^2}\).
            The set \(\reals \setminus \{0\}\) is open.
            It is known that the preimage of an open set under a smooth map is open.
            Thus, we may consider \(\generalLinear(n, \reals) \subseteq \reals^{n^2}\) as an open subset, and it is known that any open subset of \(\reals^k\) is a manifold (more generally, an open subset of a manifold is again a manifold).
        \end{itemize}
    \end{exm}
    
    One important thing about manifolds is that they have a well defined notion of dimension.
    If some space is locally homeomorphic to \(\reals^m\) in some area, but locally homeomorphic to \(\reals^n\) in another and \(m \ne n\) then it cannot be a manifold.
    For example, consider a pair of lines that cross at a point.
    Each line is a manifold on its own, but their union isn't, since we can't really define dimension in a neighbourhood of the intersection.
    
    \section{Smooth Maps}
    \begin{dfn}{Smooth Map}{}
        Let \((M, \{(U_\alpha, \varphi_\alpha)\}_{\alpha \in A})\) and \((N, \{(V_\beta, \psi_\beta)\}_{\beta \in B})\) be smooth manifolds of dimension \(m\) and \(n\) respectively.
        A \define{smooth map}\index{smooth map!between manifolds}, \(f \colon M \to N\), is a function such that for all charts \((U_\alpha, \varphi_\alpha)\) and \((V_\beta, \psi_\beta)\) the map \(\psi_\beta \circ f \circ \varphi_\alpha^{-1}\) is smooth as a map between the open sets \(\varphi_\alpha(U_\alpha) \subseteq \reals^m\) and \(\psi_\beta(V_\beta) \subseteq \reals^n\).
    \end{dfn}
    
    The idea here is that we can pass smoothness of a map between manifolds to smoothness of corresponding patches of Euclidean space, where we can use \cref{def:smooth map euclidean spaces}.
    The important thing here is that we have the commutative diagram
    \begin{equation}
        \tikzexternaldisable
        \begin{tikzcd}[column sep=small]
            & U_\alpha \arrow[rrr, "f"] \arrow[d, "\varphi_\alpha"'] &&& V_\beta \arrow[d, "\psi_\beta"]\\
            \reals^m \arrow[r, phantom, "\supseteq"] & \varphi_\alpha(U_\alpha) \arrow[rrr, "\psi_\beta \circ f \circ \varphi_\alpha^{-1}"'{yshift=-0.05cm}] &&& \psi_\beta(V_\beta) \arrow[r, phantom, "\subseteq"] & \reals^n
        \end{tikzcd}
        \tikzexternalenable
    \end{equation}
    
    \section{Tangent Space}
    The tangent space to a manifold is most immediate when we view that manifold as a subset of \(\reals^n\).
    For example, the tangent space to the circle, \(S^1\), at some point \(p\) is just the tangent line to that point.
    This line is a copy of \(\reals\), and so comes with lots of structure, and in particular is a vector space.
    If we go up a dimension we can consider the sphere, \(S^2\), and the tangent space at some point \(p\) is the tangent plane at that point.
    This plane is a copy of \(\reals^2\), and is, again, a vector space.
    
    The formal definition of the tangent space just formalises this by defining the tangent space to be the space of all tangent curves through \(p\).
    
    \begin{dfn}{Tangent Space}{}
        Let \((M, \{(U_\alpha, \varphi_\alpha)\}_{\alpha \in A})\) be a smooth manifold.
        Fix some point \(p \in M\).
        The tangent space of \(M\) at \(p\) is the quotient space
        \begin{equation}
            T_pM \coloneqq \bigsqcup_{\alpha \text{ s.t. }p \in U_\alpha} \reals^m / {\tangrel}.
        \end{equation}
        Here we use the disjoint union, but we could instead use the normal union and explicitly label each point in \(\reals^m\) with \(\alpha\) from the corresponding term in the union:
        \begin{equation}
            T_pM = \bigcup_{\alpha \text{ s.t. } p \in U_\alpha} (\{\alpha\} \times \reals^m)/{\tangrel}.
        \end{equation}
        Then the corresponding equivalence relation is
        \begin{equation}
            (\alpha, \xi) {\tangrel} (\beta, \eta) \iff \dl(\varphi_\beta \circ \varphi_\alpha^{-1})(x)\xi = \eta, \quad x = \varphi_\alpha(p).
        \end{equation}
        That is, two pairs \((\alpha, \xi)\) and \((\beta, \eta)\) are equivalent if one is the pushforward of the other along the transition maps.
        The equivalence class of \((\alpha, \xi) \in A \times \reals^m\) with \(p \in U_\alpha\) is denoted \([\alpha, \xi]_p\).
    \end{dfn}
    
    This quotient space, \(T_pM\), is a real vector space of dimension \(m\).
    
    \begin{exm}{}{}
        Consider the circle, \(S^1 = \{(x, y) \in \reals^2 \mid x^2 + y^2 = 1\}\), with the charts \(U_{\pm} = S^1 \setminus \{(0, \mp 1)\}\) where
        \begin{equation}
            \varphi_+(x, y) = \frac{x}{1 + y}, \qand \varphi_-(x, y) = \frac{x}{1 - y}.
        \end{equation}
        We have
        \begin{equation}
            \varphi_-^{-1}(t) = \left( \frac{2t}{t^2 + 1}, \frac{t^2 - 1}{t^2 + 1} \right), \qand \varphi_+^{-1}(t) = \left( \frac{2t}{t^2 + 1}, \frac{1 - t^2}{t^2 + 1} \right).
        \end{equation}
        
        Take the point \(p = (\sqrt{3}/2, 1/2) \in S^1\).
        Then we have
        \begin{equation}
            \varphi_-(p) = \sqrt{3}, \quad \varphi_+(p) = \frac{1}{\sqrt{3}}.
        \end{equation}
        The transition maps are
        \begin{equation}
            \varphi_+ \circ \varphi_-^{-1}(t) = \frac{1}{t} = \varphi_- \circ \varphi_+^{-1}(t).
        \end{equation}
        
        Consider the pair \((-, q) \in A \times \reals\) where \(A = \{{+}, {-}\}\) is the index set of the chart and \(\reals\) is the one-dimensional vector space corresponding to the tangent space to the one-dimensional manifold \(S^1\).
        What is the equivalence class of \((-, q)\) in the tangent space at \(p\)?
        That is, what is \([-, q]_p\)?
        
        To compute this we take the definition of the equivalence relation, that \((-, q) \tangrel (+, \tilde{q})\) if and only if
        \begin{equation}
            \dl (\varphi_+ \circ \varphi_-^{-1})(x)q = \tilde{q}
        \end{equation}
        where \(x = \varphi_-(p) = \sqrt{3}\).
        Then we are looking for some real number, \(\tilde{q}\), given by evaluating
        \begin{equation}
            \dl(\varphi_+ \circ \varphi_-^{-1})(\sqrt{3})q.
        \end{equation}
        Using the definition of the differential we have that
        \begin{align}
            \dl(\varphi_+ \circ \varphi_-^{-1})(x)q &= \diff{}{t}\bigg|_{t=0} \varphi_+ \circ \varphi_-^{-1}(x + tq)\\
            &= \diff{}{t}\bigg|_{t=0} \frac{1}{x + tq}\\
            &= -\frac{q}{(x + tq)^2}\bigg|_{t = 0}\\
            &= -\frac{q}{x^2}
        \end{align}
        and so taking \(x = \sqrt{3}\) we get
        \begin{equation}
            \dl(\varphi_+ \circ \varphi_-^{-1})(\sqrt{3})q = -\frac{q}{3}.
        \end{equation}
        So, \((-, q) \tangrel (+, -q/3)\), and so
        \begin{equation}
            [-, q]_p = \{(-, q), (+, -q/3)\}.
        \end{equation}
        Thus, the tangent space to the circle at \(p = (\sqrt{3}/2, 1/2)\) is
        \begin{align}
            T_{(\sqrt{3}/2, 1/2)}S^1 &= \{[-, q]_{(\sqrt{3}/2, 1/2)} \mid p \in \reals\}\\
            &= \{\{(-, q), (+, -q/3)\} \mid p \in \reals\}.
        \end{align}
    \end{exm}
    
    Often we want to consider all of the tangent spaces at once.
    To do this we construct the tangent bundle.
    
    \begin{dfn}{Tangent Bundle}{}
        The \defineindex{tangent bundle} of a manifold \(M\) is
        \begin{equation}
            TM \coloneqq \bigsqcap_{p \in M} T_pM.
        \end{equation}
    \end{dfn}
    
    The tangent bundle of an \(m\)-dimensional smooth manifold is a \(2m\)-dimensional smooth manifold in a way that we shall define later once we have some more machinery.
    
    \section{Derivatives}
    Suppose that we have two smooth manifolds, \((M, \{(U_\alpha, \varphi_\alpha)\}_{\alpha \in A})\) and \((N, \{(V_\beta, \psi_B	)\}_{\beta \in B})\), of dimensions \(m\) and \(n\) respectively, and a smooth map \(f \colon M \to N\).
    Can we construct a map
    \begin{equation}
        T_pM \to T_{f(p)}N?
    \end{equation}
    The answer is yes, and to derive\footnote{no pun intended} a sensible definition of this map we should look at what maps we really have available to us.
    
    The map we're after is \([\alpha, \xi]_p \mapsto [\beta, \eta]_{f(p)}\), we just need to specify what \(\eta\) is, it should in general depend on \(\xi\), \(\alpha\), \(\beta\), \(p\), and \(f\).
    Note that it only makes sense to consider \(\alpha\) and \(\beta\) such that \(p \in U_\alpha\) and \(f(p) \in V_\beta\), and we may further assume that \(p\) has a neighbourhood that is contained entirely in \(V_\beta\), so we'll assume that \(f(U_\alpha) \subseteq V_\beta\).
    
    The maps we have involving the manifolds directly may be summarised in the following diagram:
    \begin{equation}
        \tikzexternaldisable
        \begin{tikzcd}[column sep=2.5cm]
            U_\alpha \arrow[r, "f"] \arrow[d, "\varphi_\alpha"'] & V_\beta \arrow[d, "\psi_\beta"]\\
            \varphi_\alpha(U_\alpha) \arrow[r, "\psi_\beta \circ f \circ \varphi_\alpha^{-1} = f_{\beta\alpha}"'] & \psi_\beta(V_\beta)\mathrlap{.}
        \end{tikzcd}
        \tikzexternalenable
    \end{equation}
    The action of these maps is
    \begin{equation}
        \tikzexternaldisable
        \begin{tikzcd}
            p \arrow[r, mapsto] \arrow[d, mapsto] & f(p) \arrow[d, mapsto]\\
            \varphi_\alpha(p) \arrow[r, mapsto] & \psi_\beta(f(p))\mathrlap{.}
        \end{tikzcd}
        \tikzexternalenable
    \end{equation}
    The map \(f_{\beta\alpha}\) is between an open subset of \(\reals^m\) and an open subset of \(\reals^n\).
    This allows us to consider its differential, \(\dl f_{\beta\alpha}\), as defined in \cref{def:differential of map between Rn}.
    That is, we have the map
    \begin{equation}
        \dl f_{\beta\alpha}(x) \colon \reals^m \to \reals^n.
    \end{equation}
    So, given some \(x \in \reals^m\), we can define \(\eta\) to be \(\dl f_{\beta\alpha}(x)\xi\).
    The only question then is what \(x\) should we use.
    The only piece of data we haven't yet used is \(p\), so we should take \(x = \varphi_\alpha(p)\).
    This leads to us defining
    \begin{equation}
        \eta = \dl f_{\beta\alpha}(\varphi_\alpha(p))\xi.
    \end{equation}
    
    \begin{dfn}{Derivative}{}
        Let \((M, \{(U_\alpha, \varphi_\alpha)\}_{\alpha \in A})\) and \((N, \{(V_\beta, \psi_B	)\}_{\beta \in B})\) be smooth manifolds, and let \(f \colon M \to N\) be a smooth map.
        We define the \defineindex{derivative}, \defineindex{differential}, or \defineindex{pushforward} of \(f\) at \(p\) as the linear map
        \begin{equation}
            f_*(p) = \dl{f}_p = \dl{f}(p) \colon T_pM \to T_{f(p)}N 
        \end{equation}
        given by
        \begin{equation}
            \dl{f}(p)[\alpha, \xi]_p \coloneqq [\beta, \dl{f_{\beta\alpha}}(\varphi_\alpha(p))\xi]_{f(p)}
        \end{equation}
        where \(p \in U_\alpha\) and \(f(p) \in V_\beta\) and \(f_{\beta\alpha} = \psi_\beta \circ f \circ \varphi_\alpha^{-1}\).
        Note that \(\dl{f_{\beta\alpha}}\) is as defined in \cref{def:differential of map between Rn}.
    \end{dfn}
    
    \begin{exm}{}{exm:derivative of map into Rn}
        Consider the special case of the derivative when \(N = (\reals^n, \{(\reals^n, \id_{\reals^n})\})\) is \(\reals^n\) with a single chart.
        This means that the indexing set for charts on \(N\) is the singleton, \(B = \{\bullet\}\).
        Then for \(q \in N\) we can identify \([\bullet, \eta]_q \in T_qN\) with \(\eta \in \reals^n\), since there's only one label \(\bullet\), giving us a canonical isomorphism \(T_qN \isomorphic \reals^n\).
        If \(f \colon M \to N\) is smooth in this case, given \(p \in M\) and \([a, \xi]_p \in T_pM\), we have the derivative
        \begin{equation}
            \dl{f}(p)[a, \xi]_p = [\bullet, \dl{f_{\beta\alpha}}(\varphi_\alpha(p))\xi]_{f(p)}.
        \end{equation}
        Using this canonical isomorphism we identify this with
        \begin{equation}
            \dl{f}(p)[a, \xi]_p = \dl{f_{\bullet\alpha}}(\varphi_\alpha(p))\chi.
        \end{equation}
        This further simplifies since \(f_{\bullet\alpha} = \psi_\bullet \circ f \circ \varphi_\alpha^{-1} = \id_{\reals^n} \circ f \circ \varphi_\alpha^{-1} = f \circ \varphi_\alpha^{-1}\), and so, after identifying \(T_{f(p)}N\) and \(\reals^n\), we have
        \begin{equation}
            \dl{f}(p)[a, \xi]_p = \dl{(f \circ \varphi_\alpha^{-1})}(\varphi_\alpha(p))\xi.
        \end{equation}
        Once \(f\) is known this can be calculated using \cref{def:differential of map between Rn}.
    \end{exm}

    \begin{exm}{}{}
        We can apply this formula to maps defined on just an open subset of \(M\), rather than all of \(M\).
        The most important case of this is when the smooth map in consideration is a chart map, \(f = \varphi_{\tilde{\alpha}} \colon U_{\tilde{\alpha}} \to \reals^m\).
        In this case we may still identify \(N\) as \((\reals^n, \{(\reals^n, \id_{\reals^m})\})\), and so the results of \cref{exm:derivative of map into Rn} apply.
        In particular, after identifying \(T_{\varphi_{\tilde{\alpha}}}N\) with \(\reals^n\) we have
        \begin{equation}
            \dl{\varphi_{\tilde{\alpha}}}(p)[\alpha, \xi]_p = \dl{(\varphi_{\tilde{\alpha}} \circ \varphi_\alpha^{-1})}(\varphi_\alpha(p))\xi.
        \end{equation}
        This isn't that interesting, unless we take \(\alpha = \tilde{\alpha}\), then we have
        \begin{align}
            \dl{\varphi_\alpha}(p)[\alpha, \xi]_p &= \dl{(\varphi_\alpha\circ \varphi_\alpha^{-1})}(\varphi_\alpha(p))\xi\\
            &= \diff{}{t}\bigg|_{t=0} (\varphi_\alpha \circ \varphi_\alpha^{-1})(\varphi_\alpha(p) + t\xi)\\
            &= \diff{}{t}\bigg|_{t=0} \id(\varphi_\alpha(p) + t\xi)\\
            &= \diff{}{t}\bigg|_{t=0} (\varphi_\alpha(p) + t\xi)\\
            &= \xi.
        \end{align}
        This allows us to identify \([\alpha, \xi]_p \in T_pM\) with \(\xi \in \reals^m\), giving an isomorphism \(T_pM \isomorphic \reals^m\).
        So, \(\dl{\varphi_\alpha}\) is the canonical vector space isomorphism determined by \(\alpha\).
    \end{exm}
    
    \begin{ntn}{}{}
        Let \(\{e_i\}_{i \in \{1, \dotsc, m\}}\) be the standard basis for \(\reals^m\).
        Then for the tangent vector \([\alpha, e_i]_p \in T_pM\) we write
        \begin{equation}
            [\alpha, e_i]_p = \diffp{}{x^i}(p) = \diffp{}{x^i}\bigg|_p.
        \end{equation}
        This is (for now) just notation, we're not thinking of these as derivatives.
        We'll see why this is a sensible notation shortly.
    \end{ntn}
    
    \section{Submersions, Immersions, and Embeddings}
    In this section we state some definitions and results which are standard in the theory of smooth manifolds, but for which we will have little use.
    
    \begin{dfn}{Submersion}{}
        A \defineindex{submersion} of a smooth manifold, \(M\), in a smooth manifold, \(N\), is a smooth map, \(f \colon M \to N\), whose derivative, \(\dl{f}\), exists and is a surjective linear map
        \begin{equation}
            \dl{f}(p) \colon T_pM \to T_{f(p)}N
        \end{equation}
        for all \(p \in M\).
        
        Points \(p \in M\) at which \(\dl{f}(p)\) is a surjective linear map are called \define{regular points}\index{regular point}.
        So, a submersion is a map for which every \(p \in M\) is regular.
    \end{dfn}
    
    \begin{dfn}{Immersion}{}
        An \defineindex{immersion} of a smooth manifold, \(M\), in a smooth manifold, \(N\), is a smooth map, \(f \colon M \to N\), whose derivative, \(\dl{f}\), exists and is an injective linear map
        \begin{equation}
            \dl{f}(p) \colon T_pM \to T_{f(p)}N
        \end{equation}
        for all \(p \in M\).
        
        If an immersion is also a topological embedding, meaning that \(f(M)\) (with the subspace topology in \(N\)) is homeomorphic to \(M\), then we call \(f\) an \defineindex{embedding}.
    \end{dfn}
    
    The notion of an embedding uses the fact that \(f(M)\) is a topological space in its own right, and in fact, it's a manifold in its own right.
    This leads to the notion of a submanifold.
    
    \begin{dfn}{Submanifold}{}
        An \defineindex{embedded submanifold} of \(M\) is a subset, \(S \subseteq M\), which is itself a manifold and for which the inclusion \(S \hookrightarrow M\) is an embedding.
        
        More explicitly, \(S\) is a topological space in the subspace topology such that for every \(p \in S\) there exists a neighbourhood, \(U_\alpha\), of \(p \in M\) making a chart \((U_\alpha, \varphi_\alpha \colon U_\alpha \to \Omega_\alpha \subseteq \reals^m)\) (in some maximal atlas for \(M\)) such that \(S \cap U_\alpha = \varphi_\alpha^{-1}(\reals^k \cap \Omega_\alpha)\) for some fixed \(k \in \naturals\), which is the dimension of the submanifold, \(S\).
        Note that there is some freedom in how we embed \(\reals^k\) in \(\reals^m\) in order to take this intersection, and in general we only require that there is an embedding that makes this work, not that it works for all embeddings.
    \end{dfn}
    
    There is a weaker notion of an immersed submanifold in which the inclusion is merely required to be an immersion.
    
    A classic example of a submanifold is a smooth curve on some surface.
    This will correspond to the intersection \(\reals \cap \Omega_\alpha\).
    
    \begin{thm}{Regular Value Theorem}{}
        If \(f \colon M \to N\) is a smooth map of manifolds then \(f^{-1}(y)\) (that is, the preimage of some point \(y \in N\)) is a smooth submanifold of \(M\) for every \(y \in N\) if \(y\) is a regular value.
    \end{thm}
    
    \chapter{Vector Fields}
    \section{Definitions}
    \begin{dfn}{Vector Field}{}
        Let \(M\) be a smooth manifold.
        A \defineindex{vector field} on \(M\) is an assignment of a tangent vector, \(X(p) \in T_pM\), to each \(p \in M\).
        Thus, a vector field on \(M\) is a map \(X \colon M \to TM\) such that \(X(p) = X_p \in T_pM\) for all \(p \in M\).
    \end{dfn}
    
    \begin{exm}{}{exm:vector fields on Rn}
        Consider a chart \((U_\alpha, \varphi_\alpha \colon U_\alpha \to \Omega_\alpha \subseteq \reals^m)\) for the manifold \(M\).
        Let \(X\) be a vector field on \(M\).
        For each chart index, \(\alpha\), there is a corresponding vector field, \(X_\alpha \colon \Omega_\alpha \to \reals^m\) (identifying each \(T_pM\) with \(\reals^m\)), defined by
        \begin{equation}
            X_\alpha(\varphi_\alpha(p)) = \dl{\varphi_\alpha}(X(p)).
        \end{equation}
        Note that this is a vector field on \(\Omega_\alpha\) viewed as a submanifold of \(\reals^m\).
    \end{exm}
    
    \begin{dfn}{Smooth Vector Field}{}
        Let \(M\) be a manifold and \(X\) a vector field on \(M\).
        Then \(X\) is a \defineindex{smooth vector field} if \(X_\alpha\) (as defined in \cref{exm:vector fields on Rn}) is a smooth map between subsets of Euclidean space.
        Equivalently, \(X\) is smooth if \(X \colon M \to TM\) is a smooth map between manifolds.
        
        The set of all smooth vector fields on \(M\) is denoted \(\vectorFields(M)\). 
    \end{dfn}
    
    Since \(X \colon M \to TM\) takes values in \(T_pM \isomorphic \reals^m\) we inherit a lot of structure from \(\reals^m\).
    In particular, we can define pointwise addition,
    \begin{equation}
        (X + Y)(p) = X(p) + Y(p),
    \end{equation}
    and scalar multiplication,
    \begin{equation}
        (\lambda X)(p) = \lambda \mkern2mu X(p),
    \end{equation}
    for \(X, Y \in \vectorFields(M)\) and \(\lambda \in \reals\), and the results are still smooth vector fields.
    Since we also have the zero vector field, defined by \(0(p) = 0 \in \reals^m\), and negation (take \(\lambda = -1\)) we can easily see that \(\vectorFields(M)\) is a real vector space.
    
    Further, we can define multiplication by a smooth function, \(f \in C^{\infty}(M)\), by
    \begin{equation}
        (fX)(p) = f(p) X(p),
    \end{equation}
    and the result is again a smooth vector field.
    This is a bit like scaling, but now we scale by a different amount at each point of the manifold.
    This, combined with addition of vector fields tells us is that \(\vectorFields(M)\) is a \(C^{\infty}(M)\)-module.
    The vector space structure is then a special case where we restrict only to constant functions in \(C^{\infty}(M)\).
    
    \begin{exm}{}{}
        Let \(\{e_i\}_{i \in \{1, \dotsc, m\}}\) be the standard basis of \(\reals^m\).
        Let \(M\) be an \(m\)-dimensional smooth manifold with coordinate chart \((U_\alpha, \varphi_\alpha \colon U_\alpha \to \Omega_\alpha \subseteq \reals^m)\).
        We can define a vector field on \(U_\alpha\),
        \begin{equation}
            \diffp{}{x^i} \colon U_\alpha \to TM,
        \end{equation}
        by taking
        \begin{equation}
            \diffp{}{x^i}(p) = [\alpha, e_i]_p.
        \end{equation}
        This is such that
        \begin{equation}
            (\dl{\varphi_\alpha}(p))\left( \diffp{}{x^i}(p) \right) = e_i
        \end{equation}
        for all \(p \in U_\alpha\).
        Since \(\dl{\varphi_\alpha}(p)\) is always an isomorphism \(T_pM \to \reals^m\) we see that \(\{\difsp{}{x^i}(p)\}_{i\in \{1, \dotsc, m\}}\) is a basis for \(T_pM\), since it's mapped to a basis by an isomorphism.
        We call \(\{\difsp{}{x^i}\}_{i \in \{1,\dotsc, m\}}\) a local \defineindex{frame} on \(U_\alpha\), since it assigns to each point a basis vector.
        
        We write \(e_i\) for the constant vector field that assigns to each point in \(M\) the constant vector \(e_i \in T_pM\).
        We may then express any constant vector field as \(\sum_i X^ie_i\) for some real constants \(X^i\), and any smooth vector field as \(\sum_i X^i e_i\) where the \(X^i\) are smooth functions \(M \to \reals\).
    \end{exm}
    
    \section{Algebras}
    \begin{dfn}{Algebra}{}
        An \defineindex{algebra} over a field, \(\field\), is a vector space, \(A\), equipped with a bilinear map \(\cdot \colon A \times A \to A\).
    \end{dfn}
    
    \begin{dfn}{Derivation}{}
        If \(A\) is an algebra then a \defineindex{derivation} is a linear map \(D \colon A \to A\) satisfying the \defineindex{Leibniz rule} for all \(a, b \in A\):
        \begin{equation}
            D(a \cdot b) = D(a) \cdot b + a \cdot D(b).
        \end{equation}
    \end{dfn}
    
    The classic example of a derivation is, of course, a derivative acting on some algebra of functions, such as \(C^{\infty}(\reals)\), where the Leibniz rule is exactly the product rule.
    
    \begin{dfn}{Lie Algebra}{}
        A \defineindex{Lie algebra}, \(\lie{g}\), is a vector space over \(\field\), equipped with a bilinear map, \(\bracket{-}{-} \colon \lie{g} \times \lie{g} \to \lie{g}\), which is alternating, meaning \(\bracket{x}{x} = 0\) for all \(x \in \lie{g}\), and the Jacobi identity, that for all \(x, y, z \in \lie{g}\)
        \begin{equation}
            \bracket{x}{\bracket{y}{z}} + \bracket{y}{\bracket{z}{x}} + \bracket{z}{\bracket{x}{y}} = 0.
        \end{equation}
        
        A homomorphism of Lie algebras is a linear map \(\varphi \colon \lie{g} \to \lie{h}\) which preserves the bracket, so \(\varphi(\bracket{x}{y}) = \bracket{\varphi(x)}{\varphi(y)}\).
    \end{dfn}
    
    Let \(V\) be a vector space, then \(\End V\) is a Lie algebra where we define the bracket by \(\bracket{\varphi}{\psi} = \varphi \circ \psi - \psi \circ \varphi\).
    Let \(A\) be an algebra and write \(\derivations A\) for the subset of \(\End A\) consisting of derivations.
    Then it can be shown that \(\derivations A\) is a subalgebra of the Lie algebra \(\End A\).
    To do so one only needs to show that the commutator of two derivations is again a derivation.
    
    \begin{thm}{}{}
        Write \(\derivations(C^{\infty}(M))\) for the Lie algebra of derivations of the algebra of smooth functions. There is an isomorphism of \(C^{\infty}(M)\)-modules, \(\Phi \colon \vectorFields(M) \to \derivations(\complex^{\infty}(M))\), and this equips \(\vectorFields(M)\) with a natural Lie algebra structure.
        \begin{proof}
            Let \(\Omega \subseteq \reals^m\) be open and \(p \in \Omega\).
            Let \(X = \sum_i X^i e_i\) be a smooth vector field on \(\Omega\) expressed in the standard basis.
            Let \(f \colon \Omega \to \reals\) be a smooth function.
            We define another smooth function, \(\partial_Xf\), on \(\Omega\) by
            \begin{align}
                (\partial_X f)(p) &= \dl{f}_p(X_p)\\
                &= \dl{f}_p\left( {\textstyle\sum_i} X^i(p)e_i(p) \right)\\
                &= \sum_{i=1}^m \diffp{f}{x^i}(p) X^i(p).
            \end{align}
            This is smooth since it's a product of smooth functions \(\difsp{f}{x^i}, X^i \colon \Omega \to \reals\).
            Further, the map \(f \mapsto \partial_X f\) is a derivation on \(C^{\infty}(\Omega)\), since we have
            \begin{equation}
                \partial_X(fg) = \dl{(fg)}X = f \dd{g}X + g \dd{f}X = f\partial_Xg + g\partial_Xf.
            \end{equation}
            Now taking \(X\) to be a vector field on some smooth manifold, \(M\), and \(f \in C^{\infty}(M)\) we can define \(\partial_Xf(p) = \dl{f_p}X_p\), which we may also write as\(\partial_{X_p}f\).
            The map \(\Phi \colon \vectorFields(M) \to \derivations(C^{\infty}(M))\) defined by \(X \mapsto \partial_X\) is a morphism of \(C^{\infty}(M)\)-modules \(\vectorFields(M) \to \derivations(C^{\infty}(M))\).
            
            It can be shown that \(\Phi\) is in fact an isomorphism.
        \end{proof}
    \end{thm}
    
    Using this result it is standard to identify a smooth vector field, \(X\), with the corresponding derivation\footnote{In fact, this is a standard way to define a vector field, and then one proves the above in reverse.}, \(\partial_X \in \derivations(C^{\infty}(M))\).
    Note that every tangent vector at a point, \(X_p\), defines a linear map \(\partial_{X_p} \colon C^{\infty}(M) \to \reals\) satisfying
    \begin{equation}
        \partial_{X_p}(fg) = g(p) \partial_{X_p}(f) + f(p) \partial_{X_p}(g),
    \end{equation}
    which is almost the Leibniz rule, except for the fact that \(\partial_{X_p}\) isn't an endomorphism.
    
    \chapter{Integral Curves and Lie Groups}
    \section{Integral Curves}

    Consider the vector field \(X \in \vectorFields(\reals^2)\) given by
    \begin{equation}
        X(x, y) = 
        \begin{pmatrix}
            -y\\ x
        \end{pmatrix}
    \end{equation}
    which is interpreted as an element of \(T_{(x, y)}\reals^2 \isomorphic \reals^2\).
    If we attach \(X(x, y)\) to the point \((x, y)\) for some number of points we get an image like \cref{fig:vector field example}.
    This is why we call these vector fields.
    
    Notice that every arrow is tangent to a circle centred on the origin of radius \(\sqrt{x^2 + y^2}\).
    
    \begin{figure}
        \tikzsetnextfilename{vector-field-example}
        \begin{tikzpicture}
            \begin{axis}[%
                view     = {0}{90}, % for a view 'from above'
                domain   = -6:6,
                y domain = -6:6,
                xtick    = {0},
                ytick    = {0},
                ]
                \addplot3[highlight, quiver={u=y, v=-x, scale arrows=0.1}, samples=16, -latex] (x, y, 0);
            \end{axis}
        \end{tikzpicture}
        \caption[Example of a vector field]{The vector field \(X \in \vectorFields(\reals^2)\) given by \(X(x, y) = (-y\ x)^{\trans}\).}
        \label{fig:vector field example}
    \end{figure}
    
    \begin{dfn}{}{}
        A smooth \defineindex{path} on a manifold, \(M\), is a smooth map \(c \colon \reals \to M\).
    \end{dfn}
    
    What we see here is that the vectors in the vector field \(X\) are all tangent to the smooth curve defined by
    \begin{equation}
        c(t) =
        \begin{pmatrix}
            r \cos t\\ r \sin t
        \end{pmatrix}
        .
    \end{equation}
    
    \begin{prp}{}{}
        Let \(M\), \(N\), and \(O\) be smooth manifolds and let \(f \colon M \to N\) and \(g \colon N \to O\) be smooth maps.
        Then for \(x \in M\) we have
        \begin{equation}
            \dl (g \circ f)_x = \dl{g}_{f(x)} \circ \dl{f}_x.
        \end{equation}
    \end{prp}
    
    If \(c\) is a path we can relate the tangent vector at 0, that is \(V = \dot{c}(0)\), to the corresponding derivation by
    \begin{equation}
        \partial_V f = \dl{f}_{c(0)}(V) = \dl{f}_{c(0)}\left( \dl{c}_0\left( \diffp{}{t} \right) \right) = \dl{(f \circ c)}_0 \left( \diffp{}{t} \right) = (f \circ c)'(0).
    \end{equation}
    
    \begin{dfn}{Local Integral Curve}{}
        Let \(M\) be a smooth manifold and let \(X \in \vectorFields(M)\) be a smooth vector field on \(M\).
        A \defineindex{local integral curve} of \(X\) through \(p \in M\) is a local path \(c \colon (-\varepsilon, \varepsilon) \to M\) (for some \(\varepsilon > 0\)) such that \(c(0) = p\) and \(\dot{c}(t) = X_{c(t)}\) for all \(t \in (-\varepsilon, \varepsilon)\).
    \end{dfn}
    
    Note that for a smooth curve, \(c \colon \reals \to M\) with \(c(0) = p \in M\) the derivative \(\dot{c}(0) \in T_pM\) is defined to be the equivalence class
    \begin{equation}
        \dot{c}(0) = \left[ \alpha, \diff{}{t}\bigg|_{t=0}\varphi_\alpha(c(t)) \right]_p.
    \end{equation}
    The vector \(\dot{c}(0) \in T_pM\) is then the image of the vector \(1 \in T_0\reals = \reals\) under the linear map \(\dl{c}_0 \colon T_0 \reals \to T_{p}M\).
    
    Every \(p \in M\) and \(v \in T_pM\) has a corresponding smooth curve \(c \colon \reals \to M\) such that \(c(0) = p\) and \(\dot{c}(0) = v\).
    To see this take some coordinate chart \(\varphi_\alpha \colon U_\alpha \to \Omega_\alpha\) such that \(p \in U_\alpha\), and define \(x = \varphi_\alpha(p)\) and \(\xi = \dl{\varphi_\alpha}_p(v)\).
    Take some constant \(\varepsilon > 0\) such that \(x + t\xi \in \Omega_\alpha\) for all \(t \in (-\varepsilon, \varepsilon)\).
    Then we may define \(c\) by
    \begin{equation}
        c(t) = \varphi_\alpha^{-1}\left( x + \frac{\varepsilon t}{\sqrt{\varepsilon^2 + t^2}} \right)
    \end{equation}
    for \(t \in \reals\) and this has the desired property.
    
    \begin{prp}{}{}
        Let \(M\) be a smooth manifold and \(X \in \vectorFields(M)\) a smooth vector field.
        Then the following hold:
        \begin{enumerate}
            \item For every \(p \in M\) there exists some \(\varepsilon > 0\) such that for every \(\delta \le \varepsilon\) there exists a unique integral curve of \(X\) through \(p\) defined on \((-\delta, \delta)\).
            \item For every \(p \in M\) there exists an open neighbourhood, \(U_p\), of \(p\) and \(\varepsilon > 0\) such that the integral curve of \(X\) through every \(q \in U_p\) is defined for \(t \in (-\varepsilon, \varepsilon)\).
            \item For \(p \in M\) let \(U_p\) and \(\varepsilon\) be as in the previous point.
            If \(t < \varepsilon\) we define the map \(\varphi_t \colon U_p \to M\) by \(\varphi_t(q) = c_q(t)\) where \(c_q\) is the integral curve of \(X\) through \(q\).
            Then we have
            \begin{equation}
                \varphi_t \circ \varphi_s = \varphi_{s + t}
            \end{equation}
            for all \(t, s, s + t \in (-\varepsilon, \varepsilon)\) on whatever open set this composite is defined on.
            \item For every \(t < \varepsilon\) the local map \(\varphi_t\) is a local diffeomorphism.
        \end{enumerate}
    \end{prp}
    
    We call a family, \(\{\varphi_t\}\), of local diffeomorphisms satisfying \(\varphi_t \circ \varphi_s = \varphi_{t + s}\) a one-parameter pseudogroup of local diffeomorhpisms of \(M\).
    It's like a group, but sometimes the composite isn't defined.
    
    \section{Lie Groups and Lie Algebras}
    \begin{dfn}{}{}
        A group, \(G\), which is also a smooth manifold for which the multiplication map, \(\mu \colon G \times G \to G\), \(\mu(g, h) = gh\), and inverse map, \(\iota \colon G \to G\), \(\iota(g) = g^{-1}\), are smooth is called a Lie group.
    \end{dfn}
    
    For a Lie group, \(G\), define \(L_g, R_g \colon G \to G\) to be left and right multiplication by \(g\), that is \(L_g(h) = gh\) and \(R_g(h) = hg\).
    We call these left and right translation, because we view them as shifting the manifold around by some amount \(g\), the canonical example being \(G = \reals^n\) with addition as the group operation, in which case these really are translations.
    Note that \(L_g\) and \(R_g\) are invertible, with inverses \(L_{g^{-1}}\) and \(R_{g^{-1}}\) respectively, and they are defined in terms of the smooth multiplication map, so are themselves smooth.
    Thus \(L_g\) and \(R_g\) are diffeomorphisms of \(G\).
    
    A vector field, \(X \in \vectorFields(G)\), is called \defineindex{left invariant} (similar definitions hold for right translations) if \(\dl{L_g}(X) = X\) for all \(g \in G\).
    That is, if
    \begin{equation}
        (\dl{L}_g)_{g^{-1}a}(X_{g^{-1}a}) = X_a
    \end{equation}
    for all \(a, g \in G\).
    Note that we're writing \(g^{-1}a\) as a generic element of \(G\), since all \(b \in G\) can be written in this way, just take \(a = gb\).
    If we take \(g = a\) in the above then we find that
    \begin{equation}
        (\dl{L}_g)_e(X_e) = X_g
    \end{equation}
    and so the value of the vector field at \(g\), that is \(X_g\), is determined entirely from its value at the identity, that is \(X_e\), and the translation \(L_g\).
    Conversely, this allows us to define a smooth left invariant vector field \(X\) by specifying just it's value at \(e\).
    
    We write \(\lie{g} = T_eG\) and call this the \defineindex{Lie algebra} of \(G\).
    Every vector in \(T_eG\) defines a smooth left-invariant vector field on \(G\) by the above equation.
    This correspondence allows us to alternatively identify \(\lie{g}\) as the vector space of left-invariant vector fields on \(G\).
    
    \chapter{The Exterior Algebra}
    \textit{The order in which things were introduced in this section is questionable, and I've decided to take a more standard approach. At a few points this means results which were stated as definitions in the lecture would more properly be understood as theorems here, and I'll attempt to flag these as they arise.}
    
    Our goal in this section is to begin the introduction of calculus to manifolds, in particular integrals, as we've already seen some derivatives.
    It turns out that for a general manifold, \(M\), (as opposed to \(\reals^m\)) functions on \(M\) are not the \enquote{correct} thing to be integrating.
    Instead, we need to integrate differential forms
    
    \section{Differential Forms}
    \subsection{Symmetric Group}
    You know what this is.
    We write \(\varepsilon(\sigma)\) for the sign of the permutation \(\sigma\).
    
    \subsection{Forms}
    \begin{dfn}{Form}{}
        Let \(V\) be an \(m\)-dimensional real vector space and fix some positive integer \(k\).
        An alternating \(k\)-form is a multilinear map
        \begin{equation}
            \omega \colon V^k \to \reals
        \end{equation}
        satisfying
        \begin{equation}
            \omega(v_1, \dotsc, v_k) = \varepsilon(\sigma) \omega(v_{\sigma(1)}, \dotsc, v_{\sigma(k)})
        \end{equation}
        for \(S \in S_k\).
    \end{dfn}
    
    In physics parlance an alternating \(k\)-form is just an antisymmetric rank \(k\) tensor.
    In a given basis, \(\{e_i\}\), for \(V\) the components of \(\omega \colon V^k \to \reals\) are
    \begin{equation}
        \omega_{i_1 \dotsm i_k} = \omega_I \coloneqq \omega(e_{i_1}, \dotsc, e_{i_k}).
    \end{equation}
    Here \(I = i_1\dotsm i_k\) is \defineindex{multi-index} notation, it's just shorthand for a bunch of indices.
    
    \begin{lma}{}{}
        For a fixed \(k\) and \(V\) the set of all alternating \(k\)-forms on \(V\) is a vector space, with pointwise addition and scalar multiplication.
    \end{lma}
    
    We denote this vector space by \(\Lambda^k V^*\).
    
    \begin{exm}{}{}
        \begin{itemize}
            \item For \(k = 0\) we have \(V^0 = \reals\) and all maps \(\reals \to \reals\) are trivially alternating (since \(S_0\) is trivial).
            So \(0\)-forms are just linear functions \(\reals \to \reals\).
            Such a function is completely determined by where it sends \(1\), say it sends \(1\) to \(\lambda\), then the action on \(n\) is \(n = n \cdot 1 \mapsto n \cdot \lambda = \lambda n\), so the function is just scaling by \(\lambda\), and hence \(\Lambda^0 V^* \isomorphic \Hom_{\reals}(\reals, \reals)\).
            \item For \(k = 1\) we have \(V^1 = V\) and all maps \(V \to \reals\) are trivially alternating (since \(S_1\) is trivial).
            So \(1\)-forms are just linear maps \(V \to \reals\), which is to say elements of \(V^*\), and so \(\Lambda^1 V^* = V^* = \Hom_{\reals}(V, \reals)\).
            
            For \(V = \reals^m\) denote by \(\dl{x^i} \colon \reals^m \to \reals\) the projection onto the \(i\)th coordinate in some basis \(\{e_i\}\) for \(\reals^m\).
            So if \(\xi = \xi^1 e_1 + \dotsb + \xi^m e_m\) then \(\dl{x^i}(\xi) = \xi^i\).
            The linear maps \(\dl{x^i} \colon \reals^m \to \reals\) then form a basis for \((\reals^m)^* = \Lambda^1(\reals^m)^*\).
            
            \item For \(k = 2\) we finally have a nontrivial \(S_2\), and so not all linear maps \(V \to \reals\) are alternating \(k\)-forms.
            An alternating \(2\)-form is is a skew-symmetric linear map \(\omega \colon V \times V \to \reals\), which is to say that
            \begin{equation}
                \omega(u, v) = -\omega(v, u).
            \end{equation}
            
            For \(V = \reals^m\) any such alternating \(2\)-form corresponds to a skew-symmetric matrix, \(A\), which is such that
            \begin{equation}
                \omega(u, v) = \innerprod{u}{Av}
            \end{equation}
            where \(\innerprod{-}{-}\) is the standard inner product on \(\reals^m\).
            Further, this identification provides an isomorphism \(\Lambda^2(\reals^m)^* \isomorphic \specialOrthogonalLie(m)\) (it just happens that \(\specialOrthogonalLie(m)\) is the space of skew-symmetric matrices, there's not really anything rotational going on here).
            Simple parameter counting tells us that \(\dim \specialOrthogonalLie(m) = \dim(\Lambda^2(\reals^m)^*) = m(m - 1)/2\) (this is just the number of above-diagonal elements in an \(m \times m\) matrix).
        \end{itemize}
    \end{exm}
    
    \begin{dfn}{}{}
        \textit{This is not the standard definition of \(\dl{x}^I\). That would be \(\dl{x}^I = \dl{x}^{i_1} \wedge \dotsm \wedge \dl{x}^{i_k}\), instead this is a theorem for us here, which is both wrong and bad.}
        
        Let \(\symcal{I}_{k,m}\) denote the set of tuples \((i_1, \dotsc, i_k) \in \naturals^k\) (with \(\naturals = \{1, 2, 3, \dotsc\}\) (also wrong and bad)) such that \(1 \le i_1 < i_2 < \dotsb < i_k \le m\).
        Then define the alternating \(k\)-form
        \begin{equation}
            \dl{x^I} \colon (\reals^m)^k \to \reals
        \end{equation}
        by
        \begin{equation}
            \dl{x^I}(v_1, \dotsc, v_k) = \det
            \begin{pmatrix}
                u_1^{i_1} & u_2^{i_1} & \dots & u_k^{i_1}\\
                u_1^{i_2} & u_2^{i_2} & \dots & u_k^{i_2}\\
                \vdots & \vdots & \ddots & \vdots\\
                u_1^{i_k} & u_2^{i_k} & \dots & u_k^{i_k}
            \end{pmatrix}
            .
        \end{equation}
        If we allow for \(i_j > m\) then we just declare that \(\dl{x^I} = 0\), which is enforced by the alternating property of \(\dl{x^I}\).
    \end{dfn}
    
    \begin{lma}{}{}
        Let \(V\) be an \(m\)-dimensional real vector space.
        Then
        \begin{equation}
            \dim \Lambda^kV^* = \binom{m}{k}.
        \end{equation}
        \begin{proof}
            First note that if \(\varphi \colon V \to \reals^m\) is an isomorphism then this induces an isomorphism \(\Lambda^k V^* \to \Lambda^k (\reals^m)^*\) by \(\omega \mapsto \omega \circ \varphi^k\) where \(\varphi^k\) simply applies \(\varphi\) to each input of \(\omega\).
            Thus, it is sufficient to prove the \(V = \reals^m\) case.
            In this case we claim that \(\{\dl{x^I}\}_{I \in \symcal{I}_{k,m}}\) forms a basis for \(\Lambda^k(\reals^m)^*\), and then it is a simple counting exercise to show that
            \begin{equation}
                \abs{\symcal{I}_{k,m}} = \binom{m}{k}.
            \end{equation}
            
            We make three observations:
            \begin{enumerate}
                \item If \(\{e_i\}\) is the standard basis of \(\reals^m\) and \(J = (j_1, \dotsc, j_k) \in \symcal{I}_{k,m}\) then for \(I \in \symcal{I}_{k,m}\) we have
                \begin{equation}
                    \dl{x}^I(e_J) \coloneqq \dl{x^I}(e_{j_1}, \dotsc, e_{j_k}) = 
                    \begin{cases}
                        1 & I = J,\\
                        0 & I \ne J.
                    \end{cases}
                \end{equation}
                This follows because if \(I \ne J\) then the resulting matrix that we take the determinant of will have a zero on the diagonal, and if \(I = J\) then the resulting matrix is the identity.
                \item For \(\omega \in \Lambda^k(\reals^m)^*\) we have
                \begin{equation}
                    (\omega = 0) \iff (\omega(e_I) = \omega(e_{i_1}, \dotsc, e_{i_k}) = \omega_I = 0 \forall I \in \symcal{I}_{k,m}).
                \end{equation}
                That is, \(\omega\) vanishes only if all of its components do in the standard basis.
                \item For every \(\omega \in \Lambda^k(\reals^m)^*\) we have
                \begin{equation}
                    \omega = \sum_{I \in \symcal{I}_{k,m}} \omega_I \dd{x^I}.
                \end{equation}
                This follows by simply both sides on some set of vectors and using the definitions and observing that they give the same result.
                Alternatively this is simply the fact that \(\dl{x}^I\) is defined via a determinant, which is the only alternating map up to a scale factor, here \(\omega_I\), and thus this follows from the first two observations.
            \end{enumerate}
            The third observation proves that \(\dl{x^I}\) span \(\Lambda^k(\reals^m)^*\), and linear independent of the \(\dl{x^I}\) follows from these observations also: if \(\sum_I \omega_I \dd{x^I} = 0\) then define \(\omega = \sum_I \omega_I \dd{x^I}\) and \(\omega(e_J) = \omega_J = 0\) only if \(\omega_J\) vanishes in this sum, so \(\omega = 0\) only if all of its components vanish.
        \end{proof}
    \end{lma}
    
    \section{Exterior Product}
    \begin{dfn}{Exterior Product}{def:exterior product}
        The \defineindex{exterior product} or \defineindex{wedge product} is the product \(\Lambda^k V^* \times \Lambda^\ell V^* \to \Lambda^{K+\ell}V^*\) defined by
        \begin{equation}
            (\omega \wedge \eta)(v_1, \dotsc, v_{k + \ell}) = \frac{1}{k!\ell!} \sum_{\sigma \in S_{k + \ell}} \omega(v_{\sigma(1)}, \dotsc, v_{\sigma(k)}) \eta(v_{\sigma(k + 1)}, \dotsc, v_{\sigma(k + \ell)}).
        \end{equation}
        \textit{This is not the definition given in lectures, which is in terms of shuffles, to avoid the over-counting fixed by the prefactor of \(1/k!\ell!\) at the cost of being much worse in every other way.}
    \end{dfn}
    
    \begin{exm}{}{}
        \begin{itemize}
            \item For \(k = \ell = 1\) we have
            \begin{equation}
                (\omega \wedge \eta)(u, v) = \omega(u)\eta(v) - \omega(v)\eta(u).
            \end{equation}
            \item For \(k = 1\) and \(\ell = 2\) taking \(S_3 = \{\cycle{}, \cycle{1,2}, \cycle{2,3}, \cycle{1,3}, \cycle{1,2,3}, \cycle{1,3,2}\}\) in this order we have
            \begin{align*}
                (\omega \wedge \eta)(u, v, w) &= \frac{1}{2!}[\omega(u)\eta(v, w) - \omega(v)\eta(u, w) - \omega(u)\eta(w, v) \\
                &\qquad- \omega(w)\eta(v, u) + \omega(v)\eta(w, u) + \omega(w)\eta(u, v)]\\
                &= \frac{1}{2}[\omega(u)\eta(v, w) + \omega(v)\eta(w, u) + \omega(u)\eta(v, w) \\
                &\qquad+ \omega(w)\eta(u, v) + \omega(v)\eta(w, u) + \omega(w)\eta(u, v)]\\
                &= \omega(u)\eta(v, w) + \omega(v)\eta(w, u) + \omega(w)\eta(u, v)
            \end{align*}
        \end{itemize}
    \end{exm}
    
    \begin{lma}{}{}
        The exterior product is associative, distributes over addition, and is graded-commutative (or supercommutative), meaning
        \begin{equation}
            \omega \wedge \eta = (-1)^{\deg(\omega) \deg(\eta)}\eta \wedge \omega
        \end{equation}
        where \(\deg \omega = k\) and \(\deg \eta = \ell\) for \(\omega \in \Lambda^kV^*\) and \(\eta \in \Lambda^\ell V^*\).
    \end{lma}
    
    \subsection{Better Definitions}
    The exterior algebra, \(\Lambda V^* = \Lambda^* V\), is formally defined to be the quotient of the tensor algebra
    \begin{equation}
        T(V^*)/I = (\reals \oplus V^* \oplus (V^* \otimes V^*) \oplus \dotsb)/I
    \end{equation}
    where \(I\) is the ideal generated by \(\omega \otimes \omega\) for \(\omega \in V^*\).
    This is \(\naturals\)-graded and \(\Lambda^kV^*\) is just the \(k\)-graded part of this.
    The wedge product is just the tensor product mod \(I\), so \(\omega \wedge \eta = \tilde{\omega} \otimes \tilde{\eta} + I\) where \(\omega = \tilde{\omega} + I\) and \(\eta = \tilde{\eta} + I\) are such that \(\tilde{\omega}, \tilde{\eta} \in T(V^*)\).
    
    \begin{thm}{Determinant Theorem}{}
        For \(\omega_i \in V^* = \Lambda^1V^*\) and \(v_i \in V\) we have
        \begin{equation}
            (\alpha_1 \wedge \dotsb \wedge \alpha_k)(v_1, \dotsc, v_k) = \det
            \begin{pmatrix}
                \alpha_1(v_1) & \alpha_1(v_2) & \dots & \alpha_1(v_k)\\
                \alpha_2(v_1) & \alpha_2(v_2) & \dots & \alpha_2(v_l)\\
                \vdots & \vdots & \ddots & \vdots\\
                \alpha_k(v_1) & \alpha_k(v_2) & \dots & \alpha_k(v_k)
            \end{pmatrix}
            .
        \end{equation}
    \end{thm}
    
    \begin{crl}{}{}
        \(\dl{x^I} = \dl{x^{i_1}} \wedge \dotsb \wedge \dl{x^{i_k}}\).
    \end{crl}
    \textit{Of course, with sensible definitions this corollary is the definition and what we have as the definition is a special case of the determinant theorem.}
    
    \section{Pullback}
    \begin{dfn}{Pullback}{}
        Let \(\varphi \colon V \to W\) be a linear map between real vector spaces \(V\) and \(W\).
        The \defineindex{pullback} of the alternating \(k\)-form \(\omega \in \Lambda^kW^*\) along \(\varphi\) is the alternating \(k\)-form \(\varphi^*\omega \in \Lambda^kV^*\) defined by
        \begin{equation}
            (\varphi^*\omega)(v_1, \dotsc, v_k) = \omega(\varphi(v_1), \dotsc, \varphi(v_k))
        \end{equation}
        for \(v_i \in V\).
    \end{dfn}
    
    \begin{lma}{}{}
        For fixed \(\varphi \colon V \to W\) the map \(\Lambda^* W \to \Lambda^* V\) given by \(\omega \mapsto \varphi^* \omega\) is linear and preserves the exterior product, that is
        \begin{equation}
            \varphi^*(\omega \wedge \eta) = \varphi^*\omega \wedge \varphi^*\eta
        \end{equation}
        for all \(\omega, \eta \in \Lambda^*W\).
   \end{lma}
   \begin{lma}{}{}
        Let \(\varphi \colon V \to W\) and \(\psi \colon W \to U\) be linear maps between real vector spaces.
        Then \((\psi \circ \varphi)^*\omega = \varphi^*(\psi^*\omega)\) for all \(\omega \in \Lambda^*U\), so \((\psi \circ \varphi)^* = \varphi^* \circ \psi^*\).
        Further, if \(W = V\) we can take \(\varphi = \id_V\) and \(\id_V^*\omega = \omega\) so \(\id_V^* = \id_{\Lambda^*V}\).
        
        In other words, taking exterior algebras and pullbacks defines a contravariant functor \(\Vect[\reals]^{\op} \to \Vect[\reals]\) sending a vector space to \(\Lambda^* V\) and sending a linear map, \(\varphi\), to its pullback, \(\varphi^*\).
    \end{lma}
    
    \begin{lma}{}{}
        If \(\varphi \colon V \to V\) is an endomorphism then \(\varphi^*\omega = \det(\varphi) \omega\) for all \(\omega \in \Lambda^* V\).
    \end{lma}
    
    \chapter{Differential Forms}
    \section{Differential Forms}
    When we take the vector space \(V = T_pM\) and impose a smoothness condition on the resulting alternating \(k\)-forms we get differential forms.
    
    \begin{dfn}{Differential Form}{}
        Let \(M\) be a smooth manifold and let \(k \in \naturals\).
        A \define{differential \(k\)-form}\index{differential form}, \(\omega\), is a collection of alternating \(k\)-forms, \(\omega_p \in \Lambda^k T_p^*M\), one for each \(p \in M\).
        That is, we have differential forms
        \begin{equation}
            \omega_p \colon T_pM \times \dotsb \times T_pM \to \reals
        \end{equation}
        with \(k\) copies of \(T_pM\) in the product.
        The differential form, \(\omega\), itself is a function \(\omega \colon M \to \Lambda^kT_p^*M\).
        
        We impose the smoothness condition that for any \(k\) smooth vector fields, \(X_1, \dotsc, X_k \in \vectorFields(M)\) the function \(p \mapsto \omega_p(X_1(p), \dotsc, X_k(p))\) must be smooth.
        
        We denote the set of smooth differential \(k\)-forms on \(M\) by \(\Omega^k(M)\).
        We call \(k\) the \defineindex{degree} of \(\omega\) and write \(k = \deg(\omega)\).
    \end{dfn}
    
    \begin{remark}{}{}
        The set
        \begin{equation}
            \Lambda^k T^*M = \{(p, \omega) \mid p \in M, \omega \in \Lambda^kT^*_pM\}
        \end{equation}
        is a vector bundle over \(M\), which we'll define in a future section.
        % TODO: add reference to definition of vector bundle
        This requires that \(\Lambda^kT^*M\) is a manifold, and indeed it is.
        The projection \(\pi \colon \Lambda^k T^* M \to M\) given by \((p, \omega) \mapsto p\) is a sooth submersion, and each fibre (to be defined) \(\Lambda^kT^*_pM\) is a vector space, with addition and scalar multiplication given by smooth maps.
        The manifold structure is uniquely determined by the fact that each \(\omega \in \Omega^k(M)\) defines a smooth map \(M \to \Lambda^k T^*M\) given by \(p \mapsto (p, \omega_p)\).
        The composition of this map with the projection \(\pi\) is the identity on \(M\), and maps with this property are called (smooth) sections of the vector bundle.
        This allows us to identify \(\Omega^k(M)\) with the space of smooth sections of \(\Lambda^kT^*M\), sometimes denoted \(\Gamma(\Lambda^kT^*M)\).
        
        The space \(\Omega^k(M)\) is a vector space, and is generally infinite dimensional (the dimension is finite only if \(M\) is a finite set or \(k > \dim M\) (in which case \(\Omega^k(M) = 0\))).
        Note that \(\Omega^0(M) = \{f \colon M \to \reals \mid f \text{ is smooth}\}\) is the set of real valued smooth functions on \(M\), also denoted \(C^{\infty}(M)\).
    \end{remark}
    
    The operators on the wedge product and pullback generalise pointwise to differential forms, as we see in the following definitions.
    
    \begin{dfn}{Exterior Product}{}
        Let \(M\) be a smooth manifold and \(\omega \in \Omega^k(M)\) and \(\eta \in \Omega^{\ell}(M)\) differential forms on \(M\).
        We define the \defineindex{exterior product} pointwise by
        \begin{equation}
            (\omega \wedge \eta)_p \coloneqq \omega_p \wedge \eta_p
        \end{equation}
        where on the right the exterior product is that of alternating forms defined in \cref{def:exterior product}.
    \end{dfn}
    
    \begin{dfn}{Pullback}{}
        Let \(M\) and \(N\) be smooth manifolds and let \(\omega \in \Omega^k(N)\) be a differential form on \(N\).
        Let \(\varphi \colon M \to N\) be a smooth map between manifolds.
        The \defineindex{pullback} of \(\omega\) is the differential \(k\)-form \(\varphi^*\omega \in \Omega^k(M)\) on \(M\) given by
        \begin{equation}
            (\varphi^*\omega)_p(v_1, \dotsc, v_k) \coloneqq \omega_{\varphi(p)}(\dl{\varphi}_pv_1, \dotsc, \dl{\varphi}_pv_k)
        \end{equation}
        for all \(p \in M\) and \(v_i \in T_pM\).
    \end{dfn}
    
    The following lemma is immediate from the same properties for the exterior product and pullback of alternating forms, everything just factors through the pointwise operations.
    
    \begin{lma}{}{}
        The exterior product is associative, distributes over addition, and is graded-commutative.
        
        The pullback is linear, preserves the exterior product, and provides a contravariant functor between vector bundles.
    \end{lma}
    
    \begin{lma}{}{}
        Let \(M\) and \(N\) be smooth manifolds, \(\omega \in \Omega^k(N)\) a differential form, and \(X_1, \dotsc, X_k \in \vectorFields(N)\) vector fields.
        Let \(\varphi \colon M \to N\) be a diffeomorphism.
        Then 
        \begin{equation}
            (\varphi^*\omega)(\varphi^*X_1, \dotsc, \varphi^*X_k) = \omega(X_1, \dotsc, X_k) \circ \varphi.
        \end{equation}
    \end{lma}
    
    \section{Differential Forms in Local Coordinates}
    For explicit calculations (if you're a physicist) it can be useful to work in local coordinates.
    That is, we take some chart \((U_\alpha, \varphi_\alpha)\), and we restrict our attention to only the part of \(M\) covered by \(U_\alpha\).
    We can then use \(\varphi_\alpha\) to get explicit functions between subsets of \(\reals^m\) and \(\reals\) instead of functions \(M \to \reals\).
    In this section we'll look at how this lets us express differential forms in local coordinates.
    
    \begin{remark}{}{}
        We have so far assumed, and will continue to assume, that manifolds do not have boundaries.
        A manifold with boundary can be defined in the same way as a manifold without boundary, just replace \(\reals^m\) with the upper half space, \(\symbb{H}^m = \{(x_1, \dotsc, x_m) \in \reals^m \mid x_m \ge 0\}\).
        Then a boundary point is any point in \(M\) which maps to coordinates with \(x_m = 0\) in a chart, and all other points are interior points.
    \end{remark}
    
    % MISSING CONTENT HERE FROM MERGE, STOKES AND THAT
    
    \chapter{de Rham Cohomology}
    \section{Motivation}
    Consider a smooth vector field,  \(\vv{F} \colon U \to \reals^2\), defined on an open subset, \(U \subseteq \reals^2\)..
    This can be specified by giving the coordinates as two smooth functions \(P, Q \colon U \to \reals\), so \(\vv{F}(x, y) = \langle P(x, y), Q(x, y) \rangle\).
    Take some smooth curve, \(c \colon [0, 1] \to \reals^2\), which can also be given in terms of coordinate functions \(x, y \colon [0, 1] \to \reals^2\), \(c(t) = (x(t), y(t))\).
    One common operation is performing an integral of \(\vv{F}\) along this curve, that is, performing the integral
    \begin{equation}
        W = \int_C (P \dd{x} + Q\dd{y}).
    \end{equation}
    Suppose \(\vv{F}\) is actually the gradient of some scalar function, \(f \colon U \to \reals\), so \(\vv{F} = \gradWord f = \langle f_x, f_y \rangle\), where \(f_x = \difsp{f}{x}\) and \(f_y = \difsp{f}{y}\).
    Then we can compute this using
    \begin{equation}
        W = \int_C f_x \dd{x} + \int_C f_y \dd{y} = \int_C \dl{f} = f(1) - f(0).
    \end{equation}
    In order for \(\vv{F}\) to be a gradient it is necessary to have
    \begin{equation}
        P_y = f_{xy} = f_{yx}  Q_x,
    \end{equation}
    which is basically one of the Cauchy--Riemann equations.
    
    The question we may then ask is if this condition is sufficient for \(\vv{F}\) to be the gradient of some function.
    It turns out that it is.
    We have seen that we have a one-to-one correspondence between vectors in \(\reals^2\) and 1-forms in \(\Lambda^1\reals^2\), specifically, the isomorphism is given by \(e_1 \mapsto \dl{x}\) and \(e_2 \mapsto \dl{y}\).
    This extends to a one-to-one correspondence between vector fields in \(\vectorFields(U)\) and differential 1-forms in \(\Omega^1(U)\), the isomorphism looks the same, but now each element is viewed as a function on the manifold outputting a vector/1-form.
    This correspondence gives \(\vv{F} = \langle P, Q\rangle\) a corresponding differential 1-form \(\omega = P \dd{x} + Q \dd{y}\).
    We have seen (for the case of \(\reals^3\)) that the gradient corresponds to the exterior derivative (and this holds equally in \(\reals^2\), and indeed in \(\reals^n\) generally), so \(\gradWord f = \langle f_x, f_y \rangle\) corresponds to \(\dl f = f_x \dd{x} + f_y \dd{y}\) under this correspondence.
    Then, the fact that \(Q_x - P_y = 0\) (which is what we're assuming) means that
    \begin{align}
        \dl{\omega} &= \dl(P \dd{x} \wedge Q \dd{y})\\
        &= \dl{P} \wedge \dl{x} + \dl{Q} \wedge \dl{y}\\
        &= (P_x \dd{x} + P_y \dd{y}) \wedge \dl{x} + (Q_x \dd{x} + Q_y \dd{y}) \wedge \dl{y}\\
        &= P_y \dd{y} \wedge \dl{x} + Q_x \dd{x} \wedge \dl{y}\\
        &= (Q_x - P_y) \dd{x} \wedge \dl{y}\\
        &= 0.
    \end{align}
    So, we can say that \(\vv{F}\) is the gradient of some function if and only if the corresponding 1-form, \(\omega\), is such that \(\dl{\omega} = 0\), and it turns out that whether this is the case depends on the topology of \(U\).
    
    \subsection{Different Types of Form}
    \begin{dfn}{Closed and Exact Forms}{}
        A differential form, \(\omega\), is said to be \defineindex{closed} if \(\dl{\omega} = 0\).
        
        A differential \(k\)-form, \(\omega\), is said to be \defineindex{exact} if there exists some differential \((k - 1)\)-form, \(\tau\), such that \(\omega = \dl{\tau}\).
    \end{dfn}
    
    The terminology here comes from cohomology, which we're about to introduce.
    The map \(\dl{}\) here is interpreted as a \enquote{boundary map}, and so \(\dl{\omega} = 0\) means that \(\omega\) has no boundary, so it's closed, compare this to, for example, the circle, \(S^1\), which is a closed loop and has no boundary, as opposed to an interval, \([0, 1]\), which is not a closed loop, and has a boundary, \(\{0, 1\}\).
    
    The question then is how are closed and exact forms related?
    It follows immediately from the definitions that if \(\omega\) is exact it is also closed, since exactness implies the existence of some \(\tau\) satisfying \(\omega = \dl{\tau}\), and then \(\dl{\omega} = \dl^2\tau = 0\).
    The interesting question then is what about closed forms that aren't exact?
    It turns out that whether or not such forms exist depends on the manifold, and further, it is possible to distinguish many manifolds based solely on whether closed non-exact forms exist, and when they do exist how many linearly independent ones exist.
    To do this rigorously we introduce the general notion of cohomology.
    
    Before we do this however, note that the closed \(k\)-forms form subspace of \(\Omega^k(M)\), since if \(\omega, \omega' \in \Omega^k(M)\) are closed then \(\dl(\omega + a \omega') = \dl{\omega} + a\dd{\omega'} = 0\) for \(a \in \reals\), so the subset of closed forms is closed under addition and scalar multiplication.
    Call the subspace of closed forms \(Z^k(M) = \{\omega \in \Omega^k(M) \mid \dl{\omega} = 0\}\).
    Similarly, the subset of exact \(k\)-forms is a subspace of \(\Omega^k(M)\), since if \(\omega, \omega' \in \Omega^k(M)\) are exact, so there exist \(\tau, \tau' \in \Omega^{k-1}(M)\) such that \(\dl{\tau} = \omega\) and \(\dl{\tau'} = \omega'\), then \(\omega + a\omega' = \dl{(\tau + a\tau')}\) for all \(a \in \reals\), so the subset of exact forms is closed under addition and scalar multiplication.
    Call the subspace of exact forms \(B^k(M) = \{\omega \in \Omega^k(M) \mid \exists \tau \in \Omega^{k-1}(M) \text{ s.t.\@ } \omega = \dl{\tau}\}\).
    Further, note that since every exact form is closed we have \(B^k(M) \subseteq Z^k(M)\).
    
    The study of cohomology is then all about the study of elements of \(Z^k(M)\) which are not elements of \(B^k(M)\).
    To do this we actually look at the quotient \(Z^k(M)/B^k(M)\), which essentially sets all exact forms to be zero leaving the only non-zero elements to be (equivalence classes of) non-exact closed forms.
    
    \section{Cohomology}
    In this section we'll set up a more abstract way of defining cohomology that generalises.
    For historical reasons what we're doing here is considered \emph{co}homology.
    Turning all the arrows around and removing any \enquote{co-} prefix gives us homology, but we won't concern ourselves with that here.
    
    \begin{dfn}{Cochain Complex}{}
        A \defineindex{cochain complex}, \(C^{\bullet} = \{C^i\}_{k \in \integers}\) is a collection of vector spaces (or more generally, \(R\)-modules), \(C^k\), equipped with linear maps (\(R\)-module homomorphisms) \(d^k \colon C^k \to C^{k+1}\), which satisfy the property that \(d^{k + 1} \circ d^{k} = 0\) for all \(k \in \integers\).
        We can express all of this information as the diagram
        \begin{equation}
                \begin{tikzcd}
                    \dots \arrow[r] & C^{-1} \arrow[r, "d^{-1}"] & C^0 \arrow[r, "d^0"] & C^1 \arrow[r, "d^2"] & \dots.
                \end{tikzcd}
        \end{equation}
        We call the \(d^k\) the \define{boundary maps}\index{boundary map}, or \define{differentials}\index{differential!of a cochain complex} of the cochain complex.
        
        Elements of \(C^k\) are called \(k\)-\define{cochains}\index{cochain}.
    \end{dfn}
    
    \begin{dfn}{Exactness}{}
        A \defineindex{cochain complex} is \defineindex{exact} at \(C^k\) if \(\im d^{k} = \ker d^{k+1}\).
        An \defineindex{exact sequence} is a cochain complex which is exact at every point.
    \end{dfn}
    
    \begin{dfn}{Cohomology}{}
        The \defineindex{cohomology} of a cochain complex at a point indexed by \(k\) is the quotient vector space (or \(R\)-module) \(H^k = \ker d^k/\ker d^{k-1}\).
    \end{dfn}
    
    Note that a cochain complex is exact at \(k\) if and only if \(H^k = 0\).
    
    \begin{dfn}{Morphisms of Chain Complexes}{}
        Let \(C^{\bullet}\) and \(D^{\bullet}\) be cochain complexes with boundary maps \(d^k \colon C^k \to C^{k+1}\) and \(e^k \colon D^k \to D^{k+1}\) respectively.
        A \defineindex{morphism of cochain complexes} \(C^{\bullet} \to D^{\bullet}\) is a collection of linear maps (or \(R\)-module homomorphisms) \(f_k \colon C^k \to D^k\) such that \(f_{k+1} \circ d^k = e^{k + 1} \circ f_k\).
    \end{dfn}
    
    The idea of a cochain complex morphism is that the obvious diagram,
    \begin{equation}
        \begin{tikzcd}
            \dots \arrow[r, "d^{k-1}"] & C^{k} \arrow[r, "d^k"] \arrow[d, "f_k"'] & C^{k+1} \arrow[r, "d^{k+1}"] \arrow[d, "f_{k+1}"] & C^{k+2} \arrow[r, "d^{k+2}"] \arrow[d, "f_{k+2}"] & \dotsb\\
            \dots \arrow[r, "e^{k-1}"'] & D^{k} \arrow[r, "e^k"'] & D^{k+1} \arrow[r, "e^{k+1}"'] & D^{k+2} \arrow[r, "e^{k+2}"'] & \dotsb
        \end{tikzcd}
    \end{equation}
    should commute.
    
    The composite of two cochain complex morphisms, \(f \colon C^{\bullet} \to D^{\bullet}\) and \(g \colon D^{\bullet} \to E^{\bullet}\), is given by composing the component maps, \((g \circ f)_k = g_k \circ f_k\), and is again a cochain complex morphism, and the identity cochain morphism \(\id_{C^{\bullet}} \colon C^{\bullet} \to C^{\bullet}\) simply has componentwise identities, \((\id_{C^{\bullet}})_k = \id_{C^k}\), finally associativity is inherited from associativity of the composition of the component maps.
    Thus, cochain complexes (formed from real vector spaces) form a category \(\Ch[\reals]\) (more generally, \(\Ch[R]\) for a ring \(R\) if the \(C^k\) are \(R\)-modules).
    
    \section{de Rham Cohomology}
    We are mostly interested in the special case hinted at in the motivation section, namely when \(C^k = \Omega^k(M)\) with the exterior derivative as the differential.
    
    \begin{dfn}{de Rham Cochain Complex}{}
        The \defineindex{de Rham cochain complex} of a manifold, \(M\), is given by taking \(C^k = \Omega^k(M)\) for \(0 \le k \le m = \dim M\), and \(C^k = 0\) otherwise, and taking the maps \(\Omega^k(M) \to \Omega^{k+1}(M)\) to be exterior derivatives.
        That is, it's the cochain complex
        \begin{equation*}
            \begin{tikzcd}[column sep=small]
                0 \arrow[r] & \Omega^0(M) \arrow[r, "\dl"] & \Omega^1(M) \arrow[r, "\dl"] & \Omega^2(M) \arrow[r, "\dl"] & \dots \arrow[r, "\dl"] & \Omega^m(M) \arrow[r] \arrow[r] & 0.
            \end{tikzcd}
        \end{equation*}
    \end{dfn}
    
    Note that the condition \(d^{k+1} \circ d^k = 0\) becomes \(\dl^2 = 0\) (which is always true) for all cases not involving the zero vector space, and any case involving the zero vector space necessarily involves the zero map, so the composite will vanish in this case as well.
    
    Note also that in cases like this where (for a finite-dimensional manifold) we have finite complexes we may always assume them to be padded on either side by the zero space.
    
    \begin{dfn}{de Rham Cohomology}{}
        The \defineindex{de Rham cohomology} of a manifold, \(M\), denoted \(H^k(M)\) (or \(H^k_{\symrm{dR}}(M)\) if multiple cohomology theories are of interest) is \(H^k(M) = \ker \dl/\im \dl = Z^k(M)/B^k(M)\), where \(\ker \dl = \ker(\dl \colon \Omega^k(M) \to \Omega^{k + 1}(M))\) and \(\im \dl = \im (\dl \colon \Omega^{k-1}(M) \to \Omega^k(M))\).
    \end{dfn}
    
    Note that we simply choose the appropriate exterior derivatives such that the kernel and image are subspaces of \(\Omega^k(M)\) in order to take the quotient.
    
    In friendlier notation we have
    \begin{equation}
        H^k(M) = \frac{\{\text{closed \(k\)-forms on \(M\)}\}}{\{\text{exact \(k\)-forms on \(M\)}\}}.
    \end{equation}
    An element of \(H^k(M)\) is an equivalence class, \([\omega]\), consisting of all forms \(\omega'\) such that there exists some exact \(k\)-form, \(\eta\) such that \(\omega - \omega' = \eta\).
    Since \(\eta\) is exact this is equivalent to saying there is some \((k - 1)\)-form, \(\tau\), such that \(\omega - \omega' = \dl \tau\).
    
    \begin{exm}{Zeroth de Rham Cohomology}{}
        Consider \(H^0(M)\).
        First note that no nonzero \(0\)-forms are exact, since the only \enquote{\((-1)\)-form} is \(0\), which is such that \(\dl 0 = 0\).
        Now suppose that \(f\) is a closed \(0\)-form on \(M\), that is, \(f \colon M \to \reals\) is a smooth function and \(\dl f = 0\).
        Since \(\dl f = \sum_i f_x^i \dd{x^i}\) this means we must have \(f_x^i = 0\), so \(f\) is constant \emph{except} that \(f_{x^i}\) is only defined locally, that is on a given chart, \((U_\alpha, \varphi_\alpha)\).
        Further, if there is a second chart, \((U_\beta, \varphi_\beta)\), such that \(U_\alpha \cap U_\beta \ne \emptyset\) then we must have \(f|_{\varphi_\alpha(U_\alpha \cap U_\beta)} = f|_{\varphi_\beta(U_\alpha \cap U_\beta)}\) where \(x^i\) and \(y^i\) are the coordinates corresponding to the charts \(U_\alpha\) and \(U_\beta\) respectively.
        So, \(f\) must be constant on the overlap of the charts, and on the entirety of any chart, so \(f\) must be constant on \(U_\alpha \cup U_\beta\).
        Thus, the only way that \(f\) can vary is if no two charts upon which \(f\) disagrees have any overlap, and no charts they overlap have any overlap and so on.
        
        Thus, we see that \(f\) must be constant on any one connected component of \(M\), but may vary between different connected components.
        We call such functions \defineindex{locally constant}.
        If \(M\) has \(r\) connected components then a basis for all of the locally constant functions is given by \(1_k\) where \(1 \le k \le r\) labels the connected components and \(1_k\) takes the constant value \(1\) on the \(k\)th connected component, vanishing elsewhere.
        Clearly then the space of locally constant functions is isomorphic to \(\reals^r\), and we find that\footnote{We will only ever consider cohomology up to isomorphism, so we'll write \(=\) for any isomorphisms of cohomologies.} \(H^0(M) = \reals^r\). 
    \end{exm}
    
    \begin{exm}{}{}
        Suppose that \(M\) has dimensions \(m\).
        Then \(\Omega^k(M) = 0\) for \(k > m\), and so \(H^k(M) = 0\) for any \(k > m\).
    \end{exm}
    
    \begin{exm}{de Rham Cohomology of \(\reals\)}{}
        Consider \(\reals\) as a 1-dimensional manifold.
        We know that \(\reals\) has just a single connected component, so \(H^0(\reals) = \reals\), and \(\dim \reals = 1\), so \(H^k(\reals) = 0\) for \(k \ge 2\).
        The only question is what is \(H^1(\reals)\)?
        
        If \(\omega \in \Omega^1(\reals)\) then we know that \(\dl \omega = 0\) since \(\dl \omega \in \Omega^2(\reals) = 0\), so all \(1\)-forms on \(\reals\) are closed.
        
        Now consider the exactness of 1-forms on \(\reals\).
        Any exact 1-form may be written as \(f \dd{x}\) for some smooth function \(f \colon \reals \to \reals\).
        Such a 1-form is exact if there is some 0-form, that is some smooth function, \(g \colon \reals \to \reals\) such that \(f = g'\), since then \(\dl g = g' \dd{x}\).
        Such a function, \(g\), is simply the antiderivative of \(f\), and the antiderivative always exists because \(f\) is smooth, so the integral
        \begin{equation}
            g(x) = \int_0^x f(t) \dd{t}
        \end{equation}
        always exists.
        Thus, every 1-form on \(\reals\) is exact.
        
        Combining these results we have that
        \begin{equation}
            H^1(\reals) = \frac{\Omega^1(\reals)}{\Omega^1(\reals)} = 0,
        \end{equation}
        and thus we have
        \begin{equation}
            H^k(\reals) = 
            \begin{cases}
                \reals & k = 0,\\
                0 & k \ge 1.
            \end{cases}
        \end{equation}
    \end{exm}
    
    \begin{exm}{de Rham Cohomology of \(S^1\)}{}
        Now consider \(S^1\) as a 1-dimensional manifold.
        We know that \(S^1\) has just a single connected component, so \(H^0(S^1) = \reals\), and \(\dim S^1 = 1\), so \(H^k(S^1) = 0\) for \(k \ge 2\).
        The only question is what is \(H^1(S^1)\).
        
        To answer this question we need to be a bit more specific about what we mean by \(S^1\).
        For our calculation we'll take the circle to be \(S^1 = \{(x, y) \in \reals^2 \mid f(x, y) = 0\}\) where \(f \colon \reals^2 \to \reals\) is the smooth function defined by \(f(x, y) = x^2 + y^2 - 1\).
        Note then that \(\dl{f} \in \Omega^1(\reals^2)\).
        In general if \(S \subseteq M\) is a submanifold defined by \(S = \{p \in M \mid f(p) = 0\}\) for some smooth function \(f \colon M \to \reals\) then \(\dl{f}|_S = 0\) since \(f|_S = 0\) and the derivative of the zero function is zero.
        However, on the circle we can define the nowhere-vanishing 1-form, \(\omega \in \Omega^1(S^1)\) defined at a point \((x, y) \in S^1\) by
        \begin{equation}
            \omega_{(x, y)} =
            \begin{cases}
                \frac{\dl{y}}{x} & x \ne 0,\\
                -\frac{\dl{x}}{y} & y \ne 0.
            \end{cases}
        \end{equation}
        Note that \(x = 0\) and \(y = 0\) cannot both occur at once, since \((0, 0) \notin S^1\).
        
        Consider an arbitrary nonzero vector field
        \begin{equation}
            X = a \diffp{}{x} + b \diffp{}{y}.
        \end{equation}
        By definition we have
        \begin{equation}
            \dl{x}(X) = a, \qqand \dl{y}(X) = b,
        \end{equation}
        since \(\{\dl x, \dl y\}\) is dual to the basis \(\{\difsp{}{x}, \difsp{}{y}\}\) for vector fields on \(\reals^2\).
        However, we're restricting to the circle, which means \(f(x, y) = x^2 + y^2 - 1 = 0\), differentiating we must have \(2x + 2y = 0\), so \(x = -y\), and from this it implies that if \(X_{(x, y)}\) is to be tangent to the circle at \((x, y)\) we must have \(a = y\) and \(b = -x\), so when \(x, y \ne 0\) \(\omega\) is well-defined.
        
        The fact that \(\omega\) doesn't vanish at any point then comes from the fact that if \(x \ne 0\) then said tangent vector cannot be parallel to the \(x\)-axis, and as such it has some non-zero \(\diffp{}{y}\) component which \(\dl{y}\) picks out, likewise, if \(x = 0\) then the tangent vector \emph{is} parallel to the \(x\)-axis, so it's just some nonzero scalar multiple of \(\diffp{}{x}\), and thus this nonzero scalar is picked out by \(\dl{x}\).
        
        We now claim that the fact that \(\omega\) is nowhere vanishing means it cannot be exact.
        Suppose that \(\omega\) is exact, that is there is a 0-form (smooth function) \(g \colon S^1 \to \reals\) such that \(\omega = \dl{g}\).
        Then \(\dl{g} = g_z \dd{z}\) where \(z\) is some coordinate on \(S^1\).
        The value \(g_z = \difsp{g}{z}\) must vanish at the minimum and maximum values of \(g\), and we may take the circle to be the interval, \([0, 1]\), with endpoints identified.
        The problem is that a smooth function, \(g \colon (0, 1) \to \reals\) must always achieve a minimum and maximum on this interval, and therefore vanishes at some point, but \(\dl{g} = \omega\) does not vanish, so this is a contradiction.
        
        The fact that there are non-exact differential forms implies that \(H^1(S^1) \ne 0\).
        It can be shown that \(H^1(S^1) = \reals\).
    \end{exm}
    
    \begin{lma}{}{}
        The de Rham Cohomology is preserved by diffeomorphisms.
        \begin{proof}
            Suppose that \(\varphi \colon M \to N\) is a diffeomorphism.
            Every \(k\)-form, \(\omega \in \Omega^k(N)\) is in one-to-one correspondence with a \(k\)-form \(\varphi^*\omega \in \Omega^k(M)\).
            If \(\omega \in \Omega^k(N)\) is an exact differential form then there exists some \(\tau \in \Omega^{k-1}(N)\) such that \(\omega = \dl \tau\).
            Then we have \(\varphi^* \omega = \varphi^* \dl \tau = \dl \varphi^* \tau\) and \(\varphi^* \tau \in \Omega^{k-1}(M)\), so \(\varphi^*\omega\) is exact.
            If \(\omega \in \Omega^k(N)\) is closed then \(\dl{\omega} = 0\) and so \(\dl \varphi^* \omega = \varphi^* \dl \omega = \varphi^* 0 = 0\) so \(\varphi^* \omega\) is closed.
            This shows that diffeomorphisms preserve exactness and closedness of forms, and thus the isomorphism \(\varphi^* \colon \Omega^k(N) \to \Omega^k(M)\) factors through the quotient to an isomorphism \(\varphi^* \colon H^k(N) \to H^k(M)\) by \(\varphi^*[\omega] = [\varphi^*\omega]\).
            This is well-defined since if \(\omega, \omega' \in [\omega]\) then \(\omega - \omega' = \dl \tau\) for some \(\tau \in \Omega^{k-1}(N)\) and \(\varphi^*(\omega - \omega') = \varphi^*\omega - \varphi^*\omega' = \varphi^*\dl \tau = \dl \varphi^*\tau\) so \(\varphi^*\omega, \varphi^*\omega' \in [\varphi^*\omega]\).
        \end{proof}
    \end{lma}
    
    \begin{crl}{}{}
        The real line, \(\reals\), and circle, \(S^1\), are not diffeomorphic.
        \begin{proof}
            The real line has \(H^1(\reals) = 0\) and the circle has \(H^1(S^1) \ne 0\).
        \end{proof}
    \end{crl}
    
    \section{Ring Structure on de Rham Cohomology}
    It makes sense to extend the definition of the wedge product, \(\wedge \colon \Omega^k(M) \times \Omega^\ell(M) \to \Omega^{k + \ell}(M)\), to cohomologies.
    To do so we simply define
    \begin{equation}
        [\omega] \wedge [\tau] = [\omega \wedge \tau]
    \end{equation}
    for \([\omega] \in H^k(M)\) and \([\tau] \in H^\ell(M)\) and \([\omega \wedge \tau] \in H^{k + \ell}(M)\).
    We need to check that this definition makes sense, which requires that we check three things.
    \begin{itemize}
        \item First, we need to check that \(\omega \wedge \tau\) is a closed form, since representatives of cohomology classes must be closed.
        This follows since \(\omega\) and \(\tau\) are closed, as they are representatives of cohomology classes, and so
        \begin{equation}
            \dl (\omega \wedge \tau) = \dl \omega \wedge \tau + (-1)^k \omega \wedge \dl{\tau} = 0
        \end{equation}
        as \(\dl \omega = 0\) ad \(\dl \tau = 0\).
        \item Second, we need to check that \([\omega \wedge \tau]\) is independent of the representatives chosen for \([\tau]\).
        If \(\tau' \in [\tau]\) is another possible representative of this class then there exists an exact \(\ell\)-form, \(\rho\), such that \(\tau - \tau' = \rho\), and since \(\rho\) is exact there exists an \((\ell - 1)\)-form, \(\sigma\), such that \(\rho = \dl \sigma\), so \(\tau - \tau' = \dl \sigma\), or in other words, \(\tau = \tau' + \dl{\sigma}\).
        Then we have
        \begin{equation}
            \omega \wedge \tau = \omega \wedge (\tau' + \dl{\sigma}) = \omega \wedge \tau' + \omega \wedge \dl{\sigma}.
        \end{equation}
        Then \(\omega \wedge \tau\) and \(\omega \wedge \tau'\) represent the same equivalence class if and only if they differ by an exact form, that is, if \(\omega \wedge \dl \sigma\) is exact.
        To see that this is the case consider the derivative
        \begin{equation}
            \dl (\omega \wedge \sigma) = \dl \omega \wedge \sigma + (-1)^k \omega \wedge \dl \sigma = (-1)^k \omega \wedge \dl \sigma,
        \end{equation}
        where we've used the fact that \(\omega\) represents a cohomology class so is closed so \(\dl \omega = 0\).
        Then we see that \(\omega \wedge \dl \sigma = \dl((-1)^k \omega \wedge \sigma)\), showing that \(\omega \wedge \dl \sigma\) is exact, and thus \(\omega \wedge \tau\) and \(\omega \wedge \tau'\) do represent the same equivalence class.
        \item Finally, we need to show that \([\omega \wedge \tau]\) is independent of the representative chosen for \([\omega]\), and this follows analogously to the previous point.
    \end{itemize}
    
    For a manifold, \(M\), of dimension \(M\) define
    \begin{equation}
        H^\bullet(M) \coloneqq \bigoplus_{k=0}^m H^k(M).
    \end{equation}
    Then, an element \(\alpha \in H^{\bullet}(M)\) is a (finite\footnote{which is immediate as only finitely many cohomology classes are nonzero}) sum of cohomology classes in \(H^k(M)\) for some indices \(k\):
    \begin{equation}
        \alpha = \alpha_0 + \dotsb + \alpha_m
    \end{equation}
    where \(\alpha_k \in H^k(M)\).
    We can add and elements of \(H^{\bullet}(M)\) in the obvious way, we define the sum to just be \((\alpha_0 + \dotsb + \alpha_m) + (\beta_0 + \dotsb + \beta_m) = (\alpha_0 + \beta_0) + \dotsb + (\alpha_m + \beta_m)\) where addition of cohomology classes is just addition in the quotient space.
    We can multiply elements of \(H^{\bullet}(M)\) using the wedge product, which we declare to distribute over addition, so we consider products like
    \begin{equation}
        \alpha_0 \wedge (\beta_3 + \beta_6) = \alpha_0 \wedge \beta_3 + \alpha_0 \wedge \beta_6,
    \end{equation}
    which we've shown above gives a well-defined operation on each cohomology class which then extends by distributivity to a well-defined operation on \(H^{\bullet}(M)\).
    
    We see from this discussion that we have a graded ring, \(H^{\bullet}(M)\), with multiplication given by the wedge product.
    The grading is that \(\alpha_k \in H^k(M)\) has degree \(k\), and the fact that \(\alpha_k \wedge \alpha_\ell \in H^{k + \ell}(M)\) means that the product respects this grading, as it must to be a graded ring.
    Actually, this is a graded algebra, since the everything is also a vector space.
    Further, we have that\footnote{imagine that a representative, \(\omega\), of \(\alpha_k\) is a wedge product of \(k\) 1-forms, and a representative, \(\tau\), of \(\alpha_\ell\) is a wedge product of \(\ell\) 1-forms. Then to move \(\omega\) past \(\tau\) you first have to anticommute the first 1-form in \(\tau\) through all \(k\) 1-forms of \(\omega\), then the same for the second 1-form in \(\tau\), and so on, eventually you've commuted all \(\ell\) 1-forms of \(\tau\) past all \(k\) 1-forms of \(\omega\), picking up a \(-1\) for each swap for a total of \(k\ell\) swaps and a sign of \((-1)^{k\ell}\).}
    \begin{equation}
        \alpha_k \wedge \alpha_\ell = (-1)^{k\ell} \alpha_\ell \wedge \alpha_k,
    \end{equation}
    so this is an anticommutative graded ring (this equation actually defines what anticommutativity means in the context of a graded ring).
    
    Now suppose that \(f \colon M \to N\) is a smooth map of manifolds.
    We have seen that the pullback gives a map \(f^* \colon H^k(N) \to H^k(M)\), specifically given by \(f^*[\omega] = [f^*\omega]\).
    This extends to a homomorphism of graded rings, \(f^* \colon H^{\bullet}(N) \to H^{\bullet}(M)\) given by \(f^*(\alpha_0 + \dotsb + \alpha_m) = f^*\alpha_0 + \dotsb + f^*\alpha_m\).
    
    Put more abstractly, there is a contravariant functor \(H_{\symrm{dR}}^{\bullet} \colon \Man \to \ACGrAlg[\reals]\), where \(\Man\) is the category of smooth manifolds and smooth maps, and \(\ACGrAlg[\reals]\) is the category of anticommutative graded algebras over \(\reals\).
    It then follows by abstract nonsense (functors preserve isomorphisms) that two diffeomorphic manifolds (isomorphic in \(\Man\)) have equal de Rham cohomologies at all degrees.
    
    \chapter{More Cohomology}
    \section{Poincar\'e Duality}
    Let \(M\) be an oriented manifold of dimension \(m\) without boundary.
    Then for \(k \in \{0, 1, \dotsc, m\}\) we have a bilinear map
    \begin{align}
        \Omega^k(M) \times \Omega_{\compact}^{m-k}(M) &\to \reals\\
        (\omega, \tau) &\mapsto \int_M \omega \wedge \tau.
    \end{align}
    Further, suppose that \(\omega\) and \(\tau\) are closed, so \(\dl\omega = 0\) and \(\dl \tau = 0\), and that one of them, WLOG \(\omega\), is exact, so there exists some \(k-1\)-form \(\alpha\) such that \(\dl \alpha = \omega\).
    Then
    \begin{equation}
        \dl(\alpha \wedge \tau) = \dl \alpha \wedge \tau + (-1)^{k-1} \alpha \wedge \dl{\tau} = \omega \wedge \tau
    \end{equation}
    so \(\omega \wedge \tau\) is the exterior derivative of an \((m - 1)\)-form \(\alpha \wedge \tau\) and as such by Stokes' theorem, and the fact that \(M\) has empty boundary, this integral vanishes.
    
    Using this the pairing induces a bilinear form on the de Rham cohomology,
    \begin{align}
        H^k(M) \times H^{m-k}_{\compact}(M) &\to \reals\\
        ([\omega], [\tau]) &\mapsto \int_M \omega \wedge \tau. \label{eqn:poincare pairing}
    \end{align}
    This is well defined since adding a form of the form \(\dl \sigma\) to either \(\omega\) or \(\tau\) doesn't change the value of the integral as it just adds an integral of the form \(\int_M \omega \wedge \dl{\sigma}\), which we've just argued vanishes.
    
    Note that \(H^k_{\compact}(M)\) is defined in the obvious way by restricting our consideration to compactly supported forms before following the definition of the de Rham cohomology.
    
    \begin{thm}{Poincar\'e Duality}{}
        Let \(M\) be a smooth manifold of dimension \(m\) without boundary.
        Suppose that \(M\) has a finite good\footnote{a good cover is such that every intersection of covering sets is either empty or diffeomorphic to \(\reals^m\)} cover.
        Then the Poincar\'e pairing (\cref{eqn:poincare pairing}) is non-degenerate.
        Equivalently,
        \begin{itemize}
            \item if \(\omega \in \Omega^k(M)\) is closed and satisfies the condition that for all \(\tau \in \Omega^{m-k}_{\compact}(M)\) if \(\dl \tau = 0\) then
            \begin{equation}
                \int_M \omega \wedge \tau = 0
            \end{equation}
            then \(\omega\) is exact;
            \item if \(\tau \in \Omega_{\compact}^{m - k}(M)\) is closed and satisfies the condition that for all \(\omega \in \Omega^k(M)\) if \(\dl \omega = 0\) then
            \begin{equation}
                \int_M \omega \wedge \tau = 0
            \end{equation}
            then \(\tau\) is exact, and further there exists some \(\sigma \in \Omega_{\compact}^{m - k - 1}(M)\) such that \(\tau = \dl \sigma\) (as opposed to just \(\sigma \in \Omega^{m - k - 1}(M)\)).
        \end{itemize}
    \end{thm}
    
    Note that the two statements are truly just expressing what non-degeneracy means in this case.
    Specifically that for a non-zero input, that is a non-zero cohomology class, \([\omega]\), there is some non-zero cohomology class \([\tau]\) such that the pairing \(([\omega], [\tau])\) is non-zero.
    
    It is a general fact of non-degenerate bilinear forms \(\kappa \colon V \times U \to \reals\) (for vector spaces \(V\) and \(U\)) that they induce a linear map \(V \to U^*\) by \(v \mapsto \kappa(v, -)\).
    
    \begin{crl}{}{}
        The Poincar\'e pairing induces a linear map
        \begin{equation}
            \poincareDuality \colon H^k(M) \to H_{\compact}^{m - k}(M)*
        \end{equation}
        where \(H_{\compact}^{m-k}(M) = \Hom_{\reals}(H_{\compact}^{m-k}(M), \reals)\).
        This assigns to a cohomology class \([\omega] \in H^k(M)\) the homomorphism
        \begin{align}
            \poincareDuality([\omega]) \colon H_{\compact}^{m - k}(M) &\to \reals\\
            [\tau] &\mapsto \poincareDuality([\omega])([\tau]) = \int_M \omega \wedge \tau.
        \end{align}
    \end{crl}
    
    \section{Euler Characteristic and Betti Numbers}
    \begin{dfn}{Betti Numbers}{}
        Let \(M\) be a compact manifold of dimension \(m\).
        The \define{Betti numbers}\index{Betti number} of \(M\) are the dimensions of the de Rham cohomology:
        \begin{equation}
            b_i \coloneqq \dim (H^i(M)).
        \end{equation}
    \end{dfn}
    
    The Euler characteristic is a quantity that can be defined for a fairly general class of topological spaces, called finite CW-complexes.
    Specifically, the \defineindex{Euler characteristic} is defined as the alternating sum \(k_0 - k_1 + k_2 - k_3 + \dotsb\) where \(k_i\) denotes the number of cells of dimension \(i\) in the complex.
    Compact manifolds are all finite CW-complexes.
    The following theorem then gives an alternative way to compute the Euler characteristic for a nice class of manifolds.
    
    \begin{thm}{Euler Characteristic}{}
        Let \(M\) be a compact manifold of dimension \(m\) with boundary.
        The Euler characteristic of \(M\) is given by
        \begin{equation}
            \chi(M) = \sum_{i=0}^m (-1)^i \dim(H^i(M)) = \sum_{i=0}^m (-1)^i b_i.
        \end{equation}
    \end{thm}
    
    \section{\v{C}ech Cohomology}
    The de Rham cohomology is far from the only relevant cohomology for a manifold.
    In this section we'll briefly look at another cohomology theory which turns out to be isomorphic to the de Rham cohomology for sufficiently nice manifolds.
    
    \subsection{Defining the \v{C}ech Cohomology}
    Take a smooth manifold, \(M\), with an open cover \(\openCover = \{U_i\}_{i \in I}\), such that \(U_i \ne \emptyset\) for all \(i \in I\).
    When we look at overlaps of covering sets, such as \(U_i \cap U_j\), there is some combinatorics going on.
    For example, \(U_i \cap U_j = U_j \cap U_i\), so we don't have unique overlaps.
    The combinatorics of this open cover under intersections reduce to the combinatorics of the indices, and in particular of the multi-index set of all \(k\)-tuples of indices such that the overlap of the corresponding covering sets is non-empty:
    \begin{equation}
        \symcal{I}_k(\openCover) = \{(i_0, \dotsc, i_k) \in I^k \mid U_{i_0} \cap \dotsb \cap U_{i_k} \ne \emptyset\}.
    \end{equation}
    There is a natural action of the symmetric group, \(S_{k+1}\), on \(\symcal{I}_k(\openCover)\).
    The non-empty overlaps are then in bijection with the orbits of this action.
    
    To construct a cochain complex we need to create a sequence of vector spaces and the corresponding boundary maps.
    The obvious choice is that the vector space corresponding to \(k \in \integers\) should, for \(k \in \integers_{> 0}\), correspond to \(\symcal{I}_k(\openCover)\).
    We can construct a vector space \(\reals^{\symcal{I}_k(\openCover)}\) consisting of all functions \(\symcal{I}_k(\openCover) \to \reals\).
    We can alternatively view \(c \in \reals^{\symcal{I}_k(\openCover)}\) as a tuple \(c = (c_{i_0 \dotso i_k})_{(i_0, \dotsc, i_k) \in \symcal{I}_k(\openCover)}\) where the \(c_{i_0\dotso i_k}\) are real numbers.
    There is then a natural representation of \(S_{k+1}\) acting on this vector space by permuting indices.
    However, this isn't actually the representation we're interested in.
    It turns out that the useful vector space in this case is that of the alternating representation, that is, we look at the space of all tuples \(c = (c_{i_0 \dotso i_k})_{(i_0, \dotsc, i_k) \in \symcal{I}_k(\openCover)} \in \reals^{\symcal{I}_k(\openCover)}\) such that for all \(\sigma \in S_{k+1}\) we have
    \begin{equation}
        c_{i_{\sigma(0)} \dotso i_{\sigma(k)}} = \sgn(\sigma) c_{i_0 \dotso i_k}.
    \end{equation}
    We call the corresponding vector space of this representation \(C^k(\openCover, \reals)\) (the \(\reals\) is there because we chose \(\reals\) fairly arbitrarily as the set of values \(c_{i_0\dotso i_k}\) can take, we can equally replace it with any ring, \(R\), and consider \(R\)-modules \(C^k(\openCover, R)\) constructed in the same way).
    
    This gives us a cochain complex, called the \define{\v{C}ech complex}\index{Cech complex@\v{C}ech complex}
    \begin{equation}
        \begin{tikzcd}
            0 \arrow[r] & C^0(\openCover, \reals) \arrow[r, "\delta"] & C^1(\openCover, \reals) \arrow[r, "\delta"] & C^2(\openCover, \reals) \arrow[r, "\delta"] & \dotsb.
        \end{tikzcd}
    \end{equation}
    To define this we need to define the boundary maps, \(\delta \colon C^k(\openCover, \reals) \to C^{k+1}(\openCover, \reals)\), and we can do so by defining its action on \(c = (c_{i_0\dotso i_k})\) to give \(\delta c\) defined by
    \begin{equation}
        (\delta c)_{i_0 \dotso i_{k+1}} = \sum_{\ell = 0}^{k + 1} (-1)^{\ell} c_{i_0 \dotso \widehat{i_\ell} \dotso i_{k+1}}
    \end{equation}
    where \(\widehat{i_\ell}\) denotes leaving out \(i_\ell\) from the indices.
    
    To make this a bit more concrete let's look at what a \(k\)-cochain is for a few small values of \(k\):
    \begin{itemize}
        \item A \(0\)-cochain, \(c \in C^0(\openCover, \reals)\), simply assigns a real number, \(c_i\), to every open set, \(U_i\).
        \item A \(1\)-cochain, \(c \in C^1(\openCover, \reals)\), assigns a real number, \(c_{ij}\), to every non-empty intersection \(U_i \cap U_j\) in such a way that \(c_{ij} = -c_{ji}\).
        \item A \(2\)-cochain, \(c \in c^2(\openCover, \reals)\), assigns a real number, \(c_{ijk}\), to every non-empty intersection \(U_i \cap U_j \cap U_k\) in such a way that
        \begin{equation}
            c_{ijk} = c_{jki} = c_{kij} = -c_{ikj} = -c_{jik} = -c_{kji}. 
        \end{equation}
    \end{itemize}
    We can then look at how the boundary operator acts in these cases:
    \begin{itemize}
        \item For a \(0\)-cochain, \(c = (c_i)\), so long as \(U_i \cap U_j \ne \emptyset\) we have
        \begin{equation}
            (\delta c)_{ij} = (-1)^0 c_{\widehat{i}j} + (-1)^1 c_{i\widehat{j}} = c_{j} - c_{i}.
        \end{equation}
        \item For a \(1\)-cochain, \(c = (c_{ij})\), so long as \(U_i \cap U_j \cap U_k \ne \emptyset\) we have
        \begin{equation}
            (\delta c)_{ijk} = (-1)^0 c_{\widehat{i}jk} + (-1)^1 c_{i\widehat{j}k} + (-1)^2 c_{ij\widehat{k}} = c_{jk} - c_{ik} + c_{ij} = c_{jk} + c_{ki} + c_{ij}.
        \end{equation}
    \end{itemize}
    
    The fact that \(\delta^2 = 0\) follows from the computation
    \begin{align}
        (\delta^2 c)_{i_0 \dotso i_{k+2}} &= \sum_{p = 0}^{k + 1} (-1)^{p} (\delta_c)_{i_0 \dotso \widehat{i_{p}} \dotso i_{k+1}}\\
        &= \sum_{0 \le p < q \le k + 2} (-1)^{p + q} c_{i_0 \dotso \widehat{i_p} \dotso \widehat{i_q} \dotso i_{k+2}}\\
        &\qquad\qquad+ \sum_{0 \le q < p \le k + 2} (-1)^{p + q - 1} c_{i_0 \dotso \widehat{i_q} \dotso \widehat{i_p} \dotso i_{k + 2}} \notag\\
        &= 0.
    \end{align}
    Here we have to split the second sum up into two parts, one where \(q < p\) and one where \(q > p\).
    These sums then turn out to differ only by an overall sign, and so cancel to give zero.
    The sign change comes from the fact that when we allow \(q\) to range over values above \(p\) we have to adjust the index \(q\) which we're using to the position in the remaining indices after removing the index at \(p\), which results in the index position actually being \(q - 1\).
    
    Note that we also need to show that \(\delta c \in C^{k + 1}(\openCover, \reals)\), since from the definition all that is immediately clear is that \(\delta c \in \reals^{\symcal{I}_{k+1}(\openCover)}\).
    This just comes down to showing that \(\delta c\) is antisymmetric in all indices, and this follows immediately from the antisymmetry of \(c\) in all indices. 
    
    So, we have a cochain complex, we can now take the cohomology, and we define the \defineindex{\v{C}ech cohomology}
    \begin{equation}
        H^k(\openCover, \reals) = \check{H}^k(\openCover, \reals) = \frac{\ker(\delta \colon C^k(\openCover, \reals) \to C^{k + 1}(\openCover, \reals))}{\im(\delta \colon C^{k-1}(\openCover, \reals) \to C^k(\openCover, \reals))}.
    \end{equation}
    
    This construction so far works not just for any manifold, but for any topological space.
    There are then some natural questions to ask:
    \begin{itemize}
        \item Does the \v{C}ech cohomology depend on the choice of open cover, \(\openCover\)?
        \item If \(M\) is a manifold then how is the \v{C}ech cohomology, \(\check{H}(\openCover, \reals)\) related to the de Rham cohomology, \(H_{\derham}^k(M)\)?
    \end{itemize}
    
    \begin{exm}{Zeroth \v{C}ech Cohomology}{}
        Since the image of \(\delta \colon 0 \to C^0(\openCover, \reals)\) is \(0\) we have that
        \begin{equation}
            \check{H}^0(\openCover, \reals) = \frac{\ker(\delta \colon C^0(\openCover, \reals) \to C^1(\openCover, \reals))}{0} = \ker(\delta \colon C^0(\openCover, \reals) \to C^1(\openCover, \reals)).
        \end{equation}
        Thus, \(\check{H}^0(\openCover, \reals)\) consists of all tuples \(c = (c_i)_{i \in I}\) satisfying \(c_i = c_j\) whenever \(U_i \cap U_j \ne 0\), since these must be sent to zero by \(\delta\) as they map to \((\delta c)_{ij} = c_j - c_i\).
        Thus, whenever covering sets overlap the corresponding elements of the \v{C}ech cohomology must be equal on those open sets.
        In this way every 0-cocycle defines a locally constant function \(f \colon M \to \reals\) such that \(f|_{U_i} = c_i\) is constant.
        Then if each \(U_i\) is connected we have that \(\check{H}(\openCover, \reals)\) is isomorphic to \(\reals^r\) where \(r\) is the number of connected components of \(M\).
        This shows that so long as \(M\) is a manifold and \(\openCover\) consists only of connected sets we have \(H^0_{\derham}(M) \isomorphic \check{H}(\openCover, \reals)\).
        
        However, if \(\openCover = \{M\}\) then \(\check{H}(\openCover, \reals) = \reals\), so clearly there's some dependence on the choice of open cover.
    \end{exm}
    
    It turns out that there is a natural chain homomorphism from the \v{H}ech complex to the de Rham complex, and this factors through the quotients to induce a homomorphism between the cohomologies.
    Under some conditions this turns out to be an isomorphism.
    
    Let \(M\) be a smooth manifold with open cover \(\{\openCover\}_{i \in I}\) consisting of non-empty sets.
    Suppose also that we have chosen a partition of unity, \(\rho_i \colon M \to [0, 1]\), subordinate to \(\openCover\).
    We can use this to define the linear map
    \begin{align}
        C^k(\openCover, \reals) &\to \Omega^k(M)\\
        c &\mapsto \omega_c
    \end{align}
    where \(\omega_c\) has components given by \(c\):
    \begin{equation}
        \omega_c \coloneqq \sum_{(i_i, \dotsc, i_k) \in \symcal{I}_k(\openCover)} c_{i_0 \dotso i_k} \rho_{i_0} \ddagger\rho_{i_1} \wedge \dotsb \wedge \dl{\rho_{i_k}}.
    \end{equation}
    
    To prove that this is a chain homomorphism we need to show that \(\omega_{\delta c} = \dl \omega_c\).
    This can be done with a direct calculation, which essentially comes down to the fact that the antisymmetry of the wedge product \(\dl{\rho_{i_0}} \wedge \dotsb \wedge \dl{\rho_{i_{k+1}}}\) kills all terms that are summed over where the resulting indices aren't antisymmetrised, and any sum over all \(\rho_i\) gives \(1\).
    
    This then induces a homomorphism of the cohomologies:
    \begin{align}
        \check{H}^{k}(\openCover, \reals) &\to H_{\derham}^{k}(M)\\
        [c] &\mapsto [\omega_c].
    \end{align}
    
    \begin{thm}{}{}
        If \(\openCover\) is a good cover of \(M\) then this homomorphism of cohomologies is an isomorphism.
    \end{thm}
    
    \chapter{Vector Bundles}
    
    
    
    % Appdendix
%    \appendixpage
%    \begin{appendices}
%        
%    \end{appendices}
%
	\backmatter
	\renewcommand{\glossaryname}{Acronyms}
	\printglossary[acronym]
	\printindex
\end{document}
